+ echo Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2020-01-09_18-12-58
Logging output to experiments/logs/faster_rcnn_end2end_VGG16_.txt.2020-01-09_18-12-58
+ ./tools/train_net.py --gpu 0 --solver models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt --weights data/imagenet_models/VGG16.v2.caffemodel --imdb voc_2007_trainval --iters 7000 --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', gpu_id=0, imdb_name='voc_2007_trainval', max_iters=7000, pretrained_model='data/imagenet_models/VGG16.v2.caffemodel', randomize=False, set_cfgs=None, solver='models/pascal_voc/VGG16/faster_rcnn_end2end/solver.prototxt')
Using config:
{'DATA_DIR': '/home/ubuntu/user_space/maga_faster/our_method/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/ubuntu/user_space/maga_faster/our_method/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/user_space/maga_faster/our_method',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
Loaded dataset `voc_2007_trainval` for training
Set proposal method: gt
Appending horizontally-flipped training examples...
wrote gt roidb to /home/ubuntu/user_space/maga_faster/our_method/data/cache/voc_2007_trainval_gt_roidb.pkl
done
Preparing training data...
done
12582 roidb entries
Output will be saved to `/home/ubuntu/user_space/maga_faster/our_method/output/faster_rcnn_end2end/voc_2007_trainval`
Filtered 0 roidb entries: 12582 -> 12582
Computing bounding-box regression targets...
bbox target means:
[[0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]
 [0. 0. 0. 0.]]
[0. 0. 0. 0.]
bbox target stdevs:
[[0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]
 [0.1 0.1 0.2 0.2]]
[0.1 0.1 0.2 0.2]
Normalizing targets
done
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0109 18:13:10.991860 32941 solver.cpp:45] Initializing solver from parameters: 
train_net: "models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt"
base_lr: 0.001
display: 20
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 50000
snapshot: 0
snapshot_prefix: "vgg16_faster_rcnn"
average_loss: 100
iter_size: 2
I0109 18:13:10.991905 32941 solver.cpp:92] Creating training net from train_net file: models/pascal_voc/VGG16/faster_rcnn_end2end/train.prototxt
I0109 18:13:10.992533 32941 net.cpp:53] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TRAIN
}
layer {
  name: "input-data"
  type: "Python"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  python_param {
    module: "roi_data_layer.layer"
    layer: "RoIDataLayer"
    param_str: "\'num_classes\': 9"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "Python"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  bottom: "data"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  python_param {
    module: "rpn.anchor_target_layer"
    layer: "AnchorTargetLayer"
    param_str: "\'feat_stride\': 16"
  }
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  top: "rpn_cls_loss"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: "rpn_bbox_inside_weights"
  bottom: "rpn_bbox_outside_weights"
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16"
  }
}
layer {
  name: "roi-data"
  type: "Python"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  python_param {
    module: "rpn.proposal_target_layer"
    layer: "ProposalTargetLayer"
    param_str: "\'num_classes\': 9"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 9
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 36
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "cls_score"
  bottom: "labels"
  top: "loss_cls"
  loss_weight: 1
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1Loss"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  bottom: "bbox_inside_weights"
  bottom: "bbox_outside_weights"
  top: "loss_bbox"
  loss_weight: 1
}
I0109 18:13:10.992746 32941 layer_factory.hpp:77] Creating layer input-data
I0109 18:13:11.014134 32941 net.cpp:86] Creating Layer input-data
I0109 18:13:11.014163 32941 net.cpp:382] input-data -> data
I0109 18:13:11.014176 32941 net.cpp:382] input-data -> im_info
I0109 18:13:11.014183 32941 net.cpp:382] input-data -> gt_boxes
RoiDataLayer: name_to_top: {'im_info': 1, 'gt_boxes': 2, 'data': 0}
I0109 18:13:11.016321 32941 net.cpp:124] Setting up input-data
I0109 18:13:11.016338 32941 net.cpp:131] Top shape: 1 3 600 1000 (1800000)
I0109 18:13:11.016348 32941 net.cpp:131] Top shape: 1 3 (3)
I0109 18:13:11.016353 32941 net.cpp:131] Top shape: 1 4 (4)
I0109 18:13:11.016356 32941 net.cpp:139] Memory required for data: 7200028
I0109 18:13:11.016362 32941 layer_factory.hpp:77] Creating layer data_input-data_0_split
I0109 18:13:11.016373 32941 net.cpp:86] Creating Layer data_input-data_0_split
I0109 18:13:11.016378 32941 net.cpp:408] data_input-data_0_split <- data
I0109 18:13:11.016386 32941 net.cpp:382] data_input-data_0_split -> data_input-data_0_split_0
I0109 18:13:11.016393 32941 net.cpp:382] data_input-data_0_split -> data_input-data_0_split_1
I0109 18:13:11.016427 32941 net.cpp:124] Setting up data_input-data_0_split
I0109 18:13:11.016436 32941 net.cpp:131] Top shape: 1 3 600 1000 (1800000)
I0109 18:13:11.016441 32941 net.cpp:131] Top shape: 1 3 600 1000 (1800000)
I0109 18:13:11.016444 32941 net.cpp:139] Memory required for data: 21600028
I0109 18:13:11.016448 32941 layer_factory.hpp:77] Creating layer im_info_input-data_1_split
I0109 18:13:11.016454 32941 net.cpp:86] Creating Layer im_info_input-data_1_split
I0109 18:13:11.016458 32941 net.cpp:408] im_info_input-data_1_split <- im_info
I0109 18:13:11.016463 32941 net.cpp:382] im_info_input-data_1_split -> im_info_input-data_1_split_0
I0109 18:13:11.016470 32941 net.cpp:382] im_info_input-data_1_split -> im_info_input-data_1_split_1
I0109 18:13:11.016495 32941 net.cpp:124] Setting up im_info_input-data_1_split
I0109 18:13:11.016502 32941 net.cpp:131] Top shape: 1 3 (3)
I0109 18:13:11.016507 32941 net.cpp:131] Top shape: 1 3 (3)
I0109 18:13:11.016510 32941 net.cpp:139] Memory required for data: 21600052
I0109 18:13:11.016513 32941 layer_factory.hpp:77] Creating layer gt_boxes_input-data_2_split
I0109 18:13:11.016520 32941 net.cpp:86] Creating Layer gt_boxes_input-data_2_split
I0109 18:13:11.016522 32941 net.cpp:408] gt_boxes_input-data_2_split <- gt_boxes
I0109 18:13:11.016528 32941 net.cpp:382] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_0
I0109 18:13:11.016535 32941 net.cpp:382] gt_boxes_input-data_2_split -> gt_boxes_input-data_2_split_1
I0109 18:13:11.016561 32941 net.cpp:124] Setting up gt_boxes_input-data_2_split
I0109 18:13:11.016569 32941 net.cpp:131] Top shape: 1 4 (4)
I0109 18:13:11.016573 32941 net.cpp:131] Top shape: 1 4 (4)
I0109 18:13:11.016577 32941 net.cpp:139] Memory required for data: 21600084
I0109 18:13:11.016580 32941 layer_factory.hpp:77] Creating layer conv1_1
I0109 18:13:11.016592 32941 net.cpp:86] Creating Layer conv1_1
I0109 18:13:11.016595 32941 net.cpp:408] conv1_1 <- data_input-data_0_split_0
I0109 18:13:11.016602 32941 net.cpp:382] conv1_1 -> conv1_1
I0109 18:13:12.148244 32941 net.cpp:124] Setting up conv1_1
I0109 18:13:12.148281 32941 net.cpp:131] Top shape: 1 64 600 1000 (38400000)
I0109 18:13:12.148288 32941 net.cpp:139] Memory required for data: 175200084
I0109 18:13:12.148313 32941 layer_factory.hpp:77] Creating layer relu1_1
I0109 18:13:12.148332 32941 net.cpp:86] Creating Layer relu1_1
I0109 18:13:12.148342 32941 net.cpp:408] relu1_1 <- conv1_1
I0109 18:13:12.148350 32941 net.cpp:369] relu1_1 -> conv1_1 (in-place)
I0109 18:13:12.148669 32941 net.cpp:124] Setting up relu1_1
I0109 18:13:12.148682 32941 net.cpp:131] Top shape: 1 64 600 1000 (38400000)
I0109 18:13:12.148686 32941 net.cpp:139] Memory required for data: 328800084
I0109 18:13:12.148690 32941 layer_factory.hpp:77] Creating layer conv1_2
I0109 18:13:12.148706 32941 net.cpp:86] Creating Layer conv1_2
I0109 18:13:12.148711 32941 net.cpp:408] conv1_2 <- conv1_1
I0109 18:13:12.148718 32941 net.cpp:382] conv1_2 -> conv1_2
I0109 18:13:12.154424 32941 net.cpp:124] Setting up conv1_2
I0109 18:13:12.154445 32941 net.cpp:131] Top shape: 1 64 600 1000 (38400000)
I0109 18:13:12.154450 32941 net.cpp:139] Memory required for data: 482400084
I0109 18:13:12.154461 32941 layer_factory.hpp:77] Creating layer relu1_2
I0109 18:13:12.154470 32941 net.cpp:86] Creating Layer relu1_2
I0109 18:13:12.154475 32941 net.cpp:408] relu1_2 <- conv1_2
I0109 18:13:12.154482 32941 net.cpp:369] relu1_2 -> conv1_2 (in-place)
I0109 18:13:12.154996 32941 net.cpp:124] Setting up relu1_2
I0109 18:13:12.155014 32941 net.cpp:131] Top shape: 1 64 600 1000 (38400000)
I0109 18:13:12.155017 32941 net.cpp:139] Memory required for data: 636000084
I0109 18:13:12.155021 32941 layer_factory.hpp:77] Creating layer pool1
I0109 18:13:12.155035 32941 net.cpp:86] Creating Layer pool1
I0109 18:13:12.155040 32941 net.cpp:408] pool1 <- conv1_2
I0109 18:13:12.155048 32941 net.cpp:382] pool1 -> pool1
I0109 18:13:12.155092 32941 net.cpp:124] Setting up pool1
I0109 18:13:12.155099 32941 net.cpp:131] Top shape: 1 64 300 500 (9600000)
I0109 18:13:12.155102 32941 net.cpp:139] Memory required for data: 674400084
I0109 18:13:12.155107 32941 layer_factory.hpp:77] Creating layer conv2_1
I0109 18:13:12.155119 32941 net.cpp:86] Creating Layer conv2_1
I0109 18:13:12.155123 32941 net.cpp:408] conv2_1 <- pool1
I0109 18:13:12.155130 32941 net.cpp:382] conv2_1 -> conv2_1
I0109 18:13:12.157040 32941 net.cpp:124] Setting up conv2_1
I0109 18:13:12.157058 32941 net.cpp:131] Top shape: 1 128 300 500 (19200000)
I0109 18:13:12.157063 32941 net.cpp:139] Memory required for data: 751200084
I0109 18:13:12.157074 32941 layer_factory.hpp:77] Creating layer relu2_1
I0109 18:13:12.157083 32941 net.cpp:86] Creating Layer relu2_1
I0109 18:13:12.157088 32941 net.cpp:408] relu2_1 <- conv2_1
I0109 18:13:12.157094 32941 net.cpp:369] relu2_1 -> conv2_1 (in-place)
I0109 18:13:12.157444 32941 net.cpp:124] Setting up relu2_1
I0109 18:13:12.157457 32941 net.cpp:131] Top shape: 1 128 300 500 (19200000)
I0109 18:13:12.157461 32941 net.cpp:139] Memory required for data: 828000084
I0109 18:13:12.157465 32941 layer_factory.hpp:77] Creating layer conv2_2
I0109 18:13:12.157477 32941 net.cpp:86] Creating Layer conv2_2
I0109 18:13:12.157481 32941 net.cpp:408] conv2_2 <- conv2_1
I0109 18:13:12.157490 32941 net.cpp:382] conv2_2 -> conv2_2
I0109 18:13:12.167740 32941 net.cpp:124] Setting up conv2_2
I0109 18:13:12.167793 32941 net.cpp:131] Top shape: 1 128 300 500 (19200000)
I0109 18:13:12.167798 32941 net.cpp:139] Memory required for data: 904800084
I0109 18:13:12.167816 32941 layer_factory.hpp:77] Creating layer relu2_2
I0109 18:13:12.167843 32941 net.cpp:86] Creating Layer relu2_2
I0109 18:13:12.167850 32941 net.cpp:408] relu2_2 <- conv2_2
I0109 18:13:12.167860 32941 net.cpp:369] relu2_2 -> conv2_2 (in-place)
I0109 18:13:12.168442 32941 net.cpp:124] Setting up relu2_2
I0109 18:13:12.168460 32941 net.cpp:131] Top shape: 1 128 300 500 (19200000)
I0109 18:13:12.168463 32941 net.cpp:139] Memory required for data: 981600084
I0109 18:13:12.168468 32941 layer_factory.hpp:77] Creating layer pool2
I0109 18:13:12.168478 32941 net.cpp:86] Creating Layer pool2
I0109 18:13:12.168483 32941 net.cpp:408] pool2 <- conv2_2
I0109 18:13:12.168491 32941 net.cpp:382] pool2 -> pool2
I0109 18:13:12.168547 32941 net.cpp:124] Setting up pool2
I0109 18:13:12.168568 32941 net.cpp:131] Top shape: 1 128 150 250 (4800000)
I0109 18:13:12.168572 32941 net.cpp:139] Memory required for data: 1000800084
I0109 18:13:12.168576 32941 layer_factory.hpp:77] Creating layer conv3_1
I0109 18:13:12.168591 32941 net.cpp:86] Creating Layer conv3_1
I0109 18:13:12.168596 32941 net.cpp:408] conv3_1 <- pool2
I0109 18:13:12.168602 32941 net.cpp:382] conv3_1 -> conv3_1
I0109 18:13:12.173123 32941 net.cpp:124] Setting up conv3_1
I0109 18:13:12.173158 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.173162 32941 net.cpp:139] Memory required for data: 1039200084
I0109 18:13:12.173185 32941 layer_factory.hpp:77] Creating layer relu3_1
I0109 18:13:12.173195 32941 net.cpp:86] Creating Layer relu3_1
I0109 18:13:12.173200 32941 net.cpp:408] relu3_1 <- conv3_1
I0109 18:13:12.173211 32941 net.cpp:369] relu3_1 -> conv3_1 (in-place)
I0109 18:13:12.173779 32941 net.cpp:124] Setting up relu3_1
I0109 18:13:12.173799 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.173804 32941 net.cpp:139] Memory required for data: 1077600084
I0109 18:13:12.173812 32941 layer_factory.hpp:77] Creating layer conv3_2
I0109 18:13:12.173835 32941 net.cpp:86] Creating Layer conv3_2
I0109 18:13:12.173840 32941 net.cpp:408] conv3_2 <- conv3_1
I0109 18:13:12.173852 32941 net.cpp:382] conv3_2 -> conv3_2
I0109 18:13:12.179468 32941 net.cpp:124] Setting up conv3_2
I0109 18:13:12.179517 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.179522 32941 net.cpp:139] Memory required for data: 1116000084
I0109 18:13:12.179538 32941 layer_factory.hpp:77] Creating layer relu3_2
I0109 18:13:12.179554 32941 net.cpp:86] Creating Layer relu3_2
I0109 18:13:12.179560 32941 net.cpp:408] relu3_2 <- conv3_2
I0109 18:13:12.179574 32941 net.cpp:369] relu3_2 -> conv3_2 (in-place)
I0109 18:13:12.183444 32941 net.cpp:124] Setting up relu3_2
I0109 18:13:12.183475 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.183481 32941 net.cpp:139] Memory required for data: 1154400084
I0109 18:13:12.183488 32941 layer_factory.hpp:77] Creating layer conv3_3
I0109 18:13:12.183506 32941 net.cpp:86] Creating Layer conv3_3
I0109 18:13:12.183512 32941 net.cpp:408] conv3_3 <- conv3_2
I0109 18:13:12.183526 32941 net.cpp:382] conv3_3 -> conv3_3
I0109 18:13:12.191293 32941 net.cpp:124] Setting up conv3_3
I0109 18:13:12.191323 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.191329 32941 net.cpp:139] Memory required for data: 1192800084
I0109 18:13:12.191339 32941 layer_factory.hpp:77] Creating layer relu3_3
I0109 18:13:12.191349 32941 net.cpp:86] Creating Layer relu3_3
I0109 18:13:12.191354 32941 net.cpp:408] relu3_3 <- conv3_3
I0109 18:13:12.191365 32941 net.cpp:369] relu3_3 -> conv3_3 (in-place)
I0109 18:13:12.192025 32941 net.cpp:124] Setting up relu3_3
I0109 18:13:12.192041 32941 net.cpp:131] Top shape: 1 256 150 250 (9600000)
I0109 18:13:12.192045 32941 net.cpp:139] Memory required for data: 1231200084
I0109 18:13:12.192051 32941 layer_factory.hpp:77] Creating layer pool3
I0109 18:13:12.192061 32941 net.cpp:86] Creating Layer pool3
I0109 18:13:12.192065 32941 net.cpp:408] pool3 <- conv3_3
I0109 18:13:12.192075 32941 net.cpp:382] pool3 -> pool3
I0109 18:13:12.192121 32941 net.cpp:124] Setting up pool3
I0109 18:13:12.192131 32941 net.cpp:131] Top shape: 1 256 75 125 (2400000)
I0109 18:13:12.192134 32941 net.cpp:139] Memory required for data: 1240800084
I0109 18:13:12.192139 32941 layer_factory.hpp:77] Creating layer conv4_1
I0109 18:13:12.192157 32941 net.cpp:86] Creating Layer conv4_1
I0109 18:13:12.192163 32941 net.cpp:408] conv4_1 <- pool3
I0109 18:13:12.192169 32941 net.cpp:382] conv4_1 -> conv4_1
I0109 18:13:12.198652 32941 net.cpp:124] Setting up conv4_1
I0109 18:13:12.198685 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.198690 32941 net.cpp:139] Memory required for data: 1260000084
I0109 18:13:12.198701 32941 layer_factory.hpp:77] Creating layer relu4_1
I0109 18:13:12.198711 32941 net.cpp:86] Creating Layer relu4_1
I0109 18:13:12.198717 32941 net.cpp:408] relu4_1 <- conv4_1
I0109 18:13:12.198727 32941 net.cpp:369] relu4_1 -> conv4_1 (in-place)
I0109 18:13:12.199157 32941 net.cpp:124] Setting up relu4_1
I0109 18:13:12.199174 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.199178 32941 net.cpp:139] Memory required for data: 1279200084
I0109 18:13:12.199182 32941 layer_factory.hpp:77] Creating layer conv4_2
I0109 18:13:12.199196 32941 net.cpp:86] Creating Layer conv4_2
I0109 18:13:12.199200 32941 net.cpp:408] conv4_2 <- conv4_1
I0109 18:13:12.199208 32941 net.cpp:382] conv4_2 -> conv4_2
I0109 18:13:12.222867 32941 net.cpp:124] Setting up conv4_2
I0109 18:13:12.222904 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.222910 32941 net.cpp:139] Memory required for data: 1298400084
I0109 18:13:12.222930 32941 layer_factory.hpp:77] Creating layer relu4_2
I0109 18:13:12.222942 32941 net.cpp:86] Creating Layer relu4_2
I0109 18:13:12.222947 32941 net.cpp:408] relu4_2 <- conv4_2
I0109 18:13:12.222954 32941 net.cpp:369] relu4_2 -> conv4_2 (in-place)
I0109 18:13:12.223628 32941 net.cpp:124] Setting up relu4_2
I0109 18:13:12.223645 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.223649 32941 net.cpp:139] Memory required for data: 1317600084
I0109 18:13:12.223654 32941 layer_factory.hpp:77] Creating layer conv4_3
I0109 18:13:12.223666 32941 net.cpp:86] Creating Layer conv4_3
I0109 18:13:12.223671 32941 net.cpp:408] conv4_3 <- conv4_2
I0109 18:13:12.223680 32941 net.cpp:382] conv4_3 -> conv4_3
I0109 18:13:12.235900 32941 net.cpp:124] Setting up conv4_3
I0109 18:13:12.235935 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.235939 32941 net.cpp:139] Memory required for data: 1336800084
I0109 18:13:12.235951 32941 layer_factory.hpp:77] Creating layer relu4_3
I0109 18:13:12.235961 32941 net.cpp:86] Creating Layer relu4_3
I0109 18:13:12.235967 32941 net.cpp:408] relu4_3 <- conv4_3
I0109 18:13:12.235975 32941 net.cpp:369] relu4_3 -> conv4_3 (in-place)
I0109 18:13:12.236560 32941 net.cpp:124] Setting up relu4_3
I0109 18:13:12.236577 32941 net.cpp:131] Top shape: 1 512 75 125 (4800000)
I0109 18:13:12.236582 32941 net.cpp:139] Memory required for data: 1356000084
I0109 18:13:12.236585 32941 layer_factory.hpp:77] Creating layer pool4
I0109 18:13:12.236595 32941 net.cpp:86] Creating Layer pool4
I0109 18:13:12.236599 32941 net.cpp:408] pool4 <- conv4_3
I0109 18:13:12.236606 32941 net.cpp:382] pool4 -> pool4
I0109 18:13:12.236654 32941 net.cpp:124] Setting up pool4
I0109 18:13:12.236662 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.236666 32941 net.cpp:139] Memory required for data: 1360902996
I0109 18:13:12.236671 32941 layer_factory.hpp:77] Creating layer conv5_1
I0109 18:13:12.236685 32941 net.cpp:86] Creating Layer conv5_1
I0109 18:13:12.236690 32941 net.cpp:408] conv5_1 <- pool4
I0109 18:13:12.236696 32941 net.cpp:382] conv5_1 -> conv5_1
I0109 18:13:12.250447 32941 net.cpp:124] Setting up conv5_1
I0109 18:13:12.250484 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.250489 32941 net.cpp:139] Memory required for data: 1365805908
I0109 18:13:12.250500 32941 layer_factory.hpp:77] Creating layer relu5_1
I0109 18:13:12.250511 32941 net.cpp:86] Creating Layer relu5_1
I0109 18:13:12.250517 32941 net.cpp:408] relu5_1 <- conv5_1
I0109 18:13:12.250527 32941 net.cpp:369] relu5_1 -> conv5_1 (in-place)
I0109 18:13:12.251180 32941 net.cpp:124] Setting up relu5_1
I0109 18:13:12.251197 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.251201 32941 net.cpp:139] Memory required for data: 1370708820
I0109 18:13:12.251205 32941 layer_factory.hpp:77] Creating layer conv5_2
I0109 18:13:12.251219 32941 net.cpp:86] Creating Layer conv5_2
I0109 18:13:12.251224 32941 net.cpp:408] conv5_2 <- conv5_1
I0109 18:13:12.251233 32941 net.cpp:382] conv5_2 -> conv5_2
I0109 18:13:12.260939 32941 net.cpp:124] Setting up conv5_2
I0109 18:13:12.260974 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.260979 32941 net.cpp:139] Memory required for data: 1375611732
I0109 18:13:12.260991 32941 layer_factory.hpp:77] Creating layer relu5_2
I0109 18:13:12.261003 32941 net.cpp:86] Creating Layer relu5_2
I0109 18:13:12.261008 32941 net.cpp:408] relu5_2 <- conv5_2
I0109 18:13:12.261018 32941 net.cpp:369] relu5_2 -> conv5_2 (in-place)
I0109 18:13:12.261449 32941 net.cpp:124] Setting up relu5_2
I0109 18:13:12.261464 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.261467 32941 net.cpp:139] Memory required for data: 1380514644
I0109 18:13:12.261472 32941 layer_factory.hpp:77] Creating layer conv5_3
I0109 18:13:12.261493 32941 net.cpp:86] Creating Layer conv5_3
I0109 18:13:12.261498 32941 net.cpp:408] conv5_3 <- conv5_2
I0109 18:13:12.261505 32941 net.cpp:382] conv5_3 -> conv5_3
I0109 18:13:12.272007 32941 net.cpp:124] Setting up conv5_3
I0109 18:13:12.272043 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.272048 32941 net.cpp:139] Memory required for data: 1385417556
I0109 18:13:12.272059 32941 layer_factory.hpp:77] Creating layer relu5_3
I0109 18:13:12.272074 32941 net.cpp:86] Creating Layer relu5_3
I0109 18:13:12.272080 32941 net.cpp:408] relu5_3 <- conv5_3
I0109 18:13:12.272087 32941 net.cpp:369] relu5_3 -> conv5_3 (in-place)
I0109 18:13:12.274629 32941 net.cpp:124] Setting up relu5_3
I0109 18:13:12.274652 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.274657 32941 net.cpp:139] Memory required for data: 1390320468
I0109 18:13:12.274663 32941 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0109 18:13:12.274672 32941 net.cpp:86] Creating Layer conv5_3_relu5_3_0_split
I0109 18:13:12.274677 32941 net.cpp:408] conv5_3_relu5_3_0_split <- conv5_3
I0109 18:13:12.274688 32941 net.cpp:382] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0109 18:13:12.274698 32941 net.cpp:382] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0109 18:13:12.274745 32941 net.cpp:124] Setting up conv5_3_relu5_3_0_split
I0109 18:13:12.274755 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.274760 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.274762 32941 net.cpp:139] Memory required for data: 1400126292
I0109 18:13:12.274766 32941 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0109 18:13:12.274782 32941 net.cpp:86] Creating Layer rpn_conv/3x3
I0109 18:13:12.274788 32941 net.cpp:408] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0109 18:13:12.274840 32941 net.cpp:382] rpn_conv/3x3 -> rpn/output
I0109 18:13:12.315429 32941 net.cpp:124] Setting up rpn_conv/3x3
I0109 18:13:12.315465 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.315470 32941 net.cpp:139] Memory required for data: 1405029204
I0109 18:13:12.315482 32941 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0109 18:13:12.315497 32941 net.cpp:86] Creating Layer rpn_relu/3x3
I0109 18:13:12.315502 32941 net.cpp:408] rpn_relu/3x3 <- rpn/output
I0109 18:13:12.315511 32941 net.cpp:369] rpn_relu/3x3 -> rpn/output (in-place)
I0109 18:13:12.316331 32941 net.cpp:124] Setting up rpn_relu/3x3
I0109 18:13:12.316351 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.316356 32941 net.cpp:139] Memory required for data: 1409932116
I0109 18:13:12.316363 32941 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0109 18:13:12.316370 32941 net.cpp:86] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0109 18:13:12.316375 32941 net.cpp:408] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0109 18:13:12.316385 32941 net.cpp:382] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0109 18:13:12.316392 32941 net.cpp:382] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0109 18:13:12.316434 32941 net.cpp:124] Setting up rpn/output_rpn_relu/3x3_0_split
I0109 18:13:12.316445 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.316450 32941 net.cpp:131] Top shape: 1 512 38 63 (1225728)
I0109 18:13:12.316453 32941 net.cpp:139] Memory required for data: 1419737940
I0109 18:13:12.316457 32941 layer_factory.hpp:77] Creating layer rpn_cls_score
I0109 18:13:12.316471 32941 net.cpp:86] Creating Layer rpn_cls_score
I0109 18:13:12.316478 32941 net.cpp:408] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0109 18:13:12.316485 32941 net.cpp:382] rpn_cls_score -> rpn_cls_score
I0109 18:13:12.320909 32941 net.cpp:124] Setting up rpn_cls_score
I0109 18:13:12.320942 32941 net.cpp:131] Top shape: 1 18 38 63 (43092)
I0109 18:13:12.320948 32941 net.cpp:139] Memory required for data: 1419910308
I0109 18:13:12.320960 32941 layer_factory.hpp:77] Creating layer rpn_cls_score_rpn_cls_score_0_split
I0109 18:13:12.320974 32941 net.cpp:86] Creating Layer rpn_cls_score_rpn_cls_score_0_split
I0109 18:13:12.320981 32941 net.cpp:408] rpn_cls_score_rpn_cls_score_0_split <- rpn_cls_score
I0109 18:13:12.320991 32941 net.cpp:382] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_0
I0109 18:13:12.321023 32941 net.cpp:382] rpn_cls_score_rpn_cls_score_0_split -> rpn_cls_score_rpn_cls_score_0_split_1
I0109 18:13:12.321085 32941 net.cpp:124] Setting up rpn_cls_score_rpn_cls_score_0_split
I0109 18:13:12.321099 32941 net.cpp:131] Top shape: 1 18 38 63 (43092)
I0109 18:13:12.321106 32941 net.cpp:131] Top shape: 1 18 38 63 (43092)
I0109 18:13:12.321110 32941 net.cpp:139] Memory required for data: 1420255044
I0109 18:13:12.321118 32941 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0109 18:13:12.321136 32941 net.cpp:86] Creating Layer rpn_bbox_pred
I0109 18:13:12.321144 32941 net.cpp:408] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0109 18:13:12.321157 32941 net.cpp:382] rpn_bbox_pred -> rpn_bbox_pred
I0109 18:13:12.335616 32941 net.cpp:124] Setting up rpn_bbox_pred
I0109 18:13:12.335664 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.335670 32941 net.cpp:139] Memory required for data: 1420599780
I0109 18:13:12.335685 32941 layer_factory.hpp:77] Creating layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0109 18:13:12.335700 32941 net.cpp:86] Creating Layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0109 18:13:12.335707 32941 net.cpp:408] rpn_bbox_pred_rpn_bbox_pred_0_split <- rpn_bbox_pred
I0109 18:13:12.335721 32941 net.cpp:382] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0109 18:13:12.335741 32941 net.cpp:382] rpn_bbox_pred_rpn_bbox_pred_0_split -> rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0109 18:13:12.335803 32941 net.cpp:124] Setting up rpn_bbox_pred_rpn_bbox_pred_0_split
I0109 18:13:12.335815 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.335821 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.335826 32941 net.cpp:139] Memory required for data: 1421289252
I0109 18:13:12.335831 32941 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0109 18:13:12.335844 32941 net.cpp:86] Creating Layer rpn_cls_score_reshape
I0109 18:13:12.335851 32941 net.cpp:408] rpn_cls_score_reshape <- rpn_cls_score_rpn_cls_score_0_split_0
I0109 18:13:12.335862 32941 net.cpp:382] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0109 18:13:12.335902 32941 net.cpp:124] Setting up rpn_cls_score_reshape
I0109 18:13:12.335914 32941 net.cpp:131] Top shape: 1 2 342 63 (43092)
I0109 18:13:12.335919 32941 net.cpp:139] Memory required for data: 1421461620
I0109 18:13:12.335927 32941 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0109 18:13:12.335935 32941 net.cpp:86] Creating Layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0109 18:13:12.335949 32941 net.cpp:408] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split <- rpn_cls_score_reshape
I0109 18:13:12.335960 32941 net.cpp:382] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0109 18:13:12.335973 32941 net.cpp:382] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split -> rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0109 18:13:12.336020 32941 net.cpp:124] Setting up rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0109 18:13:12.336033 32941 net.cpp:131] Top shape: 1 2 342 63 (43092)
I0109 18:13:12.336040 32941 net.cpp:131] Top shape: 1 2 342 63 (43092)
I0109 18:13:12.336045 32941 net.cpp:139] Memory required for data: 1421806356
I0109 18:13:12.336050 32941 layer_factory.hpp:77] Creating layer rpn-data
I0109 18:13:12.337726 32941 net.cpp:86] Creating Layer rpn-data
I0109 18:13:12.337749 32941 net.cpp:408] rpn-data <- rpn_cls_score_rpn_cls_score_0_split_1
I0109 18:13:12.337759 32941 net.cpp:408] rpn-data <- gt_boxes_input-data_2_split_0
I0109 18:13:12.337765 32941 net.cpp:408] rpn-data <- im_info_input-data_1_split_0
I0109 18:13:12.337771 32941 net.cpp:408] rpn-data <- data_input-data_0_split_1
I0109 18:13:12.337785 32941 net.cpp:382] rpn-data -> rpn_labels
I0109 18:13:12.337798 32941 net.cpp:382] rpn-data -> rpn_bbox_targets
I0109 18:13:12.337811 32941 net.cpp:382] rpn-data -> rpn_bbox_inside_weights
I0109 18:13:12.337824 32941 net.cpp:382] rpn-data -> rpn_bbox_outside_weights
I0109 18:13:12.339318 32941 net.cpp:124] Setting up rpn-data
I0109 18:13:12.339341 32941 net.cpp:131] Top shape: 1 1 342 63 (21546)
I0109 18:13:12.339350 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.339357 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.339363 32941 net.cpp:131] Top shape: 1 36 38 63 (86184)
I0109 18:13:12.339368 32941 net.cpp:139] Memory required for data: 1422926748
I0109 18:13:12.339375 32941 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0109 18:13:12.339385 32941 net.cpp:86] Creating Layer rpn_loss_cls
I0109 18:13:12.339395 32941 net.cpp:408] rpn_loss_cls <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_0
I0109 18:13:12.339401 32941 net.cpp:408] rpn_loss_cls <- rpn_labels
I0109 18:13:12.339413 32941 net.cpp:382] rpn_loss_cls -> rpn_cls_loss
I0109 18:13:12.339431 32941 layer_factory.hpp:77] Creating layer rpn_loss_cls
I0109 18:13:12.340201 32941 net.cpp:124] Setting up rpn_loss_cls
I0109 18:13:12.340221 32941 net.cpp:131] Top shape: (1)
I0109 18:13:12.340226 32941 net.cpp:134]     with loss weight 1
I0109 18:13:12.340237 32941 net.cpp:139] Memory required for data: 1422926752
I0109 18:13:12.340243 32941 layer_factory.hpp:77] Creating layer rpn_loss_bbox
I0109 18:13:12.340260 32941 net.cpp:86] Creating Layer rpn_loss_bbox
I0109 18:13:12.340266 32941 net.cpp:408] rpn_loss_bbox <- rpn_bbox_pred_rpn_bbox_pred_0_split_0
I0109 18:13:12.340274 32941 net.cpp:408] rpn_loss_bbox <- rpn_bbox_targets
I0109 18:13:12.340281 32941 net.cpp:408] rpn_loss_bbox <- rpn_bbox_inside_weights
I0109 18:13:12.340287 32941 net.cpp:408] rpn_loss_bbox <- rpn_bbox_outside_weights
I0109 18:13:12.340296 32941 net.cpp:382] rpn_loss_bbox -> rpn_loss_bbox
I0109 18:13:12.341581 32941 net.cpp:124] Setting up rpn_loss_bbox
I0109 18:13:12.341596 32941 net.cpp:131] Top shape: (1)
I0109 18:13:12.341601 32941 net.cpp:134]     with loss weight 1
I0109 18:13:12.341609 32941 net.cpp:139] Memory required for data: 1422926756
I0109 18:13:12.341615 32941 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0109 18:13:12.341624 32941 net.cpp:86] Creating Layer rpn_cls_prob
I0109 18:13:12.341629 32941 net.cpp:408] rpn_cls_prob <- rpn_cls_score_reshape_rpn_cls_score_reshape_0_split_1
I0109 18:13:12.341640 32941 net.cpp:382] rpn_cls_prob -> rpn_cls_prob
I0109 18:13:12.360884 32941 net.cpp:124] Setting up rpn_cls_prob
I0109 18:13:12.360929 32941 net.cpp:131] Top shape: 1 2 342 63 (43092)
I0109 18:13:12.360937 32941 net.cpp:139] Memory required for data: 1423099124
I0109 18:13:12.360949 32941 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0109 18:13:12.360966 32941 net.cpp:86] Creating Layer rpn_cls_prob_reshape
I0109 18:13:12.360975 32941 net.cpp:408] rpn_cls_prob_reshape <- rpn_cls_prob
I0109 18:13:12.360993 32941 net.cpp:382] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0109 18:13:12.361043 32941 net.cpp:124] Setting up rpn_cls_prob_reshape
I0109 18:13:12.361059 32941 net.cpp:131] Top shape: 1 18 38 63 (43092)
I0109 18:13:12.361065 32941 net.cpp:139] Memory required for data: 1423271492
I0109 18:13:12.361071 32941 layer_factory.hpp:77] Creating layer proposal
I0109 18:13:12.366667 32941 net.cpp:86] Creating Layer proposal
I0109 18:13:12.366691 32941 net.cpp:408] proposal <- rpn_cls_prob_reshape
I0109 18:13:12.366701 32941 net.cpp:408] proposal <- rpn_bbox_pred_rpn_bbox_pred_0_split_1
I0109 18:13:12.366709 32941 net.cpp:408] proposal <- im_info_input-data_1_split_1
I0109 18:13:12.366719 32941 net.cpp:382] proposal -> rpn_rois
I0109 18:13:12.368407 32941 net.cpp:124] Setting up proposal
I0109 18:13:12.368432 32941 net.cpp:131] Top shape: 1 5 (5)
I0109 18:13:12.368438 32941 net.cpp:139] Memory required for data: 1423271512
I0109 18:13:12.368444 32941 layer_factory.hpp:77] Creating layer roi-data
I0109 18:13:12.368958 32941 net.cpp:86] Creating Layer roi-data
I0109 18:13:12.368980 32941 net.cpp:408] roi-data <- rpn_rois
I0109 18:13:12.368990 32941 net.cpp:408] roi-data <- gt_boxes_input-data_2_split_1
I0109 18:13:12.369002 32941 net.cpp:382] roi-data -> rois
I0109 18:13:12.369014 32941 net.cpp:382] roi-data -> labels
I0109 18:13:12.369026 32941 net.cpp:382] roi-data -> bbox_targets
I0109 18:13:12.369040 32941 net.cpp:382] roi-data -> bbox_inside_weights
I0109 18:13:12.369051 32941 net.cpp:382] roi-data -> bbox_outside_weights
I0109 18:13:12.369762 32941 net.cpp:124] Setting up roi-data
I0109 18:13:12.369784 32941 net.cpp:131] Top shape: 1 5 (5)
I0109 18:13:12.369791 32941 net.cpp:131] Top shape: 1 1 (1)
I0109 18:13:12.369797 32941 net.cpp:131] Top shape: 1 36 (36)
I0109 18:13:12.369804 32941 net.cpp:131] Top shape: 1 36 (36)
I0109 18:13:12.369810 32941 net.cpp:131] Top shape: 1 36 (36)
I0109 18:13:12.369815 32941 net.cpp:139] Memory required for data: 1423271968
I0109 18:13:12.369822 32941 layer_factory.hpp:77] Creating layer roi_pool5
I0109 18:13:12.369840 32941 net.cpp:86] Creating Layer roi_pool5
I0109 18:13:12.369848 32941 net.cpp:408] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0109 18:13:12.369855 32941 net.cpp:408] roi_pool5 <- rois
I0109 18:13:12.369865 32941 net.cpp:382] roi_pool5 -> pool5
I0109 18:13:12.369877 32941 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0109 18:13:12.369946 32941 net.cpp:124] Setting up roi_pool5
I0109 18:13:12.369958 32941 net.cpp:131] Top shape: 1 512 7 7 (25088)
I0109 18:13:12.369964 32941 net.cpp:139] Memory required for data: 1423372320
I0109 18:13:12.369971 32941 layer_factory.hpp:77] Creating layer fc6
I0109 18:13:12.369982 32941 net.cpp:86] Creating Layer fc6
I0109 18:13:12.369988 32941 net.cpp:408] fc6 <- pool5
I0109 18:13:12.369999 32941 net.cpp:382] fc6 -> fc6
I0109 18:13:12.749799 32941 net.cpp:124] Setting up fc6
I0109 18:13:12.749837 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.749841 32941 net.cpp:139] Memory required for data: 1423388704
I0109 18:13:12.749864 32941 layer_factory.hpp:77] Creating layer relu6
I0109 18:13:12.749876 32941 net.cpp:86] Creating Layer relu6
I0109 18:13:12.749881 32941 net.cpp:408] relu6 <- fc6
I0109 18:13:12.749888 32941 net.cpp:369] relu6 -> fc6 (in-place)
I0109 18:13:12.750339 32941 net.cpp:124] Setting up relu6
I0109 18:13:12.750352 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.750356 32941 net.cpp:139] Memory required for data: 1423405088
I0109 18:13:12.750360 32941 layer_factory.hpp:77] Creating layer drop6
I0109 18:13:12.750376 32941 net.cpp:86] Creating Layer drop6
I0109 18:13:12.750381 32941 net.cpp:408] drop6 <- fc6
I0109 18:13:12.750386 32941 net.cpp:369] drop6 -> fc6 (in-place)
I0109 18:13:12.750416 32941 net.cpp:124] Setting up drop6
I0109 18:13:12.750423 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.750427 32941 net.cpp:139] Memory required for data: 1423421472
I0109 18:13:12.750430 32941 layer_factory.hpp:77] Creating layer fc7
I0109 18:13:12.750438 32941 net.cpp:86] Creating Layer fc7
I0109 18:13:12.750442 32941 net.cpp:408] fc7 <- fc6
I0109 18:13:12.750455 32941 net.cpp:382] fc7 -> fc7
I0109 18:13:12.813083 32941 net.cpp:124] Setting up fc7
I0109 18:13:12.813130 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.813135 32941 net.cpp:139] Memory required for data: 1423437856
I0109 18:13:12.813149 32941 layer_factory.hpp:77] Creating layer relu7
I0109 18:13:12.813164 32941 net.cpp:86] Creating Layer relu7
I0109 18:13:12.813171 32941 net.cpp:408] relu7 <- fc7
I0109 18:13:12.813184 32941 net.cpp:369] relu7 -> fc7 (in-place)
I0109 18:13:12.815951 32941 net.cpp:124] Setting up relu7
I0109 18:13:12.815984 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.815989 32941 net.cpp:139] Memory required for data: 1423454240
I0109 18:13:12.815994 32941 layer_factory.hpp:77] Creating layer drop7
I0109 18:13:12.816006 32941 net.cpp:86] Creating Layer drop7
I0109 18:13:12.816011 32941 net.cpp:408] drop7 <- fc7
I0109 18:13:12.816018 32941 net.cpp:369] drop7 -> fc7 (in-place)
I0109 18:13:12.816056 32941 net.cpp:124] Setting up drop7
I0109 18:13:12.816062 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.816066 32941 net.cpp:139] Memory required for data: 1423470624
I0109 18:13:12.816071 32941 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0109 18:13:12.816078 32941 net.cpp:86] Creating Layer fc7_drop7_0_split
I0109 18:13:12.816083 32941 net.cpp:408] fc7_drop7_0_split <- fc7
I0109 18:13:12.816092 32941 net.cpp:382] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0109 18:13:12.816100 32941 net.cpp:382] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0109 18:13:12.816140 32941 net.cpp:124] Setting up fc7_drop7_0_split
I0109 18:13:12.816156 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.816161 32941 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:13:12.816165 32941 net.cpp:139] Memory required for data: 1423503392
I0109 18:13:12.816169 32941 layer_factory.hpp:77] Creating layer cls_score
I0109 18:13:12.816180 32941 net.cpp:86] Creating Layer cls_score
I0109 18:13:12.816185 32941 net.cpp:408] cls_score <- fc7_drop7_0_split_0
I0109 18:13:12.816195 32941 net.cpp:382] cls_score -> cls_score
I0109 18:13:12.816792 32941 net.cpp:124] Setting up cls_score
I0109 18:13:12.816803 32941 net.cpp:131] Top shape: 1 9 (9)
I0109 18:13:12.816812 32941 net.cpp:139] Memory required for data: 1423503428
I0109 18:13:12.816819 32941 layer_factory.hpp:77] Creating layer bbox_pred
I0109 18:13:12.816829 32941 net.cpp:86] Creating Layer bbox_pred
I0109 18:13:12.816833 32941 net.cpp:408] bbox_pred <- fc7_drop7_0_split_1
I0109 18:13:12.816840 32941 net.cpp:382] bbox_pred -> bbox_pred
I0109 18:13:12.818842 32941 net.cpp:124] Setting up bbox_pred
I0109 18:13:12.818856 32941 net.cpp:131] Top shape: 1 36 (36)
I0109 18:13:12.818859 32941 net.cpp:139] Memory required for data: 1423503572
I0109 18:13:12.818867 32941 layer_factory.hpp:77] Creating layer loss_cls
I0109 18:13:12.818876 32941 net.cpp:86] Creating Layer loss_cls
I0109 18:13:12.818879 32941 net.cpp:408] loss_cls <- cls_score
I0109 18:13:12.818886 32941 net.cpp:408] loss_cls <- labels
I0109 18:13:12.818892 32941 net.cpp:382] loss_cls -> loss_cls
I0109 18:13:12.818908 32941 layer_factory.hpp:77] Creating layer loss_cls
I0109 18:13:12.819717 32941 net.cpp:124] Setting up loss_cls
I0109 18:13:12.819734 32941 net.cpp:131] Top shape: (1)
I0109 18:13:12.819738 32941 net.cpp:134]     with loss weight 1
I0109 18:13:12.819751 32941 net.cpp:139] Memory required for data: 1423503576
I0109 18:13:12.819754 32941 layer_factory.hpp:77] Creating layer loss_bbox
I0109 18:13:12.819766 32941 net.cpp:86] Creating Layer loss_bbox
I0109 18:13:12.819772 32941 net.cpp:408] loss_bbox <- bbox_pred
I0109 18:13:12.819777 32941 net.cpp:408] loss_bbox <- bbox_targets
I0109 18:13:12.819782 32941 net.cpp:408] loss_bbox <- bbox_inside_weights
I0109 18:13:12.819787 32941 net.cpp:408] loss_bbox <- bbox_outside_weights
I0109 18:13:12.819795 32941 net.cpp:382] loss_bbox -> loss_bbox
I0109 18:13:12.819885 32941 net.cpp:124] Setting up loss_bbox
I0109 18:13:12.819897 32941 net.cpp:131] Top shape: (1)
I0109 18:13:12.819901 32941 net.cpp:134]     with loss weight 1
I0109 18:13:12.819907 32941 net.cpp:139] Memory required for data: 1423503580
I0109 18:13:12.819912 32941 net.cpp:200] loss_bbox needs backward computation.
I0109 18:13:12.819917 32941 net.cpp:200] loss_cls needs backward computation.
I0109 18:13:12.819922 32941 net.cpp:200] bbox_pred needs backward computation.
I0109 18:13:12.819926 32941 net.cpp:200] cls_score needs backward computation.
I0109 18:13:12.819931 32941 net.cpp:200] fc7_drop7_0_split needs backward computation.
I0109 18:13:12.819936 32941 net.cpp:200] drop7 needs backward computation.
I0109 18:13:12.819938 32941 net.cpp:200] relu7 needs backward computation.
I0109 18:13:12.819942 32941 net.cpp:200] fc7 needs backward computation.
I0109 18:13:12.819947 32941 net.cpp:200] drop6 needs backward computation.
I0109 18:13:12.819952 32941 net.cpp:200] relu6 needs backward computation.
I0109 18:13:12.819954 32941 net.cpp:200] fc6 needs backward computation.
I0109 18:13:12.819959 32941 net.cpp:200] roi_pool5 needs backward computation.
I0109 18:13:12.819964 32941 net.cpp:200] roi-data needs backward computation.
I0109 18:13:12.819968 32941 net.cpp:200] proposal needs backward computation.
I0109 18:13:12.819975 32941 net.cpp:200] rpn_cls_prob_reshape needs backward computation.
I0109 18:13:12.819979 32941 net.cpp:200] rpn_cls_prob needs backward computation.
I0109 18:13:12.819984 32941 net.cpp:200] rpn_loss_bbox needs backward computation.
I0109 18:13:12.819993 32941 net.cpp:200] rpn_loss_cls needs backward computation.
I0109 18:13:12.819998 32941 net.cpp:200] rpn-data needs backward computation.
I0109 18:13:12.820005 32941 net.cpp:200] rpn_cls_score_reshape_rpn_cls_score_reshape_0_split needs backward computation.
I0109 18:13:12.820010 32941 net.cpp:200] rpn_cls_score_reshape needs backward computation.
I0109 18:13:12.820015 32941 net.cpp:200] rpn_bbox_pred_rpn_bbox_pred_0_split needs backward computation.
I0109 18:13:12.820019 32941 net.cpp:200] rpn_bbox_pred needs backward computation.
I0109 18:13:12.820026 32941 net.cpp:200] rpn_cls_score_rpn_cls_score_0_split needs backward computation.
I0109 18:13:12.820031 32941 net.cpp:200] rpn_cls_score needs backward computation.
I0109 18:13:12.820036 32941 net.cpp:200] rpn/output_rpn_relu/3x3_0_split needs backward computation.
I0109 18:13:12.820041 32941 net.cpp:200] rpn_relu/3x3 needs backward computation.
I0109 18:13:12.820045 32941 net.cpp:200] rpn_conv/3x3 needs backward computation.
I0109 18:13:12.820050 32941 net.cpp:200] conv5_3_relu5_3_0_split needs backward computation.
I0109 18:13:12.820055 32941 net.cpp:200] relu5_3 needs backward computation.
I0109 18:13:12.820060 32941 net.cpp:200] conv5_3 needs backward computation.
I0109 18:13:12.820065 32941 net.cpp:200] relu5_2 needs backward computation.
I0109 18:13:12.820068 32941 net.cpp:200] conv5_2 needs backward computation.
I0109 18:13:12.820072 32941 net.cpp:200] relu5_1 needs backward computation.
I0109 18:13:12.820076 32941 net.cpp:200] conv5_1 needs backward computation.
I0109 18:13:12.820080 32941 net.cpp:200] pool4 needs backward computation.
I0109 18:13:12.820086 32941 net.cpp:200] relu4_3 needs backward computation.
I0109 18:13:12.820089 32941 net.cpp:200] conv4_3 needs backward computation.
I0109 18:13:12.820093 32941 net.cpp:200] relu4_2 needs backward computation.
I0109 18:13:12.820097 32941 net.cpp:200] conv4_2 needs backward computation.
I0109 18:13:12.820101 32941 net.cpp:200] relu4_1 needs backward computation.
I0109 18:13:12.820106 32941 net.cpp:200] conv4_1 needs backward computation.
I0109 18:13:12.820111 32941 net.cpp:200] pool3 needs backward computation.
I0109 18:13:12.820114 32941 net.cpp:200] relu3_3 needs backward computation.
I0109 18:13:12.820118 32941 net.cpp:200] conv3_3 needs backward computation.
I0109 18:13:12.820122 32941 net.cpp:200] relu3_2 needs backward computation.
I0109 18:13:12.820127 32941 net.cpp:200] conv3_2 needs backward computation.
I0109 18:13:12.820132 32941 net.cpp:200] relu3_1 needs backward computation.
I0109 18:13:12.820135 32941 net.cpp:200] conv3_1 needs backward computation.
I0109 18:13:12.820139 32941 net.cpp:202] pool2 does not need backward computation.
I0109 18:13:12.820144 32941 net.cpp:202] relu2_2 does not need backward computation.
I0109 18:13:12.820148 32941 net.cpp:202] conv2_2 does not need backward computation.
I0109 18:13:12.820153 32941 net.cpp:202] relu2_1 does not need backward computation.
I0109 18:13:12.820158 32941 net.cpp:202] conv2_1 does not need backward computation.
I0109 18:13:12.820163 32941 net.cpp:202] pool1 does not need backward computation.
I0109 18:13:12.820166 32941 net.cpp:202] relu1_2 does not need backward computation.
I0109 18:13:12.820171 32941 net.cpp:202] conv1_2 does not need backward computation.
I0109 18:13:12.820175 32941 net.cpp:202] relu1_1 does not need backward computation.
I0109 18:13:12.820179 32941 net.cpp:202] conv1_1 does not need backward computation.
I0109 18:13:12.820188 32941 net.cpp:202] gt_boxes_input-data_2_split does not need backward computation.
I0109 18:13:12.820194 32941 net.cpp:202] im_info_input-data_1_split does not need backward computation.
I0109 18:13:12.820200 32941 net.cpp:202] data_input-data_0_split does not need backward computation.
I0109 18:13:12.820205 32941 net.cpp:202] input-data does not need backward computation.
I0109 18:13:12.820209 32941 net.cpp:244] This network produces output loss_bbox
I0109 18:13:12.820214 32941 net.cpp:244] This network produces output loss_cls
I0109 18:13:12.820219 32941 net.cpp:244] This network produces output rpn_cls_loss
I0109 18:13:12.820224 32941 net.cpp:244] This network produces output rpn_loss_bbox
I0109 18:13:12.820282 32941 net.cpp:257] Network initialization done.
I0109 18:13:12.820504 32941 solver.cpp:57] Solver scaffolding done.
Loading pretrained model weights from data/imagenet_models/VGG16.v2.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 553432430
I0109 18:13:13.564215 32941 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: data/imagenet_models/VGG16.v2.caffemodel
I0109 18:13:13.564236 32941 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.
W0109 18:13:13.564240 32941 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.
I0109 18:13:13.576383 32941 net.cpp:746] Ignoring source layer pool5
I0109 18:13:13.673702 32941 net.cpp:746] Ignoring source layer fc8
I0109 18:13:13.673729 32941 net.cpp:746] Ignoring source layer prob
Solving...
I0109 18:13:14.304369 32941 solver.cpp:239] Iteration 0 (0 iter/s, 0.594001s/20 iters), loss = 3.73448
I0109 18:13:14.304435 32941 solver.cpp:258]     Train net output #0: loss_bbox = 9.80957e-05 (* 1 = 9.80957e-05 loss)
I0109 18:13:14.304445 32941 solver.cpp:258]     Train net output #1: loss_cls = 2.70708 (* 1 = 2.70708 loss)
I0109 18:13:14.304452 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.792877 (* 1 = 0.792877 loss)
I0109 18:13:14.304459 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0586466 (* 1 = 0.0586466 loss)
I0109 18:13:14.304467 32941 sgd_solver.cpp:112] Iteration 0, lr = 0.001
I0109 18:13:21.627707 32941 solver.cpp:239] Iteration 20 (2.73111 iter/s, 7.32302s/20 iters), loss = 0.794145
I0109 18:13:21.627774 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.15176 (* 1 = 0.15176 loss)
I0109 18:13:21.627784 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.195287 (* 1 = 0.195287 loss)
I0109 18:13:21.627790 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.078568 (* 1 = 0.078568 loss)
I0109 18:13:21.627797 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0179593 (* 1 = 0.0179593 loss)
I0109 18:13:21.627805 32941 sgd_solver.cpp:112] Iteration 20, lr = 0.001
I0109 18:13:28.989301 32941 solver.cpp:239] Iteration 40 (2.71692 iter/s, 7.36127s/20 iters), loss = 0.234495
I0109 18:13:28.989361 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0472649 (* 1 = 0.0472649 loss)
I0109 18:13:28.989372 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0784125 (* 1 = 0.0784125 loss)
I0109 18:13:28.989378 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0396102 (* 1 = 0.0396102 loss)
I0109 18:13:28.989387 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00769018 (* 1 = 0.00769018 loss)
I0109 18:13:28.989394 32941 sgd_solver.cpp:112] Iteration 40, lr = 0.001
I0109 18:13:36.232933 32941 solver.cpp:239] Iteration 60 (2.76117 iter/s, 7.2433s/20 iters), loss = 0.840747
I0109 18:13:36.233000 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.204237 (* 1 = 0.204237 loss)
I0109 18:13:36.233011 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.32167 (* 1 = 0.32167 loss)
I0109 18:13:36.233017 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.161351 (* 1 = 0.161351 loss)
I0109 18:13:36.233023 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.155026 (* 1 = 0.155026 loss)
I0109 18:13:36.233031 32941 sgd_solver.cpp:112] Iteration 60, lr = 0.001
I0109 18:13:43.420751 32941 solver.cpp:239] Iteration 80 (2.78261 iter/s, 7.18749s/20 iters), loss = 0.794393
I0109 18:13:43.420814 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.493467 (* 1 = 0.493467 loss)
I0109 18:13:43.420822 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.435084 (* 1 = 0.435084 loss)
I0109 18:13:43.420830 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.079709 (* 1 = 0.079709 loss)
I0109 18:13:43.420836 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00782608 (* 1 = 0.00782608 loss)
I0109 18:13:43.420845 32941 sgd_solver.cpp:112] Iteration 80, lr = 0.001
I0109 18:13:50.762468 32941 solver.cpp:239] Iteration 100 (2.72428 iter/s, 7.34139s/20 iters), loss = 1.43024
I0109 18:13:50.762542 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.27962 (* 1 = 0.27962 loss)
I0109 18:13:50.762552 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.726104 (* 1 = 0.726104 loss)
I0109 18:13:50.762559 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.495516 (* 1 = 0.495516 loss)
I0109 18:13:50.762567 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0507874 (* 1 = 0.0507874 loss)
I0109 18:13:50.762573 32941 sgd_solver.cpp:112] Iteration 100, lr = 0.001
I0109 18:13:58.016361 32941 solver.cpp:239] Iteration 120 (2.75727 iter/s, 7.25356s/20 iters), loss = 1.10297
I0109 18:13:58.016434 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.458566 (* 1 = 0.458566 loss)
I0109 18:13:58.016443 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.247217 (* 1 = 0.247217 loss)
I0109 18:13:58.016449 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.217084 (* 1 = 0.217084 loss)
I0109 18:13:58.016455 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.13558 (* 1 = 0.13558 loss)
I0109 18:13:58.016463 32941 sgd_solver.cpp:112] Iteration 120, lr = 0.001
I0109 18:14:05.394038 32941 solver.cpp:239] Iteration 140 (2.711 iter/s, 7.37734s/20 iters), loss = 0.878803
I0109 18:14:05.394107 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.311369 (* 1 = 0.311369 loss)
I0109 18:14:05.394119 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.441591 (* 1 = 0.441591 loss)
I0109 18:14:05.394125 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.133862 (* 1 = 0.133862 loss)
I0109 18:14:05.394132 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0479644 (* 1 = 0.0479644 loss)
I0109 18:14:05.394140 32941 sgd_solver.cpp:112] Iteration 140, lr = 0.001
I0109 18:14:13.016983 32941 solver.cpp:239] Iteration 160 (2.62378 iter/s, 7.62259s/20 iters), loss = 0.511658
I0109 18:14:13.017053 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.179351 (* 1 = 0.179351 loss)
I0109 18:14:13.017066 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.297972 (* 1 = 0.297972 loss)
I0109 18:14:13.017074 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0489258 (* 1 = 0.0489258 loss)
I0109 18:14:13.017081 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00414219 (* 1 = 0.00414219 loss)
I0109 18:14:13.017089 32941 sgd_solver.cpp:112] Iteration 160, lr = 0.001
I0109 18:14:20.778807 32941 solver.cpp:239] Iteration 180 (2.57683 iter/s, 7.76148s/20 iters), loss = 0.521425
I0109 18:14:20.778883 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.119977 (* 1 = 0.119977 loss)
I0109 18:14:20.778892 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0982942 (* 1 = 0.0982942 loss)
I0109 18:14:20.778899 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0256082 (* 1 = 0.0256082 loss)
I0109 18:14:20.778905 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.023194 (* 1 = 0.023194 loss)
I0109 18:14:20.778914 32941 sgd_solver.cpp:112] Iteration 180, lr = 0.001
speed: 0.371s / iter
I0109 18:14:28.353530 32941 solver.cpp:239] Iteration 200 (2.64048 iter/s, 7.57437s/20 iters), loss = 0.462866
I0109 18:14:28.353600 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.171729 (* 1 = 0.171729 loss)
I0109 18:14:28.353610 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.220507 (* 1 = 0.220507 loss)
I0109 18:14:28.353617 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.109593 (* 1 = 0.109593 loss)
I0109 18:14:28.353623 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.029833 (* 1 = 0.029833 loss)
I0109 18:14:28.353631 32941 sgd_solver.cpp:112] Iteration 200, lr = 0.001
I0109 18:14:35.891754 32941 solver.cpp:239] Iteration 220 (2.65326 iter/s, 7.53788s/20 iters), loss = 0.500672
I0109 18:14:35.891829 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.403429 (* 1 = 0.403429 loss)
I0109 18:14:35.891839 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.305138 (* 1 = 0.305138 loss)
I0109 18:14:35.891845 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0630619 (* 1 = 0.0630619 loss)
I0109 18:14:35.891854 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00517995 (* 1 = 0.00517995 loss)
I0109 18:14:35.891861 32941 sgd_solver.cpp:112] Iteration 220, lr = 0.001
I0109 18:14:43.513851 32941 solver.cpp:239] Iteration 240 (2.62407 iter/s, 7.62175s/20 iters), loss = 0.654145
I0109 18:14:43.513917 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.417751 (* 1 = 0.417751 loss)
I0109 18:14:43.513927 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.517865 (* 1 = 0.517865 loss)
I0109 18:14:43.513934 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0925948 (* 1 = 0.0925948 loss)
I0109 18:14:43.513942 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.060927 (* 1 = 0.060927 loss)
I0109 18:14:43.513949 32941 sgd_solver.cpp:112] Iteration 240, lr = 0.001
I0109 18:14:50.963304 32941 solver.cpp:239] Iteration 260 (2.68488 iter/s, 7.44912s/20 iters), loss = 0.661814
I0109 18:14:50.963363 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.475992 (* 1 = 0.475992 loss)
I0109 18:14:50.963373 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.316496 (* 1 = 0.316496 loss)
I0109 18:14:50.963380 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0620516 (* 1 = 0.0620516 loss)
I0109 18:14:50.963387 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0155774 (* 1 = 0.0155774 loss)
I0109 18:14:50.963394 32941 sgd_solver.cpp:112] Iteration 260, lr = 0.001
I0109 18:14:58.561354 32941 solver.cpp:239] Iteration 280 (2.63237 iter/s, 7.59772s/20 iters), loss = 0.312039
I0109 18:14:58.561415 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.122761 (* 1 = 0.122761 loss)
I0109 18:14:58.561424 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.103591 (* 1 = 0.103591 loss)
I0109 18:14:58.561431 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0758719 (* 1 = 0.0758719 loss)
I0109 18:14:58.561439 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0249606 (* 1 = 0.0249606 loss)
I0109 18:14:58.561446 32941 sgd_solver.cpp:112] Iteration 280, lr = 0.001
I0109 18:15:06.197454 32941 solver.cpp:239] Iteration 300 (2.61925 iter/s, 7.63577s/20 iters), loss = 0.592485
I0109 18:15:06.197517 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.37116 (* 1 = 0.37116 loss)
I0109 18:15:06.197526 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.27427 (* 1 = 0.27427 loss)
I0109 18:15:06.197533 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0685131 (* 1 = 0.0685131 loss)
I0109 18:15:06.197540 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0086519 (* 1 = 0.0086519 loss)
I0109 18:15:06.197548 32941 sgd_solver.cpp:112] Iteration 300, lr = 0.001
I0109 18:15:13.749687 32941 solver.cpp:239] Iteration 320 (2.64834 iter/s, 7.5519s/20 iters), loss = 0.744654
I0109 18:15:13.749752 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.171213 (* 1 = 0.171213 loss)
I0109 18:15:13.749761 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.223502 (* 1 = 0.223502 loss)
I0109 18:15:13.749769 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0542012 (* 1 = 0.0542012 loss)
I0109 18:15:13.749776 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0236978 (* 1 = 0.0236978 loss)
I0109 18:15:13.749783 32941 sgd_solver.cpp:112] Iteration 320, lr = 0.001
I0109 18:15:21.505120 32941 solver.cpp:239] Iteration 340 (2.57895 iter/s, 7.75509s/20 iters), loss = 0.416118
I0109 18:15:21.505183 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.11855 (* 1 = 0.11855 loss)
I0109 18:15:21.505193 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.133235 (* 1 = 0.133235 loss)
I0109 18:15:21.505200 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0422647 (* 1 = 0.0422647 loss)
I0109 18:15:21.505206 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00589245 (* 1 = 0.00589245 loss)
I0109 18:15:21.505215 32941 sgd_solver.cpp:112] Iteration 340, lr = 0.001
I0109 18:15:29.429643 32941 solver.cpp:239] Iteration 360 (2.52392 iter/s, 7.92418s/20 iters), loss = 0.267652
I0109 18:15:29.429702 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.034779 (* 1 = 0.034779 loss)
I0109 18:15:29.429711 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.118947 (* 1 = 0.118947 loss)
I0109 18:15:29.429718 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0386351 (* 1 = 0.0386351 loss)
I0109 18:15:29.429725 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0132404 (* 1 = 0.0132404 loss)
I0109 18:15:29.429733 32941 sgd_solver.cpp:112] Iteration 360, lr = 0.001
I0109 18:15:37.021091 32941 solver.cpp:239] Iteration 380 (2.63465 iter/s, 7.59113s/20 iters), loss = 0.689399
I0109 18:15:37.021157 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.285848 (* 1 = 0.285848 loss)
I0109 18:15:37.021165 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.351986 (* 1 = 0.351986 loss)
I0109 18:15:37.021173 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0839454 (* 1 = 0.0839454 loss)
I0109 18:15:37.021183 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0131837 (* 1 = 0.0131837 loss)
I0109 18:15:37.021189 32941 sgd_solver.cpp:112] Iteration 380, lr = 0.001
speed: 0.377s / iter
I0109 18:15:44.815663 32941 solver.cpp:239] Iteration 400 (2.566 iter/s, 7.79422s/20 iters), loss = 0.630445
I0109 18:15:44.815722 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.22999 (* 1 = 0.22999 loss)
I0109 18:15:44.815732 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.140262 (* 1 = 0.140262 loss)
I0109 18:15:44.815738 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0329493 (* 1 = 0.0329493 loss)
I0109 18:15:44.815744 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00809824 (* 1 = 0.00809824 loss)
I0109 18:15:44.815752 32941 sgd_solver.cpp:112] Iteration 400, lr = 0.001
I0109 18:15:52.611106 32941 solver.cpp:239] Iteration 420 (2.56571 iter/s, 7.79512s/20 iters), loss = 0.4203
I0109 18:15:52.611162 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0405974 (* 1 = 0.0405974 loss)
I0109 18:15:52.611171 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.188106 (* 1 = 0.188106 loss)
I0109 18:15:52.611178 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0144887 (* 1 = 0.0144887 loss)
I0109 18:15:52.611184 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0243871 (* 1 = 0.0243871 loss)
I0109 18:15:52.611193 32941 sgd_solver.cpp:112] Iteration 420, lr = 0.001
I0109 18:16:00.358578 32941 solver.cpp:239] Iteration 440 (2.5816 iter/s, 7.74714s/20 iters), loss = 0.637719
I0109 18:16:00.358654 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.302204 (* 1 = 0.302204 loss)
I0109 18:16:00.358662 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.641694 (* 1 = 0.641694 loss)
I0109 18:16:00.358669 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0406052 (* 1 = 0.0406052 loss)
I0109 18:16:00.358675 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0188094 (* 1 = 0.0188094 loss)
I0109 18:16:00.358683 32941 sgd_solver.cpp:112] Iteration 440, lr = 0.001
I0109 18:16:08.150342 32941 solver.cpp:239] Iteration 460 (2.56692 iter/s, 7.79143s/20 iters), loss = 0.648511
I0109 18:16:08.150403 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.195177 (* 1 = 0.195177 loss)
I0109 18:16:08.150410 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.506839 (* 1 = 0.506839 loss)
I0109 18:16:08.150418 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0144589 (* 1 = 0.0144589 loss)
I0109 18:16:08.150425 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00156637 (* 1 = 0.00156637 loss)
I0109 18:16:08.150432 32941 sgd_solver.cpp:112] Iteration 460, lr = 0.001
I0109 18:16:15.879365 32941 solver.cpp:239] Iteration 480 (2.58776 iter/s, 7.7287s/20 iters), loss = 0.223516
I0109 18:16:15.879421 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.106386 (* 1 = 0.106386 loss)
I0109 18:16:15.879431 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.08553 (* 1 = 0.08553 loss)
I0109 18:16:15.879436 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0152545 (* 1 = 0.0152545 loss)
I0109 18:16:15.879443 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00722363 (* 1 = 0.00722363 loss)
I0109 18:16:15.879449 32941 sgd_solver.cpp:112] Iteration 480, lr = 0.001
I0109 18:16:23.634398 32941 solver.cpp:239] Iteration 500 (2.57908 iter/s, 7.75471s/20 iters), loss = 0.818734
I0109 18:16:23.634461 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.327106 (* 1 = 0.327106 loss)
I0109 18:16:23.634470 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.372156 (* 1 = 0.372156 loss)
I0109 18:16:23.634477 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0858516 (* 1 = 0.0858516 loss)
I0109 18:16:23.634485 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0575291 (* 1 = 0.0575291 loss)
I0109 18:16:23.634493 32941 sgd_solver.cpp:112] Iteration 500, lr = 0.001
I0109 18:16:31.134153 32941 solver.cpp:239] Iteration 520 (2.66687 iter/s, 7.49943s/20 iters), loss = 0.795013
I0109 18:16:31.134217 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.286593 (* 1 = 0.286593 loss)
I0109 18:16:31.134225 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.330874 (* 1 = 0.330874 loss)
I0109 18:16:31.134232 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.140802 (* 1 = 0.140802 loss)
I0109 18:16:31.134238 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0305908 (* 1 = 0.0305908 loss)
I0109 18:16:31.134246 32941 sgd_solver.cpp:112] Iteration 520, lr = 0.001
I0109 18:16:38.879983 32941 solver.cpp:239] Iteration 540 (2.58214 iter/s, 7.7455s/20 iters), loss = 0.55713
I0109 18:16:38.880059 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.162164 (* 1 = 0.162164 loss)
I0109 18:16:38.880067 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0695153 (* 1 = 0.0695153 loss)
I0109 18:16:38.880074 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0774496 (* 1 = 0.0774496 loss)
I0109 18:16:38.880081 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0100193 (* 1 = 0.0100193 loss)
I0109 18:16:38.880089 32941 sgd_solver.cpp:112] Iteration 540, lr = 0.001
I0109 18:16:46.441458 32941 solver.cpp:239] Iteration 560 (2.6451 iter/s, 7.56115s/20 iters), loss = 0.573164
I0109 18:16:46.441525 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.5091 (* 1 = 0.5091 loss)
I0109 18:16:46.441534 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.22743 (* 1 = 0.22743 loss)
I0109 18:16:46.441541 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0691322 (* 1 = 0.0691322 loss)
I0109 18:16:46.441547 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0372255 (* 1 = 0.0372255 loss)
I0109 18:16:46.441555 32941 sgd_solver.cpp:112] Iteration 560, lr = 0.001
I0109 18:16:53.915788 32941 solver.cpp:239] Iteration 580 (2.67594 iter/s, 7.474s/20 iters), loss = 0.472172
I0109 18:16:53.915863 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.185471 (* 1 = 0.185471 loss)
I0109 18:16:53.915871 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.174978 (* 1 = 0.174978 loss)
I0109 18:16:53.915879 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.121907 (* 1 = 0.121907 loss)
I0109 18:16:53.915886 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.154391 (* 1 = 0.154391 loss)
I0109 18:16:53.915894 32941 sgd_solver.cpp:112] Iteration 580, lr = 0.001
speed: 0.379s / iter
I0109 18:17:01.665304 32941 solver.cpp:239] Iteration 600 (2.58092 iter/s, 7.74918s/20 iters), loss = 0.660367
I0109 18:17:01.665367 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.220612 (* 1 = 0.220612 loss)
I0109 18:17:01.665382 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.193679 (* 1 = 0.193679 loss)
I0109 18:17:01.665390 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0298949 (* 1 = 0.0298949 loss)
I0109 18:17:01.665396 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0452818 (* 1 = 0.0452818 loss)
I0109 18:17:01.665405 32941 sgd_solver.cpp:112] Iteration 600, lr = 0.001
I0109 18:17:09.086956 32941 solver.cpp:239] Iteration 620 (2.69493 iter/s, 7.42133s/20 iters), loss = 0.351697
I0109 18:17:09.087028 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.186612 (* 1 = 0.186612 loss)
I0109 18:17:09.087044 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.105335 (* 1 = 0.105335 loss)
I0109 18:17:09.087055 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0712064 (* 1 = 0.0712064 loss)
I0109 18:17:09.087065 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0040499 (* 1 = 0.0040499 loss)
I0109 18:17:09.087077 32941 sgd_solver.cpp:112] Iteration 620, lr = 0.001
I0109 18:17:16.768477 32941 solver.cpp:239] Iteration 640 (2.60376 iter/s, 7.68119s/20 iters), loss = 0.712761
I0109 18:17:16.768550 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.524222 (* 1 = 0.524222 loss)
I0109 18:17:16.768566 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.446923 (* 1 = 0.446923 loss)
I0109 18:17:16.768576 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.131688 (* 1 = 0.131688 loss)
I0109 18:17:16.768587 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0230945 (* 1 = 0.0230945 loss)
I0109 18:17:16.768605 32941 sgd_solver.cpp:112] Iteration 640, lr = 0.001
I0109 18:17:24.428925 32941 solver.cpp:239] Iteration 660 (2.61093 iter/s, 7.6601s/20 iters), loss = 0.744018
I0109 18:17:24.429044 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.372554 (* 1 = 0.372554 loss)
I0109 18:17:24.429060 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.529264 (* 1 = 0.529264 loss)
I0109 18:17:24.429072 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0616555 (* 1 = 0.0616555 loss)
I0109 18:17:24.429085 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0174595 (* 1 = 0.0174595 loss)
I0109 18:17:24.429096 32941 sgd_solver.cpp:112] Iteration 660, lr = 0.001
I0109 18:17:32.121644 32941 solver.cpp:239] Iteration 680 (2.59998 iter/s, 7.69235s/20 iters), loss = 0.443014
I0109 18:17:32.121709 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.35281 (* 1 = 0.35281 loss)
I0109 18:17:32.121718 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.301388 (* 1 = 0.301388 loss)
I0109 18:17:32.121726 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0452563 (* 1 = 0.0452563 loss)
I0109 18:17:32.121732 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0214287 (* 1 = 0.0214287 loss)
I0109 18:17:32.121739 32941 sgd_solver.cpp:112] Iteration 680, lr = 0.001
I0109 18:17:39.672142 32941 solver.cpp:239] Iteration 700 (2.64894 iter/s, 7.55018s/20 iters), loss = 0.645964
I0109 18:17:39.672202 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.323376 (* 1 = 0.323376 loss)
I0109 18:17:39.672212 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.520054 (* 1 = 0.520054 loss)
I0109 18:17:39.672219 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0141526 (* 1 = 0.0141526 loss)
I0109 18:17:39.672226 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0027015 (* 1 = 0.0027015 loss)
I0109 18:17:39.672235 32941 sgd_solver.cpp:112] Iteration 700, lr = 0.001
I0109 18:17:47.630453 32941 solver.cpp:239] Iteration 720 (2.5132 iter/s, 7.95797s/20 iters), loss = 0.414901
I0109 18:17:47.630527 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.162438 (* 1 = 0.162438 loss)
I0109 18:17:47.630537 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.228901 (* 1 = 0.228901 loss)
I0109 18:17:47.630544 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.02539 (* 1 = 0.02539 loss)
I0109 18:17:47.630550 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.016433 (* 1 = 0.016433 loss)
I0109 18:17:47.630558 32941 sgd_solver.cpp:112] Iteration 720, lr = 0.001
I0109 18:17:55.357405 32941 solver.cpp:239] Iteration 740 (2.58845 iter/s, 7.72662s/20 iters), loss = 0.422313
I0109 18:17:55.357470 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.206303 (* 1 = 0.206303 loss)
I0109 18:17:55.357481 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.193154 (* 1 = 0.193154 loss)
I0109 18:17:55.357489 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0585714 (* 1 = 0.0585714 loss)
I0109 18:17:55.357497 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0665811 (* 1 = 0.0665811 loss)
I0109 18:17:55.357506 32941 sgd_solver.cpp:112] Iteration 740, lr = 0.001
I0109 18:18:03.032109 32941 solver.cpp:239] Iteration 760 (2.60607 iter/s, 7.67439s/20 iters), loss = 0.15521
I0109 18:18:03.032167 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0573422 (* 1 = 0.0573422 loss)
I0109 18:18:03.032177 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0627064 (* 1 = 0.0627064 loss)
I0109 18:18:03.032183 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0201473 (* 1 = 0.0201473 loss)
I0109 18:18:03.032191 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00771217 (* 1 = 0.00771217 loss)
I0109 18:18:03.032196 32941 sgd_solver.cpp:112] Iteration 760, lr = 0.001
I0109 18:18:10.522886 32941 solver.cpp:239] Iteration 780 (2.67006 iter/s, 7.49047s/20 iters), loss = 0.496139
I0109 18:18:10.522948 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.372582 (* 1 = 0.372582 loss)
I0109 18:18:10.522959 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.135989 (* 1 = 0.135989 loss)
I0109 18:18:10.522969 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00605948 (* 1 = 0.00605948 loss)
I0109 18:18:10.522974 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00327914 (* 1 = 0.00327914 loss)
I0109 18:18:10.522991 32941 sgd_solver.cpp:112] Iteration 780, lr = 0.001
speed: 0.380s / iter
I0109 18:18:18.265926 32941 solver.cpp:239] Iteration 800 (2.58308 iter/s, 7.7427s/20 iters), loss = 0.356514
I0109 18:18:18.265992 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.136528 (* 1 = 0.136528 loss)
I0109 18:18:18.266002 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0714884 (* 1 = 0.0714884 loss)
I0109 18:18:18.266010 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0115663 (* 1 = 0.0115663 loss)
I0109 18:18:18.266016 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0147181 (* 1 = 0.0147181 loss)
I0109 18:18:18.266023 32941 sgd_solver.cpp:112] Iteration 800, lr = 0.001
I0109 18:18:25.952244 32941 solver.cpp:239] Iteration 820 (2.60214 iter/s, 7.68599s/20 iters), loss = 0.866518
I0109 18:18:25.952301 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116976 (* 1 = 0.116976 loss)
I0109 18:18:25.952311 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0602696 (* 1 = 0.0602696 loss)
I0109 18:18:25.952317 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0347686 (* 1 = 0.0347686 loss)
I0109 18:18:25.952324 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0590931 (* 1 = 0.0590931 loss)
I0109 18:18:25.952332 32941 sgd_solver.cpp:112] Iteration 820, lr = 0.001
I0109 18:18:33.536590 32941 solver.cpp:239] Iteration 840 (2.63712 iter/s, 7.58404s/20 iters), loss = 0.603718
I0109 18:18:33.536650 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.171233 (* 1 = 0.171233 loss)
I0109 18:18:33.536659 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.179135 (* 1 = 0.179135 loss)
I0109 18:18:33.536664 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.157351 (* 1 = 0.157351 loss)
I0109 18:18:33.536670 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.129594 (* 1 = 0.129594 loss)
I0109 18:18:33.536676 32941 sgd_solver.cpp:112] Iteration 840, lr = 0.001
I0109 18:18:41.262547 32941 solver.cpp:239] Iteration 860 (2.58879 iter/s, 7.72563s/20 iters), loss = 0.403232
I0109 18:18:41.262620 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.106021 (* 1 = 0.106021 loss)
I0109 18:18:41.262632 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.127327 (* 1 = 0.127327 loss)
I0109 18:18:41.262645 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.013486 (* 1 = 0.013486 loss)
I0109 18:18:41.262666 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00822979 (* 1 = 0.00822979 loss)
I0109 18:18:41.262679 32941 sgd_solver.cpp:112] Iteration 860, lr = 0.001
I0109 18:18:48.826267 32941 solver.cpp:239] Iteration 880 (2.64431 iter/s, 7.5634s/20 iters), loss = 0.298154
I0109 18:18:48.826331 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.24343 (* 1 = 0.24343 loss)
I0109 18:18:48.826341 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.169079 (* 1 = 0.169079 loss)
I0109 18:18:48.826349 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0421181 (* 1 = 0.0421181 loss)
I0109 18:18:48.826356 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00275897 (* 1 = 0.00275897 loss)
I0109 18:18:48.826365 32941 sgd_solver.cpp:112] Iteration 880, lr = 0.001
I0109 18:18:56.448508 32941 solver.cpp:239] Iteration 900 (2.62401 iter/s, 7.62192s/20 iters), loss = 0.337733
I0109 18:18:56.448571 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116727 (* 1 = 0.116727 loss)
I0109 18:18:56.448580 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.172878 (* 1 = 0.172878 loss)
I0109 18:18:56.448588 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0168703 (* 1 = 0.0168703 loss)
I0109 18:18:56.448596 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00351812 (* 1 = 0.00351812 loss)
I0109 18:18:56.448603 32941 sgd_solver.cpp:112] Iteration 900, lr = 0.001
I0109 18:19:03.949803 32941 solver.cpp:239] Iteration 920 (2.66632 iter/s, 7.50098s/20 iters), loss = 0.451752
I0109 18:19:03.949862 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0531896 (* 1 = 0.0531896 loss)
I0109 18:19:03.949872 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.198123 (* 1 = 0.198123 loss)
I0109 18:19:03.949889 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0465858 (* 1 = 0.0465858 loss)
I0109 18:19:03.949895 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0135065 (* 1 = 0.0135065 loss)
I0109 18:19:03.949903 32941 sgd_solver.cpp:112] Iteration 920, lr = 0.001
I0109 18:19:11.584233 32941 solver.cpp:239] Iteration 940 (2.61982 iter/s, 7.63411s/20 iters), loss = 0.467207
I0109 18:19:11.584308 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.275091 (* 1 = 0.275091 loss)
I0109 18:19:11.584318 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.146442 (* 1 = 0.146442 loss)
I0109 18:19:11.584326 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.101566 (* 1 = 0.101566 loss)
I0109 18:19:11.584332 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0416985 (* 1 = 0.0416985 loss)
I0109 18:19:11.584340 32941 sgd_solver.cpp:112] Iteration 940, lr = 0.001
I0109 18:19:19.260084 32941 solver.cpp:239] Iteration 960 (2.60569 iter/s, 7.67552s/20 iters), loss = 0.995294
I0109 18:19:19.260135 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.304982 (* 1 = 0.304982 loss)
I0109 18:19:19.260144 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.61473 (* 1 = 0.61473 loss)
I0109 18:19:19.260152 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.057949 (* 1 = 0.057949 loss)
I0109 18:19:19.260159 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0214588 (* 1 = 0.0214588 loss)
I0109 18:19:19.260165 32941 sgd_solver.cpp:112] Iteration 960, lr = 0.001
I0109 18:19:27.077208 32941 solver.cpp:239] Iteration 980 (2.55859 iter/s, 7.8168s/20 iters), loss = 0.833077
I0109 18:19:27.077268 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.248941 (* 1 = 0.248941 loss)
I0109 18:19:27.077277 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.335776 (* 1 = 0.335776 loss)
I0109 18:19:27.077284 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0367162 (* 1 = 0.0367162 loss)
I0109 18:19:27.077291 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0305498 (* 1 = 0.0305498 loss)
I0109 18:19:27.077299 32941 sgd_solver.cpp:112] Iteration 980, lr = 0.001
speed: 0.381s / iter
I0109 18:19:34.782323 32941 solver.cpp:239] Iteration 1000 (2.59579 iter/s, 7.70479s/20 iters), loss = 0.289791
I0109 18:19:34.782385 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.171187 (* 1 = 0.171187 loss)
I0109 18:19:34.782395 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0546585 (* 1 = 0.0546585 loss)
I0109 18:19:34.782402 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0748102 (* 1 = 0.0748102 loss)
I0109 18:19:34.782408 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0061642 (* 1 = 0.0061642 loss)
I0109 18:19:34.782416 32941 sgd_solver.cpp:112] Iteration 1000, lr = 0.001
I0109 18:19:42.416834 32941 solver.cpp:239] Iteration 1020 (2.61979 iter/s, 7.63419s/20 iters), loss = 0.723938
I0109 18:19:42.416904 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.378554 (* 1 = 0.378554 loss)
I0109 18:19:42.416913 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.699489 (* 1 = 0.699489 loss)
I0109 18:19:42.416920 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0232471 (* 1 = 0.0232471 loss)
I0109 18:19:42.416927 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00607672 (* 1 = 0.00607672 loss)
I0109 18:19:42.416934 32941 sgd_solver.cpp:112] Iteration 1020, lr = 0.001
I0109 18:19:49.852486 32941 solver.cpp:239] Iteration 1040 (2.68986 iter/s, 7.43533s/20 iters), loss = 0.162626
I0109 18:19:49.852553 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0671556 (* 1 = 0.0671556 loss)
I0109 18:19:49.852562 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0713591 (* 1 = 0.0713591 loss)
I0109 18:19:49.852569 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00872956 (* 1 = 0.00872956 loss)
I0109 18:19:49.852576 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00127182 (* 1 = 0.00127182 loss)
I0109 18:19:49.852583 32941 sgd_solver.cpp:112] Iteration 1040, lr = 0.001
I0109 18:19:57.413206 32941 solver.cpp:239] Iteration 1060 (2.64536 iter/s, 7.5604s/20 iters), loss = 0.712132
I0109 18:19:57.413269 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.126655 (* 1 = 0.126655 loss)
I0109 18:19:57.413280 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0939777 (* 1 = 0.0939777 loss)
I0109 18:19:57.413286 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0211997 (* 1 = 0.0211997 loss)
I0109 18:19:57.413292 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00640529 (* 1 = 0.00640529 loss)
I0109 18:19:57.413302 32941 sgd_solver.cpp:112] Iteration 1060, lr = 0.001
I0109 18:20:05.072044 32941 solver.cpp:239] Iteration 1080 (2.61147 iter/s, 7.65852s/20 iters), loss = 0.296967
I0109 18:20:05.072108 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0604396 (* 1 = 0.0604396 loss)
I0109 18:20:05.072118 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.156548 (* 1 = 0.156548 loss)
I0109 18:20:05.072124 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.150592 (* 1 = 0.150592 loss)
I0109 18:20:05.072130 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.115224 (* 1 = 0.115224 loss)
I0109 18:20:05.072137 32941 sgd_solver.cpp:112] Iteration 1080, lr = 0.001
I0109 18:20:12.895068 32941 solver.cpp:239] Iteration 1100 (2.55667 iter/s, 7.82269s/20 iters), loss = 0.381948
I0109 18:20:12.895143 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.11804 (* 1 = 0.11804 loss)
I0109 18:20:12.895153 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.351918 (* 1 = 0.351918 loss)
I0109 18:20:12.895161 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0104939 (* 1 = 0.0104939 loss)
I0109 18:20:12.895169 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00241474 (* 1 = 0.00241474 loss)
I0109 18:20:12.895177 32941 sgd_solver.cpp:112] Iteration 1100, lr = 0.001
I0109 18:20:20.361294 32941 solver.cpp:239] Iteration 1120 (2.67885 iter/s, 7.4659s/20 iters), loss = 0.207326
I0109 18:20:20.361356 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0882839 (* 1 = 0.0882839 loss)
I0109 18:20:20.361366 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0913707 (* 1 = 0.0913707 loss)
I0109 18:20:20.361372 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0151904 (* 1 = 0.0151904 loss)
I0109 18:20:20.361378 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0003688 (* 1 = 0.0003688 loss)
I0109 18:20:20.361387 32941 sgd_solver.cpp:112] Iteration 1120, lr = 0.001
I0109 18:20:27.857264 32941 solver.cpp:239] Iteration 1140 (2.66821 iter/s, 7.49566s/20 iters), loss = 0.383687
I0109 18:20:27.857326 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.254827 (* 1 = 0.254827 loss)
I0109 18:20:27.857337 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0939999 (* 1 = 0.0939999 loss)
I0109 18:20:27.857344 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0453714 (* 1 = 0.0453714 loss)
I0109 18:20:27.857350 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0225828 (* 1 = 0.0225828 loss)
I0109 18:20:27.857358 32941 sgd_solver.cpp:112] Iteration 1140, lr = 0.001
I0109 18:20:35.382877 32941 solver.cpp:239] Iteration 1160 (2.6577 iter/s, 7.5253s/20 iters), loss = 0.267274
I0109 18:20:35.382938 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.105671 (* 1 = 0.105671 loss)
I0109 18:20:35.382948 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.131024 (* 1 = 0.131024 loss)
I0109 18:20:35.382956 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0126397 (* 1 = 0.0126397 loss)
I0109 18:20:35.382961 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00650441 (* 1 = 0.00650441 loss)
I0109 18:20:35.382969 32941 sgd_solver.cpp:112] Iteration 1160, lr = 0.001
I0109 18:20:42.984637 32941 solver.cpp:239] Iteration 1180 (2.63108 iter/s, 7.60143s/20 iters), loss = 0.12822
I0109 18:20:42.984704 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0562823 (* 1 = 0.0562823 loss)
I0109 18:20:42.984714 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0278969 (* 1 = 0.0278969 loss)
I0109 18:20:42.984720 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0445468 (* 1 = 0.0445468 loss)
I0109 18:20:42.984727 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00174371 (* 1 = 0.00174371 loss)
I0109 18:20:42.984735 32941 sgd_solver.cpp:112] Iteration 1180, lr = 0.001
speed: 0.380s / iter
I0109 18:20:50.509467 32941 solver.cpp:239] Iteration 1200 (2.65798 iter/s, 7.52451s/20 iters), loss = 0.583767
I0109 18:20:50.509537 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.217482 (* 1 = 0.217482 loss)
I0109 18:20:50.509546 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.541267 (* 1 = 0.541267 loss)
I0109 18:20:50.509554 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0207265 (* 1 = 0.0207265 loss)
I0109 18:20:50.509562 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0264144 (* 1 = 0.0264144 loss)
I0109 18:20:50.509569 32941 sgd_solver.cpp:112] Iteration 1200, lr = 0.001
I0109 18:20:58.028515 32941 solver.cpp:239] Iteration 1220 (2.66003 iter/s, 7.51873s/20 iters), loss = 0.450915
I0109 18:20:58.028575 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.200212 (* 1 = 0.200212 loss)
I0109 18:20:58.028584 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.159184 (* 1 = 0.159184 loss)
I0109 18:20:58.028591 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0781065 (* 1 = 0.0781065 loss)
I0109 18:20:58.028599 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0214827 (* 1 = 0.0214827 loss)
I0109 18:20:58.028607 32941 sgd_solver.cpp:112] Iteration 1220, lr = 0.001
I0109 18:21:05.640223 32941 solver.cpp:239] Iteration 1240 (2.62764 iter/s, 7.61139s/20 iters), loss = 0.565022
I0109 18:21:05.640295 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.254578 (* 1 = 0.254578 loss)
I0109 18:21:05.640305 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.145281 (* 1 = 0.145281 loss)
I0109 18:21:05.640311 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0449877 (* 1 = 0.0449877 loss)
I0109 18:21:05.640318 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0485709 (* 1 = 0.0485709 loss)
I0109 18:21:05.640326 32941 sgd_solver.cpp:112] Iteration 1240, lr = 0.001
I0109 18:21:13.569694 32941 solver.cpp:239] Iteration 1260 (2.52234 iter/s, 7.92914s/20 iters), loss = 0.425385
I0109 18:21:13.569753 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.247715 (* 1 = 0.247715 loss)
I0109 18:21:13.569763 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.244051 (* 1 = 0.244051 loss)
I0109 18:21:13.569770 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.026698 (* 1 = 0.026698 loss)
I0109 18:21:13.569777 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0320486 (* 1 = 0.0320486 loss)
I0109 18:21:13.569785 32941 sgd_solver.cpp:112] Iteration 1260, lr = 0.001
I0109 18:21:21.390023 32941 solver.cpp:239] Iteration 1280 (2.55754 iter/s, 7.82001s/20 iters), loss = 0.637365
I0109 18:21:21.390082 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.219819 (* 1 = 0.219819 loss)
I0109 18:21:21.390091 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0937346 (* 1 = 0.0937346 loss)
I0109 18:21:21.390100 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0475834 (* 1 = 0.0475834 loss)
I0109 18:21:21.390106 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0184124 (* 1 = 0.0184124 loss)
I0109 18:21:21.390115 32941 sgd_solver.cpp:112] Iteration 1280, lr = 0.001
I0109 18:21:28.874336 32941 solver.cpp:239] Iteration 1300 (2.67237 iter/s, 7.484s/20 iters), loss = 0.146832
I0109 18:21:28.874397 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0648396 (* 1 = 0.0648396 loss)
I0109 18:21:28.874405 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0380236 (* 1 = 0.0380236 loss)
I0109 18:21:28.874413 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00405418 (* 1 = 0.00405418 loss)
I0109 18:21:28.874419 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000925673 (* 1 = 0.000925673 loss)
I0109 18:21:28.874426 32941 sgd_solver.cpp:112] Iteration 1300, lr = 0.001
I0109 18:21:36.408401 32941 solver.cpp:239] Iteration 1320 (2.65472 iter/s, 7.53374s/20 iters), loss = 0.388028
I0109 18:21:36.408473 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0746786 (* 1 = 0.0746786 loss)
I0109 18:21:36.408483 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0771484 (* 1 = 0.0771484 loss)
I0109 18:21:36.408489 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0119035 (* 1 = 0.0119035 loss)
I0109 18:21:36.408496 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00557595 (* 1 = 0.00557595 loss)
I0109 18:21:36.408515 32941 sgd_solver.cpp:112] Iteration 1320, lr = 0.001
I0109 18:21:44.140167 32941 solver.cpp:239] Iteration 1340 (2.58684 iter/s, 7.73143s/20 iters), loss = 0.173839
I0109 18:21:44.140230 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0793685 (* 1 = 0.0793685 loss)
I0109 18:21:44.140239 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.105087 (* 1 = 0.105087 loss)
I0109 18:21:44.140246 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0336143 (* 1 = 0.0336143 loss)
I0109 18:21:44.140254 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00212493 (* 1 = 0.00212493 loss)
I0109 18:21:44.140260 32941 sgd_solver.cpp:112] Iteration 1340, lr = 0.001
I0109 18:21:51.928128 32941 solver.cpp:239] Iteration 1360 (2.56817 iter/s, 7.78763s/20 iters), loss = 0.542916
I0109 18:21:51.928185 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.160063 (* 1 = 0.160063 loss)
I0109 18:21:51.928195 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.291493 (* 1 = 0.291493 loss)
I0109 18:21:51.928201 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0746638 (* 1 = 0.0746638 loss)
I0109 18:21:51.928208 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.051666 (* 1 = 0.051666 loss)
I0109 18:21:51.928216 32941 sgd_solver.cpp:112] Iteration 1360, lr = 0.001
I0109 18:21:59.444502 32941 solver.cpp:239] Iteration 1380 (2.66097 iter/s, 7.51606s/20 iters), loss = 0.601159
I0109 18:21:59.444561 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.24237 (* 1 = 0.24237 loss)
I0109 18:21:59.444569 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.347829 (* 1 = 0.347829 loss)
I0109 18:21:59.444576 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00938274 (* 1 = 0.00938274 loss)
I0109 18:21:59.444583 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0059703 (* 1 = 0.0059703 loss)
I0109 18:21:59.444591 32941 sgd_solver.cpp:112] Iteration 1380, lr = 0.001
speed: 0.381s / iter
I0109 18:22:07.240022 32941 solver.cpp:239] Iteration 1400 (2.56568 iter/s, 7.79521s/20 iters), loss = 0.245109
I0109 18:22:07.240088 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.220378 (* 1 = 0.220378 loss)
I0109 18:22:07.240098 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0760673 (* 1 = 0.0760673 loss)
I0109 18:22:07.240105 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0169805 (* 1 = 0.0169805 loss)
I0109 18:22:07.240111 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0473572 (* 1 = 0.0473572 loss)
I0109 18:22:07.240119 32941 sgd_solver.cpp:112] Iteration 1400, lr = 0.001
I0109 18:22:14.890980 32941 solver.cpp:239] Iteration 1420 (2.61416 iter/s, 7.65064s/20 iters), loss = 0.295533
I0109 18:22:14.891046 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.178228 (* 1 = 0.178228 loss)
I0109 18:22:14.891055 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.168362 (* 1 = 0.168362 loss)
I0109 18:22:14.891062 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0389404 (* 1 = 0.0389404 loss)
I0109 18:22:14.891068 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0368927 (* 1 = 0.0368927 loss)
I0109 18:22:14.891075 32941 sgd_solver.cpp:112] Iteration 1420, lr = 0.001
I0109 18:22:22.385891 32941 solver.cpp:239] Iteration 1440 (2.66859 iter/s, 7.4946s/20 iters), loss = 0.159563
I0109 18:22:22.385960 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0622608 (* 1 = 0.0622608 loss)
I0109 18:22:22.385969 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0470149 (* 1 = 0.0470149 loss)
I0109 18:22:22.385977 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0140874 (* 1 = 0.0140874 loss)
I0109 18:22:22.385994 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0149777 (* 1 = 0.0149777 loss)
I0109 18:22:22.386003 32941 sgd_solver.cpp:112] Iteration 1440, lr = 0.001
I0109 18:22:29.900895 32941 solver.cpp:239] Iteration 1460 (2.66146 iter/s, 7.51467s/20 iters), loss = 0.41198
I0109 18:22:29.900951 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.109403 (* 1 = 0.109403 loss)
I0109 18:22:29.900961 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0533651 (* 1 = 0.0533651 loss)
I0109 18:22:29.900969 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0105065 (* 1 = 0.0105065 loss)
I0109 18:22:29.900974 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00637213 (* 1 = 0.00637213 loss)
I0109 18:22:29.900982 32941 sgd_solver.cpp:112] Iteration 1460, lr = 0.001
I0109 18:22:37.330885 32941 solver.cpp:239] Iteration 1480 (2.6919 iter/s, 7.42969s/20 iters), loss = 0.509036
I0109 18:22:37.330940 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.166987 (* 1 = 0.166987 loss)
I0109 18:22:37.330948 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.100891 (* 1 = 0.100891 loss)
I0109 18:22:37.330955 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0677339 (* 1 = 0.0677339 loss)
I0109 18:22:37.330960 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0364041 (* 1 = 0.0364041 loss)
I0109 18:22:37.330966 32941 sgd_solver.cpp:112] Iteration 1480, lr = 0.001
I0109 18:22:44.870028 32941 solver.cpp:239] Iteration 1500 (2.65293 iter/s, 7.53882s/20 iters), loss = 0.504639
I0109 18:22:44.870097 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.166107 (* 1 = 0.166107 loss)
I0109 18:22:44.870107 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.462536 (* 1 = 0.462536 loss)
I0109 18:22:44.870115 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0481767 (* 1 = 0.0481767 loss)
I0109 18:22:44.870121 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0147129 (* 1 = 0.0147129 loss)
I0109 18:22:44.870128 32941 sgd_solver.cpp:112] Iteration 1500, lr = 0.001
I0109 18:22:52.499888 32941 solver.cpp:239] Iteration 1520 (2.62139 iter/s, 7.62953s/20 iters), loss = 0.300758
I0109 18:22:52.499948 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0948265 (* 1 = 0.0948265 loss)
I0109 18:22:52.499958 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.183876 (* 1 = 0.183876 loss)
I0109 18:22:52.499966 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00888176 (* 1 = 0.00888176 loss)
I0109 18:22:52.499972 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0036617 (* 1 = 0.0036617 loss)
I0109 18:22:52.499980 32941 sgd_solver.cpp:112] Iteration 1520, lr = 0.001
I0109 18:23:00.094933 32941 solver.cpp:239] Iteration 1540 (2.63341 iter/s, 7.59473s/20 iters), loss = 0.3589
I0109 18:23:00.095005 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.185287 (* 1 = 0.185287 loss)
I0109 18:23:00.095013 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.126198 (* 1 = 0.126198 loss)
I0109 18:23:00.095021 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0128415 (* 1 = 0.0128415 loss)
I0109 18:23:00.095027 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00133855 (* 1 = 0.00133855 loss)
I0109 18:23:00.095036 32941 sgd_solver.cpp:112] Iteration 1540, lr = 0.001
I0109 18:23:07.448029 32941 solver.cpp:239] Iteration 1560 (2.72006 iter/s, 7.35277s/20 iters), loss = 0.344855
I0109 18:23:07.448096 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.170752 (* 1 = 0.170752 loss)
I0109 18:23:07.448105 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.201654 (* 1 = 0.201654 loss)
I0109 18:23:07.448112 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0462155 (* 1 = 0.0462155 loss)
I0109 18:23:07.448120 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00243093 (* 1 = 0.00243093 loss)
I0109 18:23:07.448128 32941 sgd_solver.cpp:112] Iteration 1560, lr = 0.001
I0109 18:23:14.845158 32941 solver.cpp:239] Iteration 1580 (2.70387 iter/s, 7.39682s/20 iters), loss = 0.213229
I0109 18:23:14.845217 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.168047 (* 1 = 0.168047 loss)
I0109 18:23:14.845227 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0323268 (* 1 = 0.0323268 loss)
I0109 18:23:14.845234 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0133475 (* 1 = 0.0133475 loss)
I0109 18:23:14.845242 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000515127 (* 1 = 0.000515127 loss)
I0109 18:23:14.845249 32941 sgd_solver.cpp:112] Iteration 1580, lr = 0.001
speed: 0.380s / iter
I0109 18:23:22.248363 32941 solver.cpp:239] Iteration 1600 (2.70164 iter/s, 7.4029s/20 iters), loss = 0.259724
I0109 18:23:22.248425 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0849765 (* 1 = 0.0849765 loss)
I0109 18:23:22.248433 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0538442 (* 1 = 0.0538442 loss)
I0109 18:23:22.248440 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0953211 (* 1 = 0.0953211 loss)
I0109 18:23:22.248447 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0185631 (* 1 = 0.0185631 loss)
I0109 18:23:22.248456 32941 sgd_solver.cpp:112] Iteration 1600, lr = 0.001
I0109 18:23:29.831244 32941 solver.cpp:239] Iteration 1620 (2.63763 iter/s, 7.58256s/20 iters), loss = 0.120795
I0109 18:23:29.831311 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0618467 (* 1 = 0.0618467 loss)
I0109 18:23:29.831321 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0103504 (* 1 = 0.0103504 loss)
I0109 18:23:29.831328 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0497524 (* 1 = 0.0497524 loss)
I0109 18:23:29.831334 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00832768 (* 1 = 0.00832768 loss)
I0109 18:23:29.831343 32941 sgd_solver.cpp:112] Iteration 1620, lr = 0.001
I0109 18:23:37.448798 32941 solver.cpp:239] Iteration 1640 (2.62562 iter/s, 7.61724s/20 iters), loss = 0.281462
I0109 18:23:37.448873 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.136923 (* 1 = 0.136923 loss)
I0109 18:23:37.448882 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0878353 (* 1 = 0.0878353 loss)
I0109 18:23:37.448889 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00394609 (* 1 = 0.00394609 loss)
I0109 18:23:37.448896 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00969752 (* 1 = 0.00969752 loss)
I0109 18:23:37.448904 32941 sgd_solver.cpp:112] Iteration 1640, lr = 0.001
I0109 18:23:45.005411 32941 solver.cpp:239] Iteration 1660 (2.6468 iter/s, 7.55629s/20 iters), loss = 0.180872
I0109 18:23:45.005470 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0769034 (* 1 = 0.0769034 loss)
I0109 18:23:45.005478 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0612988 (* 1 = 0.0612988 loss)
I0109 18:23:45.005486 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00521924 (* 1 = 0.00521924 loss)
I0109 18:23:45.005492 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000951091 (* 1 = 0.000951091 loss)
I0109 18:23:45.005499 32941 sgd_solver.cpp:112] Iteration 1660, lr = 0.001
I0109 18:23:52.560828 32941 solver.cpp:239] Iteration 1680 (2.64722 iter/s, 7.55511s/20 iters), loss = 0.253369
I0109 18:23:52.560904 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.283832 (* 1 = 0.283832 loss)
I0109 18:23:52.560915 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.102621 (* 1 = 0.102621 loss)
I0109 18:23:52.560922 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00996173 (* 1 = 0.00996173 loss)
I0109 18:23:52.560928 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0111307 (* 1 = 0.0111307 loss)
I0109 18:23:52.560936 32941 sgd_solver.cpp:112] Iteration 1680, lr = 0.001
I0109 18:24:00.057231 32941 solver.cpp:239] Iteration 1700 (2.66806 iter/s, 7.49607s/20 iters), loss = 0.290183
I0109 18:24:00.057293 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0873025 (* 1 = 0.0873025 loss)
I0109 18:24:00.057303 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.109215 (* 1 = 0.109215 loss)
I0109 18:24:00.057310 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0700178 (* 1 = 0.0700178 loss)
I0109 18:24:00.057317 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0210363 (* 1 = 0.0210363 loss)
I0109 18:24:00.057324 32941 sgd_solver.cpp:112] Iteration 1700, lr = 0.001
I0109 18:24:07.573051 32941 solver.cpp:239] Iteration 1720 (2.66116 iter/s, 7.51551s/20 iters), loss = 0.226788
I0109 18:24:07.573109 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.195344 (* 1 = 0.195344 loss)
I0109 18:24:07.573118 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.105413 (* 1 = 0.105413 loss)
I0109 18:24:07.573125 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0157201 (* 1 = 0.0157201 loss)
I0109 18:24:07.573132 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0216924 (* 1 = 0.0216924 loss)
I0109 18:24:07.573139 32941 sgd_solver.cpp:112] Iteration 1720, lr = 0.001
I0109 18:24:15.103899 32941 solver.cpp:239] Iteration 1740 (2.65586 iter/s, 7.53053s/20 iters), loss = 0.359754
I0109 18:24:15.103983 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.132824 (* 1 = 0.132824 loss)
I0109 18:24:15.104002 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.380679 (* 1 = 0.380679 loss)
I0109 18:24:15.104017 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00812774 (* 1 = 0.00812774 loss)
I0109 18:24:15.104029 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00434045 (* 1 = 0.00434045 loss)
I0109 18:24:15.104041 32941 sgd_solver.cpp:112] Iteration 1740, lr = 0.001
I0109 18:24:22.718842 32941 solver.cpp:239] Iteration 1760 (2.62653 iter/s, 7.61462s/20 iters), loss = 0.301126
I0109 18:24:22.718890 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0993632 (* 1 = 0.0993632 loss)
I0109 18:24:22.718899 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.291871 (* 1 = 0.291871 loss)
I0109 18:24:22.718906 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0069754 (* 1 = 0.0069754 loss)
I0109 18:24:22.718912 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00369893 (* 1 = 0.00369893 loss)
I0109 18:24:22.718919 32941 sgd_solver.cpp:112] Iteration 1760, lr = 0.001
I0109 18:24:30.484705 32941 solver.cpp:239] Iteration 1780 (2.57548 iter/s, 7.76555s/20 iters), loss = 0.311492
I0109 18:24:30.484776 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.12158 (* 1 = 0.12158 loss)
I0109 18:24:30.484784 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0526858 (* 1 = 0.0526858 loss)
I0109 18:24:30.484791 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.013903 (* 1 = 0.013903 loss)
I0109 18:24:30.484797 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00422327 (* 1 = 0.00422327 loss)
I0109 18:24:30.484805 32941 sgd_solver.cpp:112] Iteration 1780, lr = 0.001
speed: 0.380s / iter
I0109 18:24:37.986765 32941 solver.cpp:239] Iteration 1800 (2.66605 iter/s, 7.50174s/20 iters), loss = 0.286218
I0109 18:24:37.986814 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.321485 (* 1 = 0.321485 loss)
I0109 18:24:37.986824 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.120672 (* 1 = 0.120672 loss)
I0109 18:24:37.986830 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.02308 (* 1 = 0.02308 loss)
I0109 18:24:37.986837 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.034122 (* 1 = 0.034122 loss)
I0109 18:24:37.986845 32941 sgd_solver.cpp:112] Iteration 1800, lr = 0.001
I0109 18:24:45.657358 32941 solver.cpp:239] Iteration 1820 (2.60747 iter/s, 7.67028s/20 iters), loss = 0.229559
I0109 18:24:45.657420 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0706437 (* 1 = 0.0706437 loss)
I0109 18:24:45.657430 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.110081 (* 1 = 0.110081 loss)
I0109 18:24:45.657438 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00364236 (* 1 = 0.00364236 loss)
I0109 18:24:45.657445 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00160506 (* 1 = 0.00160506 loss)
I0109 18:24:45.657454 32941 sgd_solver.cpp:112] Iteration 1820, lr = 0.001
I0109 18:24:53.204818 32941 solver.cpp:239] Iteration 1840 (2.65001 iter/s, 7.54714s/20 iters), loss = 0.327592
I0109 18:24:53.204900 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0561435 (* 1 = 0.0561435 loss)
I0109 18:24:53.204910 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0541948 (* 1 = 0.0541948 loss)
I0109 18:24:53.204918 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00475811 (* 1 = 0.00475811 loss)
I0109 18:24:53.204924 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00726585 (* 1 = 0.00726585 loss)
I0109 18:24:53.204933 32941 sgd_solver.cpp:112] Iteration 1840, lr = 0.001
I0109 18:25:00.735816 32941 solver.cpp:239] Iteration 1860 (2.65581 iter/s, 7.53067s/20 iters), loss = 0.532281
I0109 18:25:00.735882 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.223887 (* 1 = 0.223887 loss)
I0109 18:25:00.735890 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0471456 (* 1 = 0.0471456 loss)
I0109 18:25:00.735900 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0262701 (* 1 = 0.0262701 loss)
I0109 18:25:00.735906 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0262745 (* 1 = 0.0262745 loss)
I0109 18:25:00.735913 32941 sgd_solver.cpp:112] Iteration 1860, lr = 0.001
I0109 18:25:08.359105 32941 solver.cpp:239] Iteration 1880 (2.62365 iter/s, 7.62297s/20 iters), loss = 0.352455
I0109 18:25:08.359159 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.177012 (* 1 = 0.177012 loss)
I0109 18:25:08.359167 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.278017 (* 1 = 0.278017 loss)
I0109 18:25:08.359174 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0237545 (* 1 = 0.0237545 loss)
I0109 18:25:08.359179 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0150146 (* 1 = 0.0150146 loss)
I0109 18:25:08.359185 32941 sgd_solver.cpp:112] Iteration 1880, lr = 0.001
I0109 18:25:15.791589 32941 solver.cpp:239] Iteration 1900 (2.691 iter/s, 7.43217s/20 iters), loss = 0.248848
I0109 18:25:15.791653 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.159367 (* 1 = 0.159367 loss)
I0109 18:25:15.791663 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.109443 (* 1 = 0.109443 loss)
I0109 18:25:15.791671 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0190452 (* 1 = 0.0190452 loss)
I0109 18:25:15.791676 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0039918 (* 1 = 0.0039918 loss)
I0109 18:25:15.791684 32941 sgd_solver.cpp:112] Iteration 1900, lr = 0.001
I0109 18:25:23.408710 32941 solver.cpp:239] Iteration 1920 (2.62577 iter/s, 7.6168s/20 iters), loss = 0.350011
I0109 18:25:23.408768 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.147029 (* 1 = 0.147029 loss)
I0109 18:25:23.408777 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0535395 (* 1 = 0.0535395 loss)
I0109 18:25:23.408784 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00944361 (* 1 = 0.00944361 loss)
I0109 18:25:23.408792 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0125384 (* 1 = 0.0125384 loss)
I0109 18:25:23.408799 32941 sgd_solver.cpp:112] Iteration 1920, lr = 0.001
I0109 18:25:31.213140 32941 solver.cpp:239] Iteration 1940 (2.56275 iter/s, 7.80411s/20 iters), loss = 0.32119
I0109 18:25:31.213202 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.2015 (* 1 = 0.2015 loss)
I0109 18:25:31.213212 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0851081 (* 1 = 0.0851081 loss)
I0109 18:25:31.213219 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00759465 (* 1 = 0.00759465 loss)
I0109 18:25:31.213227 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00210496 (* 1 = 0.00210496 loss)
I0109 18:25:31.213233 32941 sgd_solver.cpp:112] Iteration 1940, lr = 0.001
I0109 18:25:38.803618 32941 solver.cpp:239] Iteration 1960 (2.63499 iter/s, 7.59016s/20 iters), loss = 0.261164
I0109 18:25:38.803678 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.193401 (* 1 = 0.193401 loss)
I0109 18:25:38.803687 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.078569 (* 1 = 0.078569 loss)
I0109 18:25:38.803694 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0219199 (* 1 = 0.0219199 loss)
I0109 18:25:38.803701 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0146515 (* 1 = 0.0146515 loss)
I0109 18:25:38.803709 32941 sgd_solver.cpp:112] Iteration 1960, lr = 0.001
I0109 18:25:46.249640 32941 solver.cpp:239] Iteration 1980 (2.68611 iter/s, 7.44571s/20 iters), loss = 0.196066
I0109 18:25:46.249703 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0735489 (* 1 = 0.0735489 loss)
I0109 18:25:46.249712 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0629968 (* 1 = 0.0629968 loss)
I0109 18:25:46.249719 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0119651 (* 1 = 0.0119651 loss)
I0109 18:25:46.249727 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00369533 (* 1 = 0.00369533 loss)
I0109 18:25:46.249733 32941 sgd_solver.cpp:112] Iteration 1980, lr = 0.001
speed: 0.380s / iter
I0109 18:25:53.769627 32941 solver.cpp:239] Iteration 2000 (2.65969 iter/s, 7.51967s/20 iters), loss = 0.279651
I0109 18:25:53.769682 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116301 (* 1 = 0.116301 loss)
I0109 18:25:53.769691 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.112188 (* 1 = 0.112188 loss)
I0109 18:25:53.769698 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0809061 (* 1 = 0.0809061 loss)
I0109 18:25:53.769704 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.157792 (* 1 = 0.157792 loss)
I0109 18:25:53.769712 32941 sgd_solver.cpp:112] Iteration 2000, lr = 0.001
I0109 18:26:01.350605 32941 solver.cpp:239] Iteration 2020 (2.63829 iter/s, 7.58067s/20 iters), loss = 0.363421
I0109 18:26:01.350678 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.255286 (* 1 = 0.255286 loss)
I0109 18:26:01.350688 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.139053 (* 1 = 0.139053 loss)
I0109 18:26:01.350695 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.027033 (* 1 = 0.027033 loss)
I0109 18:26:01.350703 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0227215 (* 1 = 0.0227215 loss)
I0109 18:26:01.350710 32941 sgd_solver.cpp:112] Iteration 2020, lr = 0.001
I0109 18:26:09.283565 32941 solver.cpp:239] Iteration 2040 (2.52123 iter/s, 7.93262s/20 iters), loss = 0.273332
I0109 18:26:09.283627 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.060789 (* 1 = 0.060789 loss)
I0109 18:26:09.283637 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.063907 (* 1 = 0.063907 loss)
I0109 18:26:09.283643 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00743192 (* 1 = 0.00743192 loss)
I0109 18:26:09.283650 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00115841 (* 1 = 0.00115841 loss)
I0109 18:26:09.283658 32941 sgd_solver.cpp:112] Iteration 2040, lr = 0.001
I0109 18:26:16.747237 32941 solver.cpp:239] Iteration 2060 (2.67976 iter/s, 7.46336s/20 iters), loss = 0.294092
I0109 18:26:16.747310 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0573428 (* 1 = 0.0573428 loss)
I0109 18:26:16.747320 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.197907 (* 1 = 0.197907 loss)
I0109 18:26:16.747326 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0178431 (* 1 = 0.0178431 loss)
I0109 18:26:16.747332 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00212427 (* 1 = 0.00212427 loss)
I0109 18:26:16.747340 32941 sgd_solver.cpp:112] Iteration 2060, lr = 0.001
I0109 18:26:24.290791 32941 solver.cpp:239] Iteration 2080 (2.65139 iter/s, 7.54323s/20 iters), loss = 0.735548
I0109 18:26:24.290851 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.186655 (* 1 = 0.186655 loss)
I0109 18:26:24.290860 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.925264 (* 1 = 0.925264 loss)
I0109 18:26:24.290868 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0153373 (* 1 = 0.0153373 loss)
I0109 18:26:24.290874 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0110148 (* 1 = 0.0110148 loss)
I0109 18:26:24.290881 32941 sgd_solver.cpp:112] Iteration 2080, lr = 0.001
I0109 18:26:31.830891 32941 solver.cpp:239] Iteration 2100 (2.6526 iter/s, 7.53977s/20 iters), loss = 0.389466
I0109 18:26:31.830957 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.19206 (* 1 = 0.19206 loss)
I0109 18:26:31.830966 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.163727 (* 1 = 0.163727 loss)
I0109 18:26:31.830974 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0934674 (* 1 = 0.0934674 loss)
I0109 18:26:31.830981 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00862409 (* 1 = 0.00862409 loss)
I0109 18:26:31.830994 32941 sgd_solver.cpp:112] Iteration 2100, lr = 0.001
I0109 18:26:39.226933 32941 solver.cpp:239] Iteration 2120 (2.70426 iter/s, 7.39573s/20 iters), loss = 0.159229
I0109 18:26:39.226994 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0442235 (* 1 = 0.0442235 loss)
I0109 18:26:39.227005 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0253869 (* 1 = 0.0253869 loss)
I0109 18:26:39.227011 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00280159 (* 1 = 0.00280159 loss)
I0109 18:26:39.227017 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000832938 (* 1 = 0.000832938 loss)
I0109 18:26:39.227025 32941 sgd_solver.cpp:112] Iteration 2120, lr = 0.001
I0109 18:26:46.766386 32941 solver.cpp:239] Iteration 2140 (2.65282 iter/s, 7.53913s/20 iters), loss = 0.0647049
I0109 18:26:46.766456 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0533356 (* 1 = 0.0533356 loss)
I0109 18:26:46.766466 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0108449 (* 1 = 0.0108449 loss)
I0109 18:26:46.766474 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0032144 (* 1 = 0.0032144 loss)
I0109 18:26:46.766481 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00902523 (* 1 = 0.00902523 loss)
I0109 18:26:46.766490 32941 sgd_solver.cpp:112] Iteration 2140, lr = 0.001
I0109 18:26:54.438529 32941 solver.cpp:239] Iteration 2160 (2.60694 iter/s, 7.67182s/20 iters), loss = 0.556078
I0109 18:26:54.438593 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.111894 (* 1 = 0.111894 loss)
I0109 18:26:54.438602 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0493937 (* 1 = 0.0493937 loss)
I0109 18:26:54.438609 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00228717 (* 1 = 0.00228717 loss)
I0109 18:26:54.438616 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00208268 (* 1 = 0.00208268 loss)
I0109 18:26:54.438624 32941 sgd_solver.cpp:112] Iteration 2160, lr = 0.001
I0109 18:27:01.886611 32941 solver.cpp:239] Iteration 2180 (2.68537 iter/s, 7.44777s/20 iters), loss = 0.108525
I0109 18:27:01.886678 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.090441 (* 1 = 0.090441 loss)
I0109 18:27:01.886688 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0301286 (* 1 = 0.0301286 loss)
I0109 18:27:01.886696 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00816552 (* 1 = 0.00816552 loss)
I0109 18:27:01.886703 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00237042 (* 1 = 0.00237042 loss)
I0109 18:27:01.886711 32941 sgd_solver.cpp:112] Iteration 2180, lr = 0.001
speed: 0.380s / iter
I0109 18:27:09.298045 32941 solver.cpp:239] Iteration 2200 (2.69865 iter/s, 7.41112s/20 iters), loss = 0.085055
I0109 18:27:09.298097 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0544033 (* 1 = 0.0544033 loss)
I0109 18:27:09.298106 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00643793 (* 1 = 0.00643793 loss)
I0109 18:27:09.298112 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00898186 (* 1 = 0.00898186 loss)
I0109 18:27:09.298120 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00336624 (* 1 = 0.00336624 loss)
I0109 18:27:09.298127 32941 sgd_solver.cpp:112] Iteration 2200, lr = 0.001
I0109 18:27:16.887130 32941 solver.cpp:239] Iteration 2220 (2.63547 iter/s, 7.58878s/20 iters), loss = 0.31672
I0109 18:27:16.887192 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.10416 (* 1 = 0.10416 loss)
I0109 18:27:16.887200 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0356157 (* 1 = 0.0356157 loss)
I0109 18:27:16.887207 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00466717 (* 1 = 0.00466717 loss)
I0109 18:27:16.887213 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00196065 (* 1 = 0.00196065 loss)
I0109 18:27:16.887230 32941 sgd_solver.cpp:112] Iteration 2220, lr = 0.001
I0109 18:27:24.473582 32941 solver.cpp:239] Iteration 2240 (2.63639 iter/s, 7.58614s/20 iters), loss = 0.167674
I0109 18:27:24.473642 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0754559 (* 1 = 0.0754559 loss)
I0109 18:27:24.473652 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00513736 (* 1 = 0.00513736 loss)
I0109 18:27:24.473659 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0184794 (* 1 = 0.0184794 loss)
I0109 18:27:24.473665 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00819053 (* 1 = 0.00819053 loss)
I0109 18:27:24.473673 32941 sgd_solver.cpp:112] Iteration 2240, lr = 0.001
I0109 18:27:31.881661 32941 solver.cpp:239] Iteration 2260 (2.69987 iter/s, 7.40777s/20 iters), loss = 0.238248
I0109 18:27:31.881714 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0577413 (* 1 = 0.0577413 loss)
I0109 18:27:31.881723 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0461945 (* 1 = 0.0461945 loss)
I0109 18:27:31.881731 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0282696 (* 1 = 0.0282696 loss)
I0109 18:27:31.881737 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00462491 (* 1 = 0.00462491 loss)
I0109 18:27:31.881743 32941 sgd_solver.cpp:112] Iteration 2260, lr = 0.001
I0109 18:27:39.564124 32941 solver.cpp:239] Iteration 2280 (2.60344 iter/s, 7.68216s/20 iters), loss = 0.34514
I0109 18:27:39.564182 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.162836 (* 1 = 0.162836 loss)
I0109 18:27:39.564191 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0610917 (* 1 = 0.0610917 loss)
I0109 18:27:39.564198 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0294568 (* 1 = 0.0294568 loss)
I0109 18:27:39.564204 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0223873 (* 1 = 0.0223873 loss)
I0109 18:27:39.564210 32941 sgd_solver.cpp:112] Iteration 2280, lr = 0.001
I0109 18:27:47.159898 32941 solver.cpp:239] Iteration 2300 (2.63316 iter/s, 7.59545s/20 iters), loss = 0.258143
I0109 18:27:47.159966 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.278182 (* 1 = 0.278182 loss)
I0109 18:27:47.159976 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0483181 (* 1 = 0.0483181 loss)
I0109 18:27:47.159988 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0120524 (* 1 = 0.0120524 loss)
I0109 18:27:47.159994 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0208306 (* 1 = 0.0208306 loss)
I0109 18:27:47.160001 32941 sgd_solver.cpp:112] Iteration 2300, lr = 0.001
I0109 18:27:54.625859 32941 solver.cpp:239] Iteration 2320 (2.67894 iter/s, 7.46564s/20 iters), loss = 0.384197
I0109 18:27:54.625921 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0122534 (* 1 = 0.0122534 loss)
I0109 18:27:54.625929 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0369886 (* 1 = 0.0369886 loss)
I0109 18:27:54.625936 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.05652 (* 1 = 0.05652 loss)
I0109 18:27:54.625942 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0367826 (* 1 = 0.0367826 loss)
I0109 18:27:54.625950 32941 sgd_solver.cpp:112] Iteration 2320, lr = 0.001
I0109 18:28:02.289342 32941 solver.cpp:239] Iteration 2340 (2.60989 iter/s, 7.66317s/20 iters), loss = 0.541268
I0109 18:28:02.289402 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.201104 (* 1 = 0.201104 loss)
I0109 18:28:02.289412 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.438079 (* 1 = 0.438079 loss)
I0109 18:28:02.289419 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0227394 (* 1 = 0.0227394 loss)
I0109 18:28:02.289427 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0110858 (* 1 = 0.0110858 loss)
I0109 18:28:02.289434 32941 sgd_solver.cpp:112] Iteration 2340, lr = 0.001
I0109 18:28:09.848568 32941 solver.cpp:239] Iteration 2360 (2.64588 iter/s, 7.55891s/20 iters), loss = 0.167004
I0109 18:28:09.848639 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0521978 (* 1 = 0.0521978 loss)
I0109 18:28:09.848649 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00804269 (* 1 = 0.00804269 loss)
I0109 18:28:09.848655 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00620829 (* 1 = 0.00620829 loss)
I0109 18:28:09.848672 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00519497 (* 1 = 0.00519497 loss)
I0109 18:28:09.848680 32941 sgd_solver.cpp:112] Iteration 2360, lr = 0.001
I0109 18:28:17.451687 32941 solver.cpp:239] Iteration 2380 (2.63061 iter/s, 7.6028s/20 iters), loss = 0.306742
I0109 18:28:17.451736 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.201298 (* 1 = 0.201298 loss)
I0109 18:28:17.451745 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.199504 (* 1 = 0.199504 loss)
I0109 18:28:17.451752 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0473476 (* 1 = 0.0473476 loss)
I0109 18:28:17.451758 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0125981 (* 1 = 0.0125981 loss)
I0109 18:28:17.451766 32941 sgd_solver.cpp:112] Iteration 2380, lr = 0.001
speed: 0.379s / iter
I0109 18:28:24.898231 32941 solver.cpp:239] Iteration 2400 (2.68592 iter/s, 7.44625s/20 iters), loss = 0.32433
I0109 18:28:24.898290 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.177374 (* 1 = 0.177374 loss)
I0109 18:28:24.898299 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.232718 (* 1 = 0.232718 loss)
I0109 18:28:24.898306 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0310359 (* 1 = 0.0310359 loss)
I0109 18:28:24.898313 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0186896 (* 1 = 0.0186896 loss)
I0109 18:28:24.898319 32941 sgd_solver.cpp:112] Iteration 2400, lr = 0.001
I0109 18:28:32.490155 32941 solver.cpp:239] Iteration 2420 (2.63449 iter/s, 7.59161s/20 iters), loss = 0.160562
I0109 18:28:32.490208 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0970846 (* 1 = 0.0970846 loss)
I0109 18:28:32.490217 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0771128 (* 1 = 0.0771128 loss)
I0109 18:28:32.490224 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0182258 (* 1 = 0.0182258 loss)
I0109 18:28:32.490231 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00957665 (* 1 = 0.00957665 loss)
I0109 18:28:32.490236 32941 sgd_solver.cpp:112] Iteration 2420, lr = 0.001
I0109 18:28:40.139654 32941 solver.cpp:239] Iteration 2440 (2.61466 iter/s, 7.64918s/20 iters), loss = 0.48215
I0109 18:28:40.139724 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.188413 (* 1 = 0.188413 loss)
I0109 18:28:40.139734 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.376187 (* 1 = 0.376187 loss)
I0109 18:28:40.139740 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00257707 (* 1 = 0.00257707 loss)
I0109 18:28:40.139747 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00936743 (* 1 = 0.00936743 loss)
I0109 18:28:40.139755 32941 sgd_solver.cpp:112] Iteration 2440, lr = 0.001
I0109 18:28:47.597390 32941 solver.cpp:239] Iteration 2460 (2.6819 iter/s, 7.45741s/20 iters), loss = 0.316113
I0109 18:28:47.597455 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.18429 (* 1 = 0.18429 loss)
I0109 18:28:47.597465 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.316358 (* 1 = 0.316358 loss)
I0109 18:28:47.597472 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00611573 (* 1 = 0.00611573 loss)
I0109 18:28:47.597479 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00324983 (* 1 = 0.00324983 loss)
I0109 18:28:47.597487 32941 sgd_solver.cpp:112] Iteration 2460, lr = 0.001
I0109 18:28:55.447909 32941 solver.cpp:239] Iteration 2480 (2.54771 iter/s, 7.85019s/20 iters), loss = 0.332351
I0109 18:28:55.447966 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.15249 (* 1 = 0.15249 loss)
I0109 18:28:55.447975 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.232996 (* 1 = 0.232996 loss)
I0109 18:28:55.447983 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0910552 (* 1 = 0.0910552 loss)
I0109 18:28:55.447988 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0190627 (* 1 = 0.0190627 loss)
I0109 18:28:55.447996 32941 sgd_solver.cpp:112] Iteration 2480, lr = 0.001
I0109 18:29:02.957758 32941 solver.cpp:239] Iteration 2500 (2.66328 iter/s, 7.50953s/20 iters), loss = 0.0961421
I0109 18:29:02.957820 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0873413 (* 1 = 0.0873413 loss)
I0109 18:29:02.957830 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0238887 (* 1 = 0.0238887 loss)
I0109 18:29:02.957837 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00351367 (* 1 = 0.00351367 loss)
I0109 18:29:02.957844 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00126077 (* 1 = 0.00126077 loss)
I0109 18:29:02.957851 32941 sgd_solver.cpp:112] Iteration 2500, lr = 0.001
I0109 18:29:10.589359 32941 solver.cpp:239] Iteration 2520 (2.62079 iter/s, 7.63128s/20 iters), loss = 0.28504
I0109 18:29:10.589435 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0306792 (* 1 = 0.0306792 loss)
I0109 18:29:10.589445 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0267501 (* 1 = 0.0267501 loss)
I0109 18:29:10.589452 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0111691 (* 1 = 0.0111691 loss)
I0109 18:29:10.589458 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0010187 (* 1 = 0.0010187 loss)
I0109 18:29:10.589466 32941 sgd_solver.cpp:112] Iteration 2520, lr = 0.001
I0109 18:29:17.949635 32941 solver.cpp:239] Iteration 2540 (2.71741 iter/s, 7.35995s/20 iters), loss = 0.130396
I0109 18:29:17.949697 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0620503 (* 1 = 0.0620503 loss)
I0109 18:29:17.949707 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0400718 (* 1 = 0.0400718 loss)
I0109 18:29:17.949713 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00661178 (* 1 = 0.00661178 loss)
I0109 18:29:17.949720 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000947283 (* 1 = 0.000947283 loss)
I0109 18:29:17.949728 32941 sgd_solver.cpp:112] Iteration 2540, lr = 0.001
I0109 18:29:25.558707 32941 solver.cpp:239] Iteration 2560 (2.62855 iter/s, 7.60875s/20 iters), loss = 0.418426
I0109 18:29:25.558781 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.129975 (* 1 = 0.129975 loss)
I0109 18:29:25.558791 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.239321 (* 1 = 0.239321 loss)
I0109 18:29:25.558799 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.105862 (* 1 = 0.105862 loss)
I0109 18:29:25.558807 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0423458 (* 1 = 0.0423458 loss)
I0109 18:29:25.558816 32941 sgd_solver.cpp:112] Iteration 2560, lr = 0.001
I0109 18:29:33.048671 32941 solver.cpp:239] Iteration 2580 (2.67035 iter/s, 7.48964s/20 iters), loss = 0.207743
I0109 18:29:33.048730 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.110543 (* 1 = 0.110543 loss)
I0109 18:29:33.048739 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0728558 (* 1 = 0.0728558 loss)
I0109 18:29:33.048746 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0316249 (* 1 = 0.0316249 loss)
I0109 18:29:33.048753 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0226103 (* 1 = 0.0226103 loss)
I0109 18:29:33.048761 32941 sgd_solver.cpp:112] Iteration 2580, lr = 0.001
speed: 0.379s / iter
I0109 18:29:40.511507 32941 solver.cpp:239] Iteration 2600 (2.68006 iter/s, 7.46252s/20 iters), loss = 0.529575
I0109 18:29:40.511567 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.245932 (* 1 = 0.245932 loss)
I0109 18:29:40.511576 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.176543 (* 1 = 0.176543 loss)
I0109 18:29:40.511584 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0853133 (* 1 = 0.0853133 loss)
I0109 18:29:40.511590 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0854635 (* 1 = 0.0854635 loss)
I0109 18:29:40.511598 32941 sgd_solver.cpp:112] Iteration 2600, lr = 0.001
I0109 18:29:47.945583 32941 solver.cpp:239] Iteration 2620 (2.69043 iter/s, 7.43376s/20 iters), loss = 0.146168
I0109 18:29:47.945657 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0735384 (* 1 = 0.0735384 loss)
I0109 18:29:47.945667 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0393036 (* 1 = 0.0393036 loss)
I0109 18:29:47.945673 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0136656 (* 1 = 0.0136656 loss)
I0109 18:29:47.945679 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0169 (* 1 = 0.0169 loss)
I0109 18:29:47.945688 32941 sgd_solver.cpp:112] Iteration 2620, lr = 0.001
I0109 18:29:55.752235 32941 solver.cpp:239] Iteration 2640 (2.56203 iter/s, 7.8063s/20 iters), loss = 0.384572
I0109 18:29:55.752346 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.154203 (* 1 = 0.154203 loss)
I0109 18:29:55.752362 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.100601 (* 1 = 0.100601 loss)
I0109 18:29:55.752375 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0618291 (* 1 = 0.0618291 loss)
I0109 18:29:55.752388 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.250789 (* 1 = 0.250789 loss)
I0109 18:29:55.752408 32941 sgd_solver.cpp:112] Iteration 2640, lr = 0.001
I0109 18:30:03.105520 32941 solver.cpp:239] Iteration 2660 (2.72 iter/s, 7.35293s/20 iters), loss = 0.209099
I0109 18:30:03.105590 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.130136 (* 1 = 0.130136 loss)
I0109 18:30:03.105599 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.118974 (* 1 = 0.118974 loss)
I0109 18:30:03.105607 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00635933 (* 1 = 0.00635933 loss)
I0109 18:30:03.105613 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0119456 (* 1 = 0.0119456 loss)
I0109 18:30:03.105621 32941 sgd_solver.cpp:112] Iteration 2660, lr = 0.001
I0109 18:30:10.769851 32941 solver.cpp:239] Iteration 2680 (2.6096 iter/s, 7.66401s/20 iters), loss = 0.188742
I0109 18:30:10.769917 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.124375 (* 1 = 0.124375 loss)
I0109 18:30:10.769925 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0358134 (* 1 = 0.0358134 loss)
I0109 18:30:10.769932 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0161176 (* 1 = 0.0161176 loss)
I0109 18:30:10.769938 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0123597 (* 1 = 0.0123597 loss)
I0109 18:30:10.769945 32941 sgd_solver.cpp:112] Iteration 2680, lr = 0.001
I0109 18:30:18.316524 32941 solver.cpp:239] Iteration 2700 (2.65029 iter/s, 7.54635s/20 iters), loss = 0.320168
I0109 18:30:18.316606 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0849942 (* 1 = 0.0849942 loss)
I0109 18:30:18.316617 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0884593 (* 1 = 0.0884593 loss)
I0109 18:30:18.316623 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0191989 (* 1 = 0.0191989 loss)
I0109 18:30:18.316630 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0136306 (* 1 = 0.0136306 loss)
I0109 18:30:18.316638 32941 sgd_solver.cpp:112] Iteration 2700, lr = 0.001
I0109 18:30:25.687176 32941 solver.cpp:239] Iteration 2720 (2.71358 iter/s, 7.37034s/20 iters), loss = 0.332115
I0109 18:30:25.687233 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0856962 (* 1 = 0.0856962 loss)
I0109 18:30:25.687243 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0680815 (* 1 = 0.0680815 loss)
I0109 18:30:25.687250 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00243949 (* 1 = 0.00243949 loss)
I0109 18:30:25.687256 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00626474 (* 1 = 0.00626474 loss)
I0109 18:30:25.687263 32941 sgd_solver.cpp:112] Iteration 2720, lr = 0.001
I0109 18:30:33.236069 32941 solver.cpp:239] Iteration 2740 (2.6495 iter/s, 7.54859s/20 iters), loss = 0.225013
I0109 18:30:33.236122 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0787388 (* 1 = 0.0787388 loss)
I0109 18:30:33.236131 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0231039 (* 1 = 0.0231039 loss)
I0109 18:30:33.236137 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00555047 (* 1 = 0.00555047 loss)
I0109 18:30:33.236145 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00713578 (* 1 = 0.00713578 loss)
I0109 18:30:33.236151 32941 sgd_solver.cpp:112] Iteration 2740, lr = 0.001
I0109 18:30:40.839414 32941 solver.cpp:239] Iteration 2760 (2.63053 iter/s, 7.60303s/20 iters), loss = 0.387389
I0109 18:30:40.839476 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.238594 (* 1 = 0.238594 loss)
I0109 18:30:40.839485 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.252834 (* 1 = 0.252834 loss)
I0109 18:30:40.839493 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.025516 (* 1 = 0.025516 loss)
I0109 18:30:40.839499 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0137818 (* 1 = 0.0137818 loss)
I0109 18:30:40.839509 32941 sgd_solver.cpp:112] Iteration 2760, lr = 0.001
I0109 18:30:48.239763 32941 solver.cpp:239] Iteration 2780 (2.70269 iter/s, 7.40002s/20 iters), loss = 0.249778
I0109 18:30:48.239833 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.098839 (* 1 = 0.098839 loss)
I0109 18:30:48.239843 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0617397 (* 1 = 0.0617397 loss)
I0109 18:30:48.239850 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0805692 (* 1 = 0.0805692 loss)
I0109 18:30:48.239857 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00401252 (* 1 = 0.00401252 loss)
I0109 18:30:48.239864 32941 sgd_solver.cpp:112] Iteration 2780, lr = 0.001
speed: 0.379s / iter
I0109 18:30:55.721813 32941 solver.cpp:239] Iteration 2800 (2.67318 iter/s, 7.48174s/20 iters), loss = 0.296081
I0109 18:30:55.721869 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.00286501 (* 1 = 0.00286501 loss)
I0109 18:30:55.721879 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.134957 (* 1 = 0.134957 loss)
I0109 18:30:55.721884 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0801081 (* 1 = 0.0801081 loss)
I0109 18:30:55.721891 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0523458 (* 1 = 0.0523458 loss)
I0109 18:30:55.721897 32941 sgd_solver.cpp:112] Iteration 2800, lr = 0.001
I0109 18:31:03.513027 32941 solver.cpp:239] Iteration 2820 (2.5671 iter/s, 7.79088s/20 iters), loss = 0.399573
I0109 18:31:03.513101 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.132752 (* 1 = 0.132752 loss)
I0109 18:31:03.513118 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.368353 (* 1 = 0.368353 loss)
I0109 18:31:03.513128 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0154145 (* 1 = 0.0154145 loss)
I0109 18:31:03.513139 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00523016 (* 1 = 0.00523016 loss)
I0109 18:31:03.513146 32941 sgd_solver.cpp:112] Iteration 2820, lr = 0.001
I0109 18:31:11.067800 32941 solver.cpp:239] Iteration 2840 (2.64745 iter/s, 7.55442s/20 iters), loss = 0.389302
I0109 18:31:11.067867 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.163183 (* 1 = 0.163183 loss)
I0109 18:31:11.067878 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.308113 (* 1 = 0.308113 loss)
I0109 18:31:11.067886 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0100449 (* 1 = 0.0100449 loss)
I0109 18:31:11.067898 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00321819 (* 1 = 0.00321819 loss)
I0109 18:31:11.067909 32941 sgd_solver.cpp:112] Iteration 2840, lr = 0.001
I0109 18:31:18.767957 32941 solver.cpp:239] Iteration 2860 (2.59746 iter/s, 7.69982s/20 iters), loss = 0.261024
I0109 18:31:18.768033 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.184588 (* 1 = 0.184588 loss)
I0109 18:31:18.768043 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0646634 (* 1 = 0.0646634 loss)
I0109 18:31:18.768049 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00285621 (* 1 = 0.00285621 loss)
I0109 18:31:18.768056 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00743902 (* 1 = 0.00743902 loss)
I0109 18:31:18.768064 32941 sgd_solver.cpp:112] Iteration 2860, lr = 0.001
I0109 18:31:26.410959 32941 solver.cpp:239] Iteration 2880 (2.61689 iter/s, 7.64266s/20 iters), loss = 0.211748
I0109 18:31:26.411026 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0736287 (* 1 = 0.0736287 loss)
I0109 18:31:26.411036 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0905257 (* 1 = 0.0905257 loss)
I0109 18:31:26.411043 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00478871 (* 1 = 0.00478871 loss)
I0109 18:31:26.411049 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0103208 (* 1 = 0.0103208 loss)
I0109 18:31:26.411057 32941 sgd_solver.cpp:112] Iteration 2880, lr = 0.001
I0109 18:31:34.107064 32941 solver.cpp:239] Iteration 2900 (2.59882 iter/s, 7.69579s/20 iters), loss = 0.203912
I0109 18:31:34.107116 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.102187 (* 1 = 0.102187 loss)
I0109 18:31:34.107125 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0532514 (* 1 = 0.0532514 loss)
I0109 18:31:34.107131 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0412073 (* 1 = 0.0412073 loss)
I0109 18:31:34.107139 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00447833 (* 1 = 0.00447833 loss)
I0109 18:31:34.107146 32941 sgd_solver.cpp:112] Iteration 2900, lr = 0.001
I0109 18:31:41.688091 32941 solver.cpp:239] Iteration 2920 (2.63827 iter/s, 7.58071s/20 iters), loss = 0.33545
I0109 18:31:41.688169 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.167893 (* 1 = 0.167893 loss)
I0109 18:31:41.688177 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0885235 (* 1 = 0.0885235 loss)
I0109 18:31:41.688184 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0583772 (* 1 = 0.0583772 loss)
I0109 18:31:41.688190 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0291649 (* 1 = 0.0291649 loss)
I0109 18:31:41.688210 32941 sgd_solver.cpp:112] Iteration 2920, lr = 0.001
I0109 18:31:49.117470 32941 solver.cpp:239] Iteration 2940 (2.69214 iter/s, 7.42905s/20 iters), loss = 0.142628
I0109 18:31:49.117540 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0539769 (* 1 = 0.0539769 loss)
I0109 18:31:49.117550 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.066697 (* 1 = 0.066697 loss)
I0109 18:31:49.117558 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00675149 (* 1 = 0.00675149 loss)
I0109 18:31:49.117563 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00256159 (* 1 = 0.00256159 loss)
I0109 18:31:49.117571 32941 sgd_solver.cpp:112] Iteration 2940, lr = 0.001
I0109 18:31:56.622102 32941 solver.cpp:239] Iteration 2960 (2.66514 iter/s, 7.50431s/20 iters), loss = 0.197511
I0109 18:31:56.622181 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0780779 (* 1 = 0.0780779 loss)
I0109 18:31:56.622191 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0211827 (* 1 = 0.0211827 loss)
I0109 18:31:56.622198 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00234826 (* 1 = 0.00234826 loss)
I0109 18:31:56.622205 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00195355 (* 1 = 0.00195355 loss)
I0109 18:31:56.622212 32941 sgd_solver.cpp:112] Iteration 2960, lr = 0.001
I0109 18:32:03.989500 32941 solver.cpp:239] Iteration 2980 (2.71478 iter/s, 7.36708s/20 iters), loss = 0.271235
I0109 18:32:03.989558 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.131695 (* 1 = 0.131695 loss)
I0109 18:32:03.989567 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0427155 (* 1 = 0.0427155 loss)
I0109 18:32:03.989574 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0117723 (* 1 = 0.0117723 loss)
I0109 18:32:03.989581 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0027809 (* 1 = 0.0027809 loss)
I0109 18:32:03.989590 32941 sgd_solver.cpp:112] Iteration 2980, lr = 0.001
speed: 0.379s / iter
I0109 18:32:11.394511 32941 solver.cpp:239] Iteration 3000 (2.70099 iter/s, 7.40469s/20 iters), loss = 0.257492
I0109 18:32:11.394585 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0391497 (* 1 = 0.0391497 loss)
I0109 18:32:11.394596 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0768432 (* 1 = 0.0768432 loss)
I0109 18:32:11.394605 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00124926 (* 1 = 0.00124926 loss)
I0109 18:32:11.394613 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00379625 (* 1 = 0.00379625 loss)
I0109 18:32:11.394621 32941 sgd_solver.cpp:112] Iteration 3000, lr = 0.001
I0109 18:32:18.848847 32941 solver.cpp:239] Iteration 3020 (2.68312 iter/s, 7.45401s/20 iters), loss = 0.296515
I0109 18:32:18.848913 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.18555 (* 1 = 0.18555 loss)
I0109 18:32:18.848923 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.132713 (* 1 = 0.132713 loss)
I0109 18:32:18.848930 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0252342 (* 1 = 0.0252342 loss)
I0109 18:32:18.848937 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00624276 (* 1 = 0.00624276 loss)
I0109 18:32:18.848944 32941 sgd_solver.cpp:112] Iteration 3020, lr = 0.001
I0109 18:32:26.386741 32941 solver.cpp:239] Iteration 3040 (2.65337 iter/s, 7.53757s/20 iters), loss = 0.520025
I0109 18:32:26.386803 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.237895 (* 1 = 0.237895 loss)
I0109 18:32:26.386812 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.17418 (* 1 = 0.17418 loss)
I0109 18:32:26.386819 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0385753 (* 1 = 0.0385753 loss)
I0109 18:32:26.386826 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0791675 (* 1 = 0.0791675 loss)
I0109 18:32:26.386833 32941 sgd_solver.cpp:112] Iteration 3040, lr = 0.001
I0109 18:32:34.121469 32941 solver.cpp:239] Iteration 3060 (2.58585 iter/s, 7.7344s/20 iters), loss = 0.126596
I0109 18:32:34.121536 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0736131 (* 1 = 0.0736131 loss)
I0109 18:32:34.121544 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0443905 (* 1 = 0.0443905 loss)
I0109 18:32:34.121551 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00788679 (* 1 = 0.00788679 loss)
I0109 18:32:34.121558 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000666772 (* 1 = 0.000666772 loss)
I0109 18:32:34.121567 32941 sgd_solver.cpp:112] Iteration 3060, lr = 0.001
I0109 18:32:41.727849 32941 solver.cpp:239] Iteration 3080 (2.62948 iter/s, 7.60605s/20 iters), loss = 0.244584
I0109 18:32:41.727910 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.13318 (* 1 = 0.13318 loss)
I0109 18:32:41.727921 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.133003 (* 1 = 0.133003 loss)
I0109 18:32:41.727927 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0719104 (* 1 = 0.0719104 loss)
I0109 18:32:41.727933 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00997013 (* 1 = 0.00997013 loss)
I0109 18:32:41.727942 32941 sgd_solver.cpp:112] Iteration 3080, lr = 0.001
I0109 18:32:49.333727 32941 solver.cpp:239] Iteration 3100 (2.62966 iter/s, 7.60555s/20 iters), loss = 0.437251
I0109 18:32:49.333801 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.188279 (* 1 = 0.188279 loss)
I0109 18:32:49.333819 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.490535 (* 1 = 0.490535 loss)
I0109 18:32:49.333845 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0083629 (* 1 = 0.0083629 loss)
I0109 18:32:49.333861 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00564926 (* 1 = 0.00564926 loss)
I0109 18:32:49.333870 32941 sgd_solver.cpp:112] Iteration 3100, lr = 0.001
I0109 18:32:56.856293 32941 solver.cpp:239] Iteration 3120 (2.65878 iter/s, 7.52225s/20 iters), loss = 0.256478
I0109 18:32:56.856360 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.120874 (* 1 = 0.120874 loss)
I0109 18:32:56.856370 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.112442 (* 1 = 0.112442 loss)
I0109 18:32:56.856377 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0318822 (* 1 = 0.0318822 loss)
I0109 18:32:56.856384 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00994637 (* 1 = 0.00994637 loss)
I0109 18:32:56.856391 32941 sgd_solver.cpp:112] Iteration 3120, lr = 0.001
I0109 18:33:04.474279 32941 solver.cpp:239] Iteration 3140 (2.62547 iter/s, 7.61767s/20 iters), loss = 0.300992
I0109 18:33:04.474335 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0716041 (* 1 = 0.0716041 loss)
I0109 18:33:04.474344 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.10408 (* 1 = 0.10408 loss)
I0109 18:33:04.474350 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00240743 (* 1 = 0.00240743 loss)
I0109 18:33:04.474356 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000757579 (* 1 = 0.000757579 loss)
I0109 18:33:04.474365 32941 sgd_solver.cpp:112] Iteration 3140, lr = 0.001
I0109 18:33:11.934428 32941 solver.cpp:239] Iteration 3160 (2.68102 iter/s, 7.45984s/20 iters), loss = 0.34361
I0109 18:33:11.934489 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.167535 (* 1 = 0.167535 loss)
I0109 18:33:11.934497 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.190207 (* 1 = 0.190207 loss)
I0109 18:33:11.934504 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0124646 (* 1 = 0.0124646 loss)
I0109 18:33:11.934511 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0115508 (* 1 = 0.0115508 loss)
I0109 18:33:11.934520 32941 sgd_solver.cpp:112] Iteration 3160, lr = 0.001
I0109 18:33:19.354672 32941 solver.cpp:239] Iteration 3180 (2.69544 iter/s, 7.41993s/20 iters), loss = 0.107345
I0109 18:33:19.354732 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0931796 (* 1 = 0.0931796 loss)
I0109 18:33:19.354740 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0563305 (* 1 = 0.0563305 loss)
I0109 18:33:19.354748 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00204763 (* 1 = 0.00204763 loss)
I0109 18:33:19.354753 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00347569 (* 1 = 0.00347569 loss)
I0109 18:33:19.354759 32941 sgd_solver.cpp:112] Iteration 3180, lr = 0.001
speed: 0.379s / iter
I0109 18:33:26.866878 32941 solver.cpp:239] Iteration 3200 (2.66244 iter/s, 7.5119s/20 iters), loss = 0.103746
I0109 18:33:26.866945 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0653225 (* 1 = 0.0653225 loss)
I0109 18:33:26.866955 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0416252 (* 1 = 0.0416252 loss)
I0109 18:33:26.866962 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0204319 (* 1 = 0.0204319 loss)
I0109 18:33:26.866968 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00316402 (* 1 = 0.00316402 loss)
I0109 18:33:26.866976 32941 sgd_solver.cpp:112] Iteration 3200, lr = 0.001
I0109 18:33:34.473707 32941 solver.cpp:239] Iteration 3220 (2.62933 iter/s, 7.60651s/20 iters), loss = 0.424583
I0109 18:33:34.473774 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0215433 (* 1 = 0.0215433 loss)
I0109 18:33:34.473784 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00734948 (* 1 = 0.00734948 loss)
I0109 18:33:34.473791 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0942964 (* 1 = 0.0942964 loss)
I0109 18:33:34.473798 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.251403 (* 1 = 0.251403 loss)
I0109 18:33:34.473805 32941 sgd_solver.cpp:112] Iteration 3220, lr = 0.001
I0109 18:33:41.841300 32941 solver.cpp:239] Iteration 3240 (2.71471 iter/s, 7.36728s/20 iters), loss = 0.438161
I0109 18:33:41.841367 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.130255 (* 1 = 0.130255 loss)
I0109 18:33:41.841377 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.532041 (* 1 = 0.532041 loss)
I0109 18:33:41.841383 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0256049 (* 1 = 0.0256049 loss)
I0109 18:33:41.841389 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00508082 (* 1 = 0.00508082 loss)
I0109 18:33:41.841397 32941 sgd_solver.cpp:112] Iteration 3240, lr = 0.001
I0109 18:33:49.279865 32941 solver.cpp:239] Iteration 3260 (2.68881 iter/s, 7.43824s/20 iters), loss = 0.246899
I0109 18:33:49.279937 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.272539 (* 1 = 0.272539 loss)
I0109 18:33:49.279947 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0827948 (* 1 = 0.0827948 loss)
I0109 18:33:49.279954 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0341419 (* 1 = 0.0341419 loss)
I0109 18:33:49.279961 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0275748 (* 1 = 0.0275748 loss)
I0109 18:33:49.279968 32941 sgd_solver.cpp:112] Iteration 3260, lr = 0.001
I0109 18:33:56.849941 32941 solver.cpp:239] Iteration 3280 (2.64209 iter/s, 7.56975s/20 iters), loss = 0.163824
I0109 18:33:56.850008 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0931767 (* 1 = 0.0931767 loss)
I0109 18:33:56.850018 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00991629 (* 1 = 0.00991629 loss)
I0109 18:33:56.850024 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0060842 (* 1 = 0.0060842 loss)
I0109 18:33:56.850031 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00170536 (* 1 = 0.00170536 loss)
I0109 18:33:56.850039 32941 sgd_solver.cpp:112] Iteration 3280, lr = 0.001
I0109 18:34:04.431535 32941 solver.cpp:239] Iteration 3300 (2.63808 iter/s, 7.58126s/20 iters), loss = 0.229512
I0109 18:34:04.431602 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.103857 (* 1 = 0.103857 loss)
I0109 18:34:04.431612 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.197356 (* 1 = 0.197356 loss)
I0109 18:34:04.431620 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0238004 (* 1 = 0.0238004 loss)
I0109 18:34:04.431627 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0287395 (* 1 = 0.0287395 loss)
I0109 18:34:04.431635 32941 sgd_solver.cpp:112] Iteration 3300, lr = 0.001
I0109 18:34:12.144630 32941 solver.cpp:239] Iteration 3320 (2.5931 iter/s, 7.71278s/20 iters), loss = 0.386412
I0109 18:34:12.144696 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.100773 (* 1 = 0.100773 loss)
I0109 18:34:12.144704 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0912918 (* 1 = 0.0912918 loss)
I0109 18:34:12.144711 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00146571 (* 1 = 0.00146571 loss)
I0109 18:34:12.144717 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00104698 (* 1 = 0.00104698 loss)
I0109 18:34:12.144724 32941 sgd_solver.cpp:112] Iteration 3320, lr = 0.001
I0109 18:34:19.570529 32941 solver.cpp:239] Iteration 3340 (2.69339 iter/s, 7.42558s/20 iters), loss = 0.148644
I0109 18:34:19.570595 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.15888 (* 1 = 0.15888 loss)
I0109 18:34:19.570603 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0337929 (* 1 = 0.0337929 loss)
I0109 18:34:19.570611 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00330736 (* 1 = 0.00330736 loss)
I0109 18:34:19.570616 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00222517 (* 1 = 0.00222517 loss)
I0109 18:34:19.570623 32941 sgd_solver.cpp:112] Iteration 3340, lr = 0.001
I0109 18:34:27.088848 32941 solver.cpp:239] Iteration 3360 (2.66028 iter/s, 7.51799s/20 iters), loss = 0.180285
I0109 18:34:27.088924 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0618599 (* 1 = 0.0618599 loss)
I0109 18:34:27.088934 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0269229 (* 1 = 0.0269229 loss)
I0109 18:34:27.088941 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.012999 (* 1 = 0.012999 loss)
I0109 18:34:27.088948 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00471069 (* 1 = 0.00471069 loss)
I0109 18:34:27.088955 32941 sgd_solver.cpp:112] Iteration 3360, lr = 0.001
I0109 18:34:34.582358 32941 solver.cpp:239] Iteration 3380 (2.66909 iter/s, 7.49319s/20 iters), loss = 0.392353
I0109 18:34:34.582422 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.27739 (* 1 = 0.27739 loss)
I0109 18:34:34.582432 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0936882 (* 1 = 0.0936882 loss)
I0109 18:34:34.582438 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0184181 (* 1 = 0.0184181 loss)
I0109 18:34:34.582444 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0239219 (* 1 = 0.0239219 loss)
I0109 18:34:34.582453 32941 sgd_solver.cpp:112] Iteration 3380, lr = 0.001
speed: 0.379s / iter
I0109 18:34:42.216928 32941 solver.cpp:239] Iteration 3400 (2.61977 iter/s, 7.63426s/20 iters), loss = 0.267102
I0109 18:34:42.216979 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0872018 (* 1 = 0.0872018 loss)
I0109 18:34:42.216987 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.217947 (* 1 = 0.217947 loss)
I0109 18:34:42.216994 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00293798 (* 1 = 0.00293798 loss)
I0109 18:34:42.217000 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00380131 (* 1 = 0.00380131 loss)
I0109 18:34:42.217006 32941 sgd_solver.cpp:112] Iteration 3400, lr = 0.001
I0109 18:34:49.730118 32941 solver.cpp:239] Iteration 3420 (2.6621 iter/s, 7.51287s/20 iters), loss = 0.192625
I0109 18:34:49.730221 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.105087 (* 1 = 0.105087 loss)
I0109 18:34:49.730239 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0786528 (* 1 = 0.0786528 loss)
I0109 18:34:49.730253 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00511888 (* 1 = 0.00511888 loss)
I0109 18:34:49.730265 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000690572 (* 1 = 0.000690572 loss)
I0109 18:34:49.730278 32941 sgd_solver.cpp:112] Iteration 3420, lr = 0.001
I0109 18:34:57.163388 32941 solver.cpp:239] Iteration 3440 (2.69073 iter/s, 7.43293s/20 iters), loss = 0.256276
I0109 18:34:57.163439 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.20141 (* 1 = 0.20141 loss)
I0109 18:34:57.163447 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.129585 (* 1 = 0.129585 loss)
I0109 18:34:57.163455 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.042663 (* 1 = 0.042663 loss)
I0109 18:34:57.163460 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0103618 (* 1 = 0.0103618 loss)
I0109 18:34:57.163466 32941 sgd_solver.cpp:112] Iteration 3440, lr = 0.001
I0109 18:35:04.567579 32941 solver.cpp:239] Iteration 3460 (2.70128 iter/s, 7.4039s/20 iters), loss = 0.161673
I0109 18:35:04.567631 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0744091 (* 1 = 0.0744091 loss)
I0109 18:35:04.567641 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0296791 (* 1 = 0.0296791 loss)
I0109 18:35:04.567647 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0258404 (* 1 = 0.0258404 loss)
I0109 18:35:04.567656 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00432087 (* 1 = 0.00432087 loss)
I0109 18:35:04.567662 32941 sgd_solver.cpp:112] Iteration 3460, lr = 0.001
I0109 18:35:12.032308 32941 solver.cpp:239] Iteration 3480 (2.67938 iter/s, 7.46442s/20 iters), loss = 0.383954
I0109 18:35:12.032372 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.163081 (* 1 = 0.163081 loss)
I0109 18:35:12.032388 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.168606 (* 1 = 0.168606 loss)
I0109 18:35:12.032398 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.108086 (* 1 = 0.108086 loss)
I0109 18:35:12.032408 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0448018 (* 1 = 0.0448018 loss)
I0109 18:35:12.032419 32941 sgd_solver.cpp:112] Iteration 3480, lr = 0.001
I0109 18:35:19.607724 32941 solver.cpp:239] Iteration 3500 (2.64023 iter/s, 7.57511s/20 iters), loss = 0.229102
I0109 18:35:19.607782 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116142 (* 1 = 0.116142 loss)
I0109 18:35:19.607791 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.061411 (* 1 = 0.061411 loss)
I0109 18:35:19.607798 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00785865 (* 1 = 0.00785865 loss)
I0109 18:35:19.607803 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0273042 (* 1 = 0.0273042 loss)
I0109 18:35:19.607810 32941 sgd_solver.cpp:112] Iteration 3500, lr = 0.001
I0109 18:35:27.188235 32941 solver.cpp:239] Iteration 3520 (2.63846 iter/s, 7.58019s/20 iters), loss = 0.11027
I0109 18:35:27.188303 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0700431 (* 1 = 0.0700431 loss)
I0109 18:35:27.188313 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0693218 (* 1 = 0.0693218 loss)
I0109 18:35:27.188319 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0022101 (* 1 = 0.0022101 loss)
I0109 18:35:27.188325 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000103969 (* 1 = 0.000103969 loss)
I0109 18:35:27.188334 32941 sgd_solver.cpp:112] Iteration 3520, lr = 0.001
I0109 18:35:34.916297 32941 solver.cpp:239] Iteration 3540 (2.58808 iter/s, 7.72773s/20 iters), loss = 0.213848
I0109 18:35:34.916376 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0533542 (* 1 = 0.0533542 loss)
I0109 18:35:34.916385 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0990631 (* 1 = 0.0990631 loss)
I0109 18:35:34.916393 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0233605 (* 1 = 0.0233605 loss)
I0109 18:35:34.916399 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00772512 (* 1 = 0.00772512 loss)
I0109 18:35:34.916406 32941 sgd_solver.cpp:112] Iteration 3540, lr = 0.001
I0109 18:35:42.307574 32941 solver.cpp:239] Iteration 3560 (2.70601 iter/s, 7.39096s/20 iters), loss = 0.193431
I0109 18:35:42.307621 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0496069 (* 1 = 0.0496069 loss)
I0109 18:35:42.307631 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0268352 (* 1 = 0.0268352 loss)
I0109 18:35:42.307637 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0189083 (* 1 = 0.0189083 loss)
I0109 18:35:42.307643 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00417646 (* 1 = 0.00417646 loss)
I0109 18:35:42.307649 32941 sgd_solver.cpp:112] Iteration 3560, lr = 0.001
I0109 18:35:49.935539 32941 solver.cpp:239] Iteration 3580 (2.62204 iter/s, 7.62765s/20 iters), loss = 0.238486
I0109 18:35:49.935600 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116873 (* 1 = 0.116873 loss)
I0109 18:35:49.935614 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.180038 (* 1 = 0.180038 loss)
I0109 18:35:49.935622 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00536838 (* 1 = 0.00536838 loss)
I0109 18:35:49.935628 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00297418 (* 1 = 0.00297418 loss)
I0109 18:35:49.935636 32941 sgd_solver.cpp:112] Iteration 3580, lr = 0.001
speed: 0.379s / iter
I0109 18:35:57.467411 32941 solver.cpp:239] Iteration 3600 (2.65549 iter/s, 7.53156s/20 iters), loss = 0.238672
I0109 18:35:57.467463 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.118804 (* 1 = 0.118804 loss)
I0109 18:35:57.467473 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.192457 (* 1 = 0.192457 loss)
I0109 18:35:57.467479 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0110972 (* 1 = 0.0110972 loss)
I0109 18:35:57.467486 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00723895 (* 1 = 0.00723895 loss)
I0109 18:35:57.467494 32941 sgd_solver.cpp:112] Iteration 3600, lr = 0.001
I0109 18:36:05.205235 32941 solver.cpp:239] Iteration 3620 (2.58481 iter/s, 7.73751s/20 iters), loss = 0.295937
I0109 18:36:05.205298 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.127414 (* 1 = 0.127414 loss)
I0109 18:36:05.205308 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.338385 (* 1 = 0.338385 loss)
I0109 18:36:05.205315 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0207762 (* 1 = 0.0207762 loss)
I0109 18:36:05.205322 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00482606 (* 1 = 0.00482606 loss)
I0109 18:36:05.205329 32941 sgd_solver.cpp:112] Iteration 3620, lr = 0.001
I0109 18:36:12.682603 32941 solver.cpp:239] Iteration 3640 (2.67486 iter/s, 7.47704s/20 iters), loss = 0.153538
I0109 18:36:12.682677 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.110794 (* 1 = 0.110794 loss)
I0109 18:36:12.682687 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0696115 (* 1 = 0.0696115 loss)
I0109 18:36:12.682694 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00958453 (* 1 = 0.00958453 loss)
I0109 18:36:12.682701 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0196395 (* 1 = 0.0196395 loss)
I0109 18:36:12.682708 32941 sgd_solver.cpp:112] Iteration 3640, lr = 0.001
I0109 18:36:20.103420 32941 solver.cpp:239] Iteration 3660 (2.69524 iter/s, 7.42048s/20 iters), loss = 0.224571
I0109 18:36:20.103515 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0278957 (* 1 = 0.0278957 loss)
I0109 18:36:20.103530 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0659178 (* 1 = 0.0659178 loss)
I0109 18:36:20.103541 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0292134 (* 1 = 0.0292134 loss)
I0109 18:36:20.103552 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00762643 (* 1 = 0.00762643 loss)
I0109 18:36:20.103564 32941 sgd_solver.cpp:112] Iteration 3660, lr = 0.001
I0109 18:36:27.495064 32941 solver.cpp:239] Iteration 3680 (2.70589 iter/s, 7.39128s/20 iters), loss = 0.419734
I0109 18:36:27.495175 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.183894 (* 1 = 0.183894 loss)
I0109 18:36:27.495194 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.317724 (* 1 = 0.317724 loss)
I0109 18:36:27.495208 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0695273 (* 1 = 0.0695273 loss)
I0109 18:36:27.495220 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0108541 (* 1 = 0.0108541 loss)
I0109 18:36:27.495232 32941 sgd_solver.cpp:112] Iteration 3680, lr = 0.001
I0109 18:36:35.153285 32941 solver.cpp:239] Iteration 3700 (2.6117 iter/s, 7.65786s/20 iters), loss = 0.226643
I0109 18:36:35.153342 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.107416 (* 1 = 0.107416 loss)
I0109 18:36:35.153350 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0639812 (* 1 = 0.0639812 loss)
I0109 18:36:35.153357 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0173758 (* 1 = 0.0173758 loss)
I0109 18:36:35.153363 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0157502 (* 1 = 0.0157502 loss)
I0109 18:36:35.153371 32941 sgd_solver.cpp:112] Iteration 3700, lr = 0.001
I0109 18:36:42.589999 32941 solver.cpp:239] Iteration 3720 (2.68947 iter/s, 7.43641s/20 iters), loss = 0.362586
I0109 18:36:42.590060 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.101018 (* 1 = 0.101018 loss)
I0109 18:36:42.590070 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.135183 (* 1 = 0.135183 loss)
I0109 18:36:42.590075 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0151525 (* 1 = 0.0151525 loss)
I0109 18:36:42.590081 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00444494 (* 1 = 0.00444494 loss)
I0109 18:36:42.590090 32941 sgd_solver.cpp:112] Iteration 3720, lr = 0.001
I0109 18:36:50.025606 32941 solver.cpp:239] Iteration 3740 (2.68988 iter/s, 7.43528s/20 iters), loss = 0.160612
I0109 18:36:50.025676 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0352806 (* 1 = 0.0352806 loss)
I0109 18:36:50.025686 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0468977 (* 1 = 0.0468977 loss)
I0109 18:36:50.025693 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0135069 (* 1 = 0.0135069 loss)
I0109 18:36:50.025701 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000594323 (* 1 = 0.000594323 loss)
I0109 18:36:50.025708 32941 sgd_solver.cpp:112] Iteration 3740, lr = 0.001
I0109 18:36:57.605610 32941 solver.cpp:239] Iteration 3760 (2.63864 iter/s, 7.57968s/20 iters), loss = 0.489691
I0109 18:36:57.605674 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.115742 (* 1 = 0.115742 loss)
I0109 18:36:57.605684 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.476025 (* 1 = 0.476025 loss)
I0109 18:36:57.605690 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0174986 (* 1 = 0.0174986 loss)
I0109 18:36:57.605696 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.037184 (* 1 = 0.037184 loss)
I0109 18:36:57.605706 32941 sgd_solver.cpp:112] Iteration 3760, lr = 0.001
I0109 18:37:05.155231 32941 solver.cpp:239] Iteration 3780 (2.64925 iter/s, 7.5493s/20 iters), loss = 0.250448
I0109 18:37:05.155293 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.12465 (* 1 = 0.12465 loss)
I0109 18:37:05.155303 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0545543 (* 1 = 0.0545543 loss)
I0109 18:37:05.155309 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0126678 (* 1 = 0.0126678 loss)
I0109 18:37:05.155316 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00747563 (* 1 = 0.00747563 loss)
I0109 18:37:05.155324 32941 sgd_solver.cpp:112] Iteration 3780, lr = 0.001
speed: 0.379s / iter
I0109 18:37:12.543839 32941 solver.cpp:239] Iteration 3800 (2.70698 iter/s, 7.3883s/20 iters), loss = 0.228477
I0109 18:37:12.543906 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0550181 (* 1 = 0.0550181 loss)
I0109 18:37:12.543916 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.3212 (* 1 = 0.3212 loss)
I0109 18:37:12.543923 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0086668 (* 1 = 0.0086668 loss)
I0109 18:37:12.543929 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00182893 (* 1 = 0.00182893 loss)
I0109 18:37:12.543937 32941 sgd_solver.cpp:112] Iteration 3800, lr = 0.001
I0109 18:37:20.147591 32941 solver.cpp:239] Iteration 3820 (2.63039 iter/s, 7.60343s/20 iters), loss = 0.319536
I0109 18:37:20.147653 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.251786 (* 1 = 0.251786 loss)
I0109 18:37:20.147662 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.147265 (* 1 = 0.147265 loss)
I0109 18:37:20.147670 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0407321 (* 1 = 0.0407321 loss)
I0109 18:37:20.147676 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00600804 (* 1 = 0.00600804 loss)
I0109 18:37:20.147684 32941 sgd_solver.cpp:112] Iteration 3820, lr = 0.001
I0109 18:37:27.655261 32941 solver.cpp:239] Iteration 3840 (2.66406 iter/s, 7.50735s/20 iters), loss = 0.200058
I0109 18:37:27.655331 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.161711 (* 1 = 0.161711 loss)
I0109 18:37:27.655341 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0636463 (* 1 = 0.0636463 loss)
I0109 18:37:27.655349 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00877669 (* 1 = 0.00877669 loss)
I0109 18:37:27.655354 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00275582 (* 1 = 0.00275582 loss)
I0109 18:37:27.655362 32941 sgd_solver.cpp:112] Iteration 3840, lr = 0.001
I0109 18:37:35.237424 32941 solver.cpp:239] Iteration 3860 (2.63788 iter/s, 7.58184s/20 iters), loss = 0.21047
I0109 18:37:35.237485 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.141932 (* 1 = 0.141932 loss)
I0109 18:37:35.237495 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0418999 (* 1 = 0.0418999 loss)
I0109 18:37:35.237502 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00349979 (* 1 = 0.00349979 loss)
I0109 18:37:35.237509 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00498025 (* 1 = 0.00498025 loss)
I0109 18:37:35.237516 32941 sgd_solver.cpp:112] Iteration 3860, lr = 0.001
I0109 18:37:42.827781 32941 solver.cpp:239] Iteration 3880 (2.63503 iter/s, 7.59003s/20 iters), loss = 0.117024
I0109 18:37:42.827842 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0135578 (* 1 = 0.0135578 loss)
I0109 18:37:42.827852 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0449364 (* 1 = 0.0449364 loss)
I0109 18:37:42.827859 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00273469 (* 1 = 0.00273469 loss)
I0109 18:37:42.827865 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00145625 (* 1 = 0.00145625 loss)
I0109 18:37:42.827873 32941 sgd_solver.cpp:112] Iteration 3880, lr = 0.001
I0109 18:37:50.268541 32941 solver.cpp:239] Iteration 3900 (2.68801 iter/s, 7.44045s/20 iters), loss = 0.438587
I0109 18:37:50.268604 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.199717 (* 1 = 0.199717 loss)
I0109 18:37:50.268612 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.3625 (* 1 = 0.3625 loss)
I0109 18:37:50.268620 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0089247 (* 1 = 0.0089247 loss)
I0109 18:37:50.268626 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00849396 (* 1 = 0.00849396 loss)
I0109 18:37:50.268633 32941 sgd_solver.cpp:112] Iteration 3900, lr = 0.001
I0109 18:37:57.714778 32941 solver.cpp:239] Iteration 3920 (2.68603 iter/s, 7.44592s/20 iters), loss = 0.549957
I0109 18:37:57.714852 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.145289 (* 1 = 0.145289 loss)
I0109 18:37:57.714862 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.707308 (* 1 = 0.707308 loss)
I0109 18:37:57.714869 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0101578 (* 1 = 0.0101578 loss)
I0109 18:37:57.714876 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00183834 (* 1 = 0.00183834 loss)
I0109 18:37:57.714884 32941 sgd_solver.cpp:112] Iteration 3920, lr = 0.001
I0109 18:38:05.515146 32941 solver.cpp:239] Iteration 3940 (2.56409 iter/s, 7.80004s/20 iters), loss = 0.355813
I0109 18:38:05.515208 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.104162 (* 1 = 0.104162 loss)
I0109 18:38:05.515218 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0431124 (* 1 = 0.0431124 loss)
I0109 18:38:05.515225 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00795731 (* 1 = 0.00795731 loss)
I0109 18:38:05.515231 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00612808 (* 1 = 0.00612808 loss)
I0109 18:38:05.515239 32941 sgd_solver.cpp:112] Iteration 3940, lr = 0.001
I0109 18:38:13.102627 32941 solver.cpp:239] Iteration 3960 (2.63603 iter/s, 7.58715s/20 iters), loss = 0.364673
I0109 18:38:13.102692 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.102485 (* 1 = 0.102485 loss)
I0109 18:38:13.102702 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.24422 (* 1 = 0.24422 loss)
I0109 18:38:13.102710 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0184109 (* 1 = 0.0184109 loss)
I0109 18:38:13.102716 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00317265 (* 1 = 0.00317265 loss)
I0109 18:38:13.102725 32941 sgd_solver.cpp:112] Iteration 3960, lr = 0.001
I0109 18:38:20.700456 32941 solver.cpp:239] Iteration 3980 (2.63244 iter/s, 7.5975s/20 iters), loss = 0.841423
I0109 18:38:20.700526 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.246616 (* 1 = 0.246616 loss)
I0109 18:38:20.700536 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.148402 (* 1 = 0.148402 loss)
I0109 18:38:20.700543 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.038862 (* 1 = 0.038862 loss)
I0109 18:38:20.700551 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0198321 (* 1 = 0.0198321 loss)
I0109 18:38:20.700558 32941 sgd_solver.cpp:112] Iteration 3980, lr = 0.001
speed: 0.378s / iter
I0109 18:38:28.247218 32941 solver.cpp:239] Iteration 4000 (2.65026 iter/s, 7.54643s/20 iters), loss = 0.357935
I0109 18:38:28.247284 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.104101 (* 1 = 0.104101 loss)
I0109 18:38:28.247294 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0911075 (* 1 = 0.0911075 loss)
I0109 18:38:28.247301 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00085432 (* 1 = 0.00085432 loss)
I0109 18:38:28.247308 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00954925 (* 1 = 0.00954925 loss)
I0109 18:38:28.247315 32941 sgd_solver.cpp:112] Iteration 4000, lr = 0.001
I0109 18:38:35.650480 32941 solver.cpp:239] Iteration 4020 (2.70163 iter/s, 7.40294s/20 iters), loss = 0.275745
I0109 18:38:35.650544 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.150021 (* 1 = 0.150021 loss)
I0109 18:38:35.650554 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.205107 (* 1 = 0.205107 loss)
I0109 18:38:35.650563 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00190655 (* 1 = 0.00190655 loss)
I0109 18:38:35.650569 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00235404 (* 1 = 0.00235404 loss)
I0109 18:38:35.650578 32941 sgd_solver.cpp:112] Iteration 4020, lr = 0.001
I0109 18:38:43.051136 32941 solver.cpp:239] Iteration 4040 (2.70258 iter/s, 7.40033s/20 iters), loss = 0.215627
I0109 18:38:43.051204 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0908014 (* 1 = 0.0908014 loss)
I0109 18:38:43.051214 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0458077 (* 1 = 0.0458077 loss)
I0109 18:38:43.051223 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00916866 (* 1 = 0.00916866 loss)
I0109 18:38:43.051229 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0326931 (* 1 = 0.0326931 loss)
I0109 18:38:43.051237 32941 sgd_solver.cpp:112] Iteration 4040, lr = 0.001
I0109 18:38:50.453830 32941 solver.cpp:239] Iteration 4060 (2.70184 iter/s, 7.40236s/20 iters), loss = 0.135983
I0109 18:38:50.453899 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.014963 (* 1 = 0.014963 loss)
I0109 18:38:50.453910 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0934464 (* 1 = 0.0934464 loss)
I0109 18:38:50.453917 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0815295 (* 1 = 0.0815295 loss)
I0109 18:38:50.453924 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0276009 (* 1 = 0.0276009 loss)
I0109 18:38:50.453933 32941 sgd_solver.cpp:112] Iteration 4060, lr = 0.001
I0109 18:38:57.922425 32941 solver.cpp:239] Iteration 4080 (2.678 iter/s, 7.46827s/20 iters), loss = 0.366266
I0109 18:38:57.922485 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.216747 (* 1 = 0.216747 loss)
I0109 18:38:57.922495 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.236156 (* 1 = 0.236156 loss)
I0109 18:38:57.922502 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0292822 (* 1 = 0.0292822 loss)
I0109 18:38:57.922508 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0209922 (* 1 = 0.0209922 loss)
I0109 18:38:57.922516 32941 sgd_solver.cpp:112] Iteration 4080, lr = 0.001
I0109 18:39:05.333873 32941 solver.cpp:239] Iteration 4100 (2.69864 iter/s, 7.41113s/20 iters), loss = 0.200012
I0109 18:39:05.333942 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0825276 (* 1 = 0.0825276 loss)
I0109 18:39:05.333952 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.027036 (* 1 = 0.027036 loss)
I0109 18:39:05.333959 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00487774 (* 1 = 0.00487774 loss)
I0109 18:39:05.333966 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00680984 (* 1 = 0.00680984 loss)
I0109 18:39:05.333974 32941 sgd_solver.cpp:112] Iteration 4100, lr = 0.001
I0109 18:39:12.701522 32941 solver.cpp:239] Iteration 4120 (2.71469 iter/s, 7.36732s/20 iters), loss = 0.158267
I0109 18:39:12.701588 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.105006 (* 1 = 0.105006 loss)
I0109 18:39:12.701599 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0740306 (* 1 = 0.0740306 loss)
I0109 18:39:12.701606 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0159477 (* 1 = 0.0159477 loss)
I0109 18:39:12.701612 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00790847 (* 1 = 0.00790847 loss)
I0109 18:39:12.701620 32941 sgd_solver.cpp:112] Iteration 4120, lr = 0.001
I0109 18:39:20.245235 32941 solver.cpp:239] Iteration 4140 (2.65133 iter/s, 7.54337s/20 iters), loss = 0.162017
I0109 18:39:20.245308 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.054724 (* 1 = 0.054724 loss)
I0109 18:39:20.245317 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0718368 (* 1 = 0.0718368 loss)
I0109 18:39:20.245324 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00153955 (* 1 = 0.00153955 loss)
I0109 18:39:20.245330 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0018647 (* 1 = 0.0018647 loss)
I0109 18:39:20.245338 32941 sgd_solver.cpp:112] Iteration 4140, lr = 0.001
I0109 18:39:27.733770 32941 solver.cpp:239] Iteration 4160 (2.67086 iter/s, 7.48821s/20 iters), loss = 0.579481
I0109 18:39:27.733830 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.290642 (* 1 = 0.290642 loss)
I0109 18:39:27.733839 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.093638 (* 1 = 0.093638 loss)
I0109 18:39:27.733846 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0700187 (* 1 = 0.0700187 loss)
I0109 18:39:27.733852 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00900569 (* 1 = 0.00900569 loss)
I0109 18:39:27.733861 32941 sgd_solver.cpp:112] Iteration 4160, lr = 0.001
I0109 18:39:35.222157 32941 solver.cpp:239] Iteration 4180 (2.67092 iter/s, 7.48807s/20 iters), loss = 0.233103
I0109 18:39:35.222218 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.16663 (* 1 = 0.16663 loss)
I0109 18:39:35.222226 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0587795 (* 1 = 0.0587795 loss)
I0109 18:39:35.222234 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00640554 (* 1 = 0.00640554 loss)
I0109 18:39:35.222240 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0214188 (* 1 = 0.0214188 loss)
I0109 18:39:35.222249 32941 sgd_solver.cpp:112] Iteration 4180, lr = 0.001
speed: 0.378s / iter
I0109 18:39:42.842797 32941 solver.cpp:239] Iteration 4200 (2.62456 iter/s, 7.62032s/20 iters), loss = 0.158133
I0109 18:39:42.842859 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.129241 (* 1 = 0.129241 loss)
I0109 18:39:42.842869 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0679229 (* 1 = 0.0679229 loss)
I0109 18:39:42.842875 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00606132 (* 1 = 0.00606132 loss)
I0109 18:39:42.842882 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00375974 (* 1 = 0.00375974 loss)
I0109 18:39:42.842890 32941 sgd_solver.cpp:112] Iteration 4200, lr = 0.001
I0109 18:39:50.463351 32941 solver.cpp:239] Iteration 4220 (2.62459 iter/s, 7.62024s/20 iters), loss = 0.155242
I0109 18:39:50.463421 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0645201 (* 1 = 0.0645201 loss)
I0109 18:39:50.463430 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.051381 (* 1 = 0.051381 loss)
I0109 18:39:50.463438 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0155915 (* 1 = 0.0155915 loss)
I0109 18:39:50.463444 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000575972 (* 1 = 0.000575972 loss)
I0109 18:39:50.463452 32941 sgd_solver.cpp:112] Iteration 4220, lr = 0.001
I0109 18:39:57.918839 32941 solver.cpp:239] Iteration 4240 (2.6827 iter/s, 7.45517s/20 iters), loss = 0.269
I0109 18:39:57.918903 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0394684 (* 1 = 0.0394684 loss)
I0109 18:39:57.918912 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.271517 (* 1 = 0.271517 loss)
I0109 18:39:57.918920 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0347564 (* 1 = 0.0347564 loss)
I0109 18:39:57.918926 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00938972 (* 1 = 0.00938972 loss)
I0109 18:39:57.918933 32941 sgd_solver.cpp:112] Iteration 4240, lr = 0.001
I0109 18:40:05.286015 32941 solver.cpp:239] Iteration 4260 (2.71486 iter/s, 7.36686s/20 iters), loss = 0.261038
I0109 18:40:05.286077 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.116726 (* 1 = 0.116726 loss)
I0109 18:40:05.286085 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.087599 (* 1 = 0.087599 loss)
I0109 18:40:05.286092 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00199002 (* 1 = 0.00199002 loss)
I0109 18:40:05.286098 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00206192 (* 1 = 0.00206192 loss)
I0109 18:40:05.286108 32941 sgd_solver.cpp:112] Iteration 4260, lr = 0.001
I0109 18:40:12.562382 32941 solver.cpp:239] Iteration 4280 (2.74874 iter/s, 7.27606s/20 iters), loss = 0.179407
I0109 18:40:12.562448 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.134683 (* 1 = 0.134683 loss)
I0109 18:40:12.562456 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.117957 (* 1 = 0.117957 loss)
I0109 18:40:12.562463 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0191652 (* 1 = 0.0191652 loss)
I0109 18:40:12.562469 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.006482 (* 1 = 0.006482 loss)
I0109 18:40:12.562477 32941 sgd_solver.cpp:112] Iteration 4280, lr = 0.001
I0109 18:40:19.884651 32941 solver.cpp:239] Iteration 4300 (2.73151 iter/s, 7.32195s/20 iters), loss = 0.108828
I0109 18:40:19.884716 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0557245 (* 1 = 0.0557245 loss)
I0109 18:40:19.884724 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0444468 (* 1 = 0.0444468 loss)
I0109 18:40:19.884732 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00588026 (* 1 = 0.00588026 loss)
I0109 18:40:19.884740 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000860147 (* 1 = 0.000860147 loss)
I0109 18:40:19.884748 32941 sgd_solver.cpp:112] Iteration 4300, lr = 0.001
I0109 18:40:27.362527 32941 solver.cpp:239] Iteration 4320 (2.67467 iter/s, 7.47756s/20 iters), loss = 0.22498
I0109 18:40:27.362581 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.064285 (* 1 = 0.064285 loss)
I0109 18:40:27.362591 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0893665 (* 1 = 0.0893665 loss)
I0109 18:40:27.362597 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0158945 (* 1 = 0.0158945 loss)
I0109 18:40:27.362604 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00302363 (* 1 = 0.00302363 loss)
I0109 18:40:27.362612 32941 sgd_solver.cpp:112] Iteration 4320, lr = 0.001
I0109 18:40:34.830734 32941 solver.cpp:239] Iteration 4340 (2.67813 iter/s, 7.4679s/20 iters), loss = 0.19701
I0109 18:40:34.830794 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.266295 (* 1 = 0.266295 loss)
I0109 18:40:34.830803 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0422702 (* 1 = 0.0422702 loss)
I0109 18:40:34.830811 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0166033 (* 1 = 0.0166033 loss)
I0109 18:40:34.830817 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00885288 (* 1 = 0.00885288 loss)
I0109 18:40:34.830824 32941 sgd_solver.cpp:112] Iteration 4340, lr = 0.001
I0109 18:40:42.257130 32941 solver.cpp:239] Iteration 4360 (2.69321 iter/s, 7.42609s/20 iters), loss = 0.239476
I0109 18:40:42.257180 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.14424 (* 1 = 0.14424 loss)
I0109 18:40:42.257189 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.157333 (* 1 = 0.157333 loss)
I0109 18:40:42.257208 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0013832 (* 1 = 0.0013832 loss)
I0109 18:40:42.257215 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0034303 (* 1 = 0.0034303 loss)
I0109 18:40:42.257220 32941 sgd_solver.cpp:112] Iteration 4360, lr = 0.001
I0109 18:40:49.580448 32941 solver.cpp:239] Iteration 4380 (2.73111 iter/s, 7.32303s/20 iters), loss = 0.247316
I0109 18:40:49.580498 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0847104 (* 1 = 0.0847104 loss)
I0109 18:40:49.580507 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0661971 (* 1 = 0.0661971 loss)
I0109 18:40:49.580513 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000831418 (* 1 = 0.000831418 loss)
I0109 18:40:49.580519 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00142145 (* 1 = 0.00142145 loss)
I0109 18:40:49.580524 32941 sgd_solver.cpp:112] Iteration 4380, lr = 0.001
speed: 0.378s / iter
I0109 18:40:57.000406 32941 solver.cpp:239] Iteration 4400 (2.69554 iter/s, 7.41965s/20 iters), loss = 0.199767
I0109 18:40:57.000495 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0494027 (* 1 = 0.0494027 loss)
I0109 18:40:57.000509 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.153885 (* 1 = 0.153885 loss)
I0109 18:40:57.000519 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00255426 (* 1 = 0.00255426 loss)
I0109 18:40:57.000540 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000653795 (* 1 = 0.000653795 loss)
I0109 18:40:57.000550 32941 sgd_solver.cpp:112] Iteration 4400, lr = 0.001
I0109 18:41:04.597429 32941 solver.cpp:239] Iteration 4420 (2.63273 iter/s, 7.59667s/20 iters), loss = 0.555223
I0109 18:41:04.597508 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.288794 (* 1 = 0.288794 loss)
I0109 18:41:04.597518 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.409206 (* 1 = 0.409206 loss)
I0109 18:41:04.597525 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0877175 (* 1 = 0.0877175 loss)
I0109 18:41:04.597532 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0215158 (* 1 = 0.0215158 loss)
I0109 18:41:04.597539 32941 sgd_solver.cpp:112] Iteration 4420, lr = 0.001
I0109 18:41:12.024781 32941 solver.cpp:239] Iteration 4440 (2.69287 iter/s, 7.42701s/20 iters), loss = 0.366063
I0109 18:41:12.024849 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.18818 (* 1 = 0.18818 loss)
I0109 18:41:12.024865 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.208355 (* 1 = 0.208355 loss)
I0109 18:41:12.024873 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0362939 (* 1 = 0.0362939 loss)
I0109 18:41:12.024879 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0137996 (* 1 = 0.0137996 loss)
I0109 18:41:12.024888 32941 sgd_solver.cpp:112] Iteration 4440, lr = 0.001
I0109 18:41:19.527120 32941 solver.cpp:239] Iteration 4460 (2.66595 iter/s, 7.50201s/20 iters), loss = 0.275285
I0109 18:41:19.527200 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834202 (* 1 = 0.0834202 loss)
I0109 18:41:19.527225 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0900984 (* 1 = 0.0900984 loss)
I0109 18:41:19.527231 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0055787 (* 1 = 0.0055787 loss)
I0109 18:41:19.527238 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000777168 (* 1 = 0.000777168 loss)
I0109 18:41:19.527257 32941 sgd_solver.cpp:112] Iteration 4460, lr = 0.001
I0109 18:41:26.918107 32941 solver.cpp:239] Iteration 4480 (2.70612 iter/s, 7.39065s/20 iters), loss = 0.213379
I0109 18:41:26.918181 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.161074 (* 1 = 0.161074 loss)
I0109 18:41:26.918191 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.116074 (* 1 = 0.116074 loss)
I0109 18:41:26.918201 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00681036 (* 1 = 0.00681036 loss)
I0109 18:41:26.918207 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00467134 (* 1 = 0.00467134 loss)
I0109 18:41:26.918215 32941 sgd_solver.cpp:112] Iteration 4480, lr = 0.001
I0109 18:41:34.566943 32941 solver.cpp:239] Iteration 4500 (2.61489 iter/s, 7.6485s/20 iters), loss = 0.326406
I0109 18:41:34.567010 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0835331 (* 1 = 0.0835331 loss)
I0109 18:41:34.567020 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0364271 (* 1 = 0.0364271 loss)
I0109 18:41:34.567028 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0148723 (* 1 = 0.0148723 loss)
I0109 18:41:34.567034 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0265362 (* 1 = 0.0265362 loss)
I0109 18:41:34.567041 32941 sgd_solver.cpp:112] Iteration 4500, lr = 0.001
I0109 18:41:41.909559 32941 solver.cpp:239] Iteration 4520 (2.72394 iter/s, 7.3423s/20 iters), loss = 0.181447
I0109 18:41:41.909620 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.107541 (* 1 = 0.107541 loss)
I0109 18:41:41.909631 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.110388 (* 1 = 0.110388 loss)
I0109 18:41:41.909637 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0187018 (* 1 = 0.0187018 loss)
I0109 18:41:41.909643 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0197895 (* 1 = 0.0197895 loss)
I0109 18:41:41.909651 32941 sgd_solver.cpp:112] Iteration 4520, lr = 0.001
I0109 18:41:49.317607 32941 solver.cpp:239] Iteration 4540 (2.69988 iter/s, 7.40773s/20 iters), loss = 0.131392
I0109 18:41:49.317683 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0823963 (* 1 = 0.0823963 loss)
I0109 18:41:49.317692 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0415881 (* 1 = 0.0415881 loss)
I0109 18:41:49.317698 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0115374 (* 1 = 0.0115374 loss)
I0109 18:41:49.317705 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00579668 (* 1 = 0.00579668 loss)
I0109 18:41:49.317724 32941 sgd_solver.cpp:112] Iteration 4540, lr = 0.001
I0109 18:41:56.793823 32941 solver.cpp:239] Iteration 4560 (2.67527 iter/s, 7.47589s/20 iters), loss = 0.208638
I0109 18:41:56.793874 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.140829 (* 1 = 0.140829 loss)
I0109 18:41:56.793884 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0626348 (* 1 = 0.0626348 loss)
I0109 18:41:56.793890 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0180866 (* 1 = 0.0180866 loss)
I0109 18:41:56.793896 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00462561 (* 1 = 0.00462561 loss)
I0109 18:41:56.793903 32941 sgd_solver.cpp:112] Iteration 4560, lr = 0.001
I0109 18:42:04.131877 32941 solver.cpp:239] Iteration 4580 (2.72563 iter/s, 7.33775s/20 iters), loss = 0.255126
I0109 18:42:04.131938 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.14967 (* 1 = 0.14967 loss)
I0109 18:42:04.131947 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.175072 (* 1 = 0.175072 loss)
I0109 18:42:04.131954 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0682421 (* 1 = 0.0682421 loss)
I0109 18:42:04.131963 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0092062 (* 1 = 0.0092062 loss)
I0109 18:42:04.131970 32941 sgd_solver.cpp:112] Iteration 4580, lr = 0.001
speed: 0.378s / iter
I0109 18:42:11.762603 32941 solver.cpp:239] Iteration 4600 (2.62109 iter/s, 7.63041s/20 iters), loss = 0.591571
I0109 18:42:11.762668 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.171625 (* 1 = 0.171625 loss)
I0109 18:42:11.762678 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.074303 (* 1 = 0.074303 loss)
I0109 18:42:11.762686 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0199694 (* 1 = 0.0199694 loss)
I0109 18:42:11.762692 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00243062 (* 1 = 0.00243062 loss)
I0109 18:42:11.762699 32941 sgd_solver.cpp:112] Iteration 4600, lr = 0.001
I0109 18:42:19.292299 32941 solver.cpp:239] Iteration 4620 (2.65626 iter/s, 7.52938s/20 iters), loss = 0.310664
I0109 18:42:19.292368 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.101366 (* 1 = 0.101366 loss)
I0109 18:42:19.292376 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.228618 (* 1 = 0.228618 loss)
I0109 18:42:19.292383 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0297228 (* 1 = 0.0297228 loss)
I0109 18:42:19.292402 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0063732 (* 1 = 0.0063732 loss)
I0109 18:42:19.292410 32941 sgd_solver.cpp:112] Iteration 4620, lr = 0.001
I0109 18:42:26.710278 32941 solver.cpp:239] Iteration 4640 (2.69627 iter/s, 7.41765s/20 iters), loss = 0.237265
I0109 18:42:26.710345 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0479962 (* 1 = 0.0479962 loss)
I0109 18:42:26.710353 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0567733 (* 1 = 0.0567733 loss)
I0109 18:42:26.710361 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0100747 (* 1 = 0.0100747 loss)
I0109 18:42:26.710367 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00139309 (* 1 = 0.00139309 loss)
I0109 18:42:26.710374 32941 sgd_solver.cpp:112] Iteration 4640, lr = 0.001
I0109 18:42:34.276837 32941 solver.cpp:239] Iteration 4660 (2.64332 iter/s, 7.56624s/20 iters), loss = 0.204692
I0109 18:42:34.276912 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0712162 (* 1 = 0.0712162 loss)
I0109 18:42:34.276922 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0358454 (* 1 = 0.0358454 loss)
I0109 18:42:34.276928 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0267065 (* 1 = 0.0267065 loss)
I0109 18:42:34.276935 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0310449 (* 1 = 0.0310449 loss)
I0109 18:42:34.276943 32941 sgd_solver.cpp:112] Iteration 4660, lr = 0.001
I0109 18:42:41.844458 32941 solver.cpp:239] Iteration 4680 (2.64296 iter/s, 7.56728s/20 iters), loss = 0.311372
I0109 18:42:41.844524 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.260625 (* 1 = 0.260625 loss)
I0109 18:42:41.844534 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0362795 (* 1 = 0.0362795 loss)
I0109 18:42:41.844542 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00982209 (* 1 = 0.00982209 loss)
I0109 18:42:41.844547 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00754614 (* 1 = 0.00754614 loss)
I0109 18:42:41.844555 32941 sgd_solver.cpp:112] Iteration 4680, lr = 0.001
I0109 18:42:49.246757 32941 solver.cpp:239] Iteration 4700 (2.70198 iter/s, 7.40199s/20 iters), loss = 0.226621
I0109 18:42:49.246814 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.111105 (* 1 = 0.111105 loss)
I0109 18:42:49.246822 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0263927 (* 1 = 0.0263927 loss)
I0109 18:42:49.246829 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00231983 (* 1 = 0.00231983 loss)
I0109 18:42:49.246835 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0031687 (* 1 = 0.0031687 loss)
I0109 18:42:49.246843 32941 sgd_solver.cpp:112] Iteration 4700, lr = 0.001
I0109 18:42:56.534487 32941 solver.cpp:239] Iteration 4720 (2.74445 iter/s, 7.28743s/20 iters), loss = 0.302832
I0109 18:42:56.534540 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.274056 (* 1 = 0.274056 loss)
I0109 18:42:56.534550 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0616529 (* 1 = 0.0616529 loss)
I0109 18:42:56.534556 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0228107 (* 1 = 0.0228107 loss)
I0109 18:42:56.534562 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0448168 (* 1 = 0.0448168 loss)
I0109 18:42:56.534570 32941 sgd_solver.cpp:112] Iteration 4720, lr = 0.001
I0109 18:43:03.889226 32941 solver.cpp:239] Iteration 4740 (2.71945 iter/s, 7.35444s/20 iters), loss = 0.355862
I0109 18:43:03.889276 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.157515 (* 1 = 0.157515 loss)
I0109 18:43:03.889284 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0777019 (* 1 = 0.0777019 loss)
I0109 18:43:03.889292 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0364449 (* 1 = 0.0364449 loss)
I0109 18:43:03.889298 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0129239 (* 1 = 0.0129239 loss)
I0109 18:43:03.889305 32941 sgd_solver.cpp:112] Iteration 4740, lr = 0.001
I0109 18:43:11.455448 32941 solver.cpp:239] Iteration 4760 (2.64343 iter/s, 7.56592s/20 iters), loss = 0.165858
I0109 18:43:11.455515 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0922041 (* 1 = 0.0922041 loss)
I0109 18:43:11.455525 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0456435 (* 1 = 0.0456435 loss)
I0109 18:43:11.455533 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00489041 (* 1 = 0.00489041 loss)
I0109 18:43:11.455541 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00397143 (* 1 = 0.00397143 loss)
I0109 18:43:11.455549 32941 sgd_solver.cpp:112] Iteration 4760, lr = 0.001
I0109 18:43:18.721844 32941 solver.cpp:239] Iteration 4780 (2.75252 iter/s, 7.26608s/20 iters), loss = 0.174102
I0109 18:43:18.721920 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0884715 (* 1 = 0.0884715 loss)
I0109 18:43:18.721930 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0453505 (* 1 = 0.0453505 loss)
I0109 18:43:18.721938 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0122406 (* 1 = 0.0122406 loss)
I0109 18:43:18.721945 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00223399 (* 1 = 0.00223399 loss)
I0109 18:43:18.721952 32941 sgd_solver.cpp:112] Iteration 4780, lr = 0.001
speed: 0.377s / iter
I0109 18:43:26.052165 32941 solver.cpp:239] Iteration 4800 (2.72851 iter/s, 7.33s/20 iters), loss = 0.269392
I0109 18:43:26.052212 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0544811 (* 1 = 0.0544811 loss)
I0109 18:43:26.052222 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0664769 (* 1 = 0.0664769 loss)
I0109 18:43:26.052228 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0124344 (* 1 = 0.0124344 loss)
I0109 18:43:26.052234 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00137856 (* 1 = 0.00137856 loss)
I0109 18:43:26.052242 32941 sgd_solver.cpp:112] Iteration 4800, lr = 0.001
I0109 18:43:33.539767 32941 solver.cpp:239] Iteration 4820 (2.67119 iter/s, 7.48731s/20 iters), loss = 0.271315
I0109 18:43:33.539829 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.213676 (* 1 = 0.213676 loss)
I0109 18:43:33.539837 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0829047 (* 1 = 0.0829047 loss)
I0109 18:43:33.539845 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0026676 (* 1 = 0.0026676 loss)
I0109 18:43:33.539852 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00256296 (* 1 = 0.00256296 loss)
I0109 18:43:33.539858 32941 sgd_solver.cpp:112] Iteration 4820, lr = 0.001
I0109 18:43:41.146158 32941 solver.cpp:239] Iteration 4840 (2.62948 iter/s, 7.60606s/20 iters), loss = 0.180707
I0109 18:43:41.146229 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.151153 (* 1 = 0.151153 loss)
I0109 18:43:41.146239 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0448286 (* 1 = 0.0448286 loss)
I0109 18:43:41.146245 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0110978 (* 1 = 0.0110978 loss)
I0109 18:43:41.146251 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0347789 (* 1 = 0.0347789 loss)
I0109 18:43:41.146261 32941 sgd_solver.cpp:112] Iteration 4840, lr = 0.001
I0109 18:43:48.304658 32941 solver.cpp:239] Iteration 4860 (2.794 iter/s, 7.15819s/20 iters), loss = 0.331027
I0109 18:43:48.304721 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0686405 (* 1 = 0.0686405 loss)
I0109 18:43:48.304731 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0266128 (* 1 = 0.0266128 loss)
I0109 18:43:48.304738 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000859438 (* 1 = 0.000859438 loss)
I0109 18:43:48.304744 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000408897 (* 1 = 0.000408897 loss)
I0109 18:43:48.304754 32941 sgd_solver.cpp:112] Iteration 4860, lr = 0.001
I0109 18:43:55.709815 32941 solver.cpp:239] Iteration 4880 (2.70094 iter/s, 7.40484s/20 iters), loss = 0.246131
I0109 18:43:55.709874 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0828605 (* 1 = 0.0828605 loss)
I0109 18:43:55.709884 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00585966 (* 1 = 0.00585966 loss)
I0109 18:43:55.709892 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00106604 (* 1 = 0.00106604 loss)
I0109 18:43:55.709897 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00797577 (* 1 = 0.00797577 loss)
I0109 18:43:55.709905 32941 sgd_solver.cpp:112] Iteration 4880, lr = 0.001
I0109 18:44:03.083286 32941 solver.cpp:239] Iteration 4900 (2.71254 iter/s, 7.37316s/20 iters), loss = 0.298459
I0109 18:44:03.083362 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.134641 (* 1 = 0.134641 loss)
I0109 18:44:03.083372 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0370755 (* 1 = 0.0370755 loss)
I0109 18:44:03.083379 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0295412 (* 1 = 0.0295412 loss)
I0109 18:44:03.083385 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0159742 (* 1 = 0.0159742 loss)
I0109 18:44:03.083392 32941 sgd_solver.cpp:112] Iteration 4900, lr = 0.001
I0109 18:44:10.646461 32941 solver.cpp:239] Iteration 4920 (2.64451 iter/s, 7.56285s/20 iters), loss = 0.192877
I0109 18:44:10.646540 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.19245 (* 1 = 0.19245 loss)
I0109 18:44:10.646550 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0492696 (* 1 = 0.0492696 loss)
I0109 18:44:10.646558 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0146223 (* 1 = 0.0146223 loss)
I0109 18:44:10.646564 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0185314 (* 1 = 0.0185314 loss)
I0109 18:44:10.646572 32941 sgd_solver.cpp:112] Iteration 4920, lr = 0.001
I0109 18:44:18.035574 32941 solver.cpp:239] Iteration 4940 (2.70681 iter/s, 7.38878s/20 iters), loss = 0.157701
I0109 18:44:18.035645 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0984569 (* 1 = 0.0984569 loss)
I0109 18:44:18.035656 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.137709 (* 1 = 0.137709 loss)
I0109 18:44:18.035665 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0123275 (* 1 = 0.0123275 loss)
I0109 18:44:18.035671 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00258703 (* 1 = 0.00258703 loss)
I0109 18:44:18.035679 32941 sgd_solver.cpp:112] Iteration 4940, lr = 0.001
I0109 18:44:25.417750 32941 solver.cpp:239] Iteration 4960 (2.70935 iter/s, 7.38186s/20 iters), loss = 0.198375
I0109 18:44:25.417817 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.105551 (* 1 = 0.105551 loss)
I0109 18:44:25.417826 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.171904 (* 1 = 0.171904 loss)
I0109 18:44:25.417834 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00577749 (* 1 = 0.00577749 loss)
I0109 18:44:25.417840 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00528164 (* 1 = 0.00528164 loss)
I0109 18:44:25.417850 32941 sgd_solver.cpp:112] Iteration 4960, lr = 0.001
I0109 18:44:32.933985 32941 solver.cpp:239] Iteration 4980 (2.66102 iter/s, 7.51591s/20 iters), loss = 0.277812
I0109 18:44:32.934058 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.161048 (* 1 = 0.161048 loss)
I0109 18:44:32.934069 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.041297 (* 1 = 0.041297 loss)
I0109 18:44:32.934077 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0525431 (* 1 = 0.0525431 loss)
I0109 18:44:32.934083 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00608825 (* 1 = 0.00608825 loss)
I0109 18:44:32.934098 32941 sgd_solver.cpp:112] Iteration 4980, lr = 0.001
speed: 0.377s / iter
I0109 18:44:40.339061 32941 solver.cpp:239] Iteration 5000 (2.70097 iter/s, 7.40476s/20 iters), loss = 0.970173
I0109 18:44:40.339118 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.11293 (* 1 = 0.11293 loss)
I0109 18:44:40.339126 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.24063 (* 1 = 0.24063 loss)
I0109 18:44:40.339133 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0236655 (* 1 = 0.0236655 loss)
I0109 18:44:40.339140 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00713286 (* 1 = 0.00713286 loss)
I0109 18:44:40.339148 32941 sgd_solver.cpp:112] Iteration 5000, lr = 0.001
I0109 18:44:47.772176 32941 solver.cpp:239] Iteration 5020 (2.69078 iter/s, 7.4328s/20 iters), loss = 0.136886
I0109 18:44:47.772251 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0309332 (* 1 = 0.0309332 loss)
I0109 18:44:47.772260 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0254193 (* 1 = 0.0254193 loss)
I0109 18:44:47.772267 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00244128 (* 1 = 0.00244128 loss)
I0109 18:44:47.772277 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0047686 (* 1 = 0.0047686 loss)
I0109 18:44:47.772289 32941 sgd_solver.cpp:112] Iteration 5020, lr = 0.001
I0109 18:44:55.029589 32941 solver.cpp:239] Iteration 5040 (2.75592 iter/s, 7.2571s/20 iters), loss = 0.261963
I0109 18:44:55.029655 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.047193 (* 1 = 0.047193 loss)
I0109 18:44:55.029664 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0687519 (* 1 = 0.0687519 loss)
I0109 18:44:55.029671 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0365023 (* 1 = 0.0365023 loss)
I0109 18:44:55.029677 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00166673 (* 1 = 0.00166673 loss)
I0109 18:44:55.029696 32941 sgd_solver.cpp:112] Iteration 5040, lr = 0.001
I0109 18:45:02.344990 32941 solver.cpp:239] Iteration 5060 (2.73408 iter/s, 7.31508s/20 iters), loss = 0.295059
I0109 18:45:02.345050 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.10142 (* 1 = 0.10142 loss)
I0109 18:45:02.345059 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.247872 (* 1 = 0.247872 loss)
I0109 18:45:02.345067 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0112277 (* 1 = 0.0112277 loss)
I0109 18:45:02.345073 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00651309 (* 1 = 0.00651309 loss)
I0109 18:45:02.345086 32941 sgd_solver.cpp:112] Iteration 5060, lr = 0.001
I0109 18:45:09.790397 32941 solver.cpp:239] Iteration 5080 (2.68633 iter/s, 7.4451s/20 iters), loss = 0.221494
I0109 18:45:09.790457 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.117343 (* 1 = 0.117343 loss)
I0109 18:45:09.790465 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0973975 (* 1 = 0.0973975 loss)
I0109 18:45:09.790472 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0493727 (* 1 = 0.0493727 loss)
I0109 18:45:09.790478 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0070058 (* 1 = 0.0070058 loss)
I0109 18:45:09.790486 32941 sgd_solver.cpp:112] Iteration 5080, lr = 0.001
I0109 18:45:17.204334 32941 solver.cpp:239] Iteration 5100 (2.69773 iter/s, 7.41363s/20 iters), loss = 0.114573
I0109 18:45:17.204398 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0797779 (* 1 = 0.0797779 loss)
I0109 18:45:17.204407 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0608397 (* 1 = 0.0608397 loss)
I0109 18:45:17.204414 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00131591 (* 1 = 0.00131591 loss)
I0109 18:45:17.204421 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000853707 (* 1 = 0.000853707 loss)
I0109 18:45:17.204429 32941 sgd_solver.cpp:112] Iteration 5100, lr = 0.001
I0109 18:45:24.563102 32941 solver.cpp:239] Iteration 5120 (2.71796 iter/s, 7.35847s/20 iters), loss = 0.35501
I0109 18:45:24.563158 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0894647 (* 1 = 0.0894647 loss)
I0109 18:45:24.563166 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.135981 (* 1 = 0.135981 loss)
I0109 18:45:24.563172 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0284509 (* 1 = 0.0284509 loss)
I0109 18:45:24.563179 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00938564 (* 1 = 0.00938564 loss)
I0109 18:45:24.563186 32941 sgd_solver.cpp:112] Iteration 5120, lr = 0.001
I0109 18:45:31.946058 32941 solver.cpp:239] Iteration 5140 (2.70905 iter/s, 7.38266s/20 iters), loss = 0.327581
I0109 18:45:31.946106 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.207432 (* 1 = 0.207432 loss)
I0109 18:45:31.946115 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0901205 (* 1 = 0.0901205 loss)
I0109 18:45:31.946121 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0459621 (* 1 = 0.0459621 loss)
I0109 18:45:31.946127 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.028886 (* 1 = 0.028886 loss)
I0109 18:45:31.946132 32941 sgd_solver.cpp:112] Iteration 5140, lr = 0.001
I0109 18:45:39.301411 32941 solver.cpp:239] Iteration 5160 (2.71922 iter/s, 7.35506s/20 iters), loss = 0.213863
I0109 18:45:39.301483 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.108486 (* 1 = 0.108486 loss)
I0109 18:45:39.301492 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.179744 (* 1 = 0.179744 loss)
I0109 18:45:39.301498 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0131552 (* 1 = 0.0131552 loss)
I0109 18:45:39.301503 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0120825 (* 1 = 0.0120825 loss)
I0109 18:45:39.301510 32941 sgd_solver.cpp:112] Iteration 5160, lr = 0.001
I0109 18:45:46.742156 32941 solver.cpp:239] Iteration 5180 (2.68802 iter/s, 7.44043s/20 iters), loss = 0.234076
I0109 18:45:46.742235 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0507679 (* 1 = 0.0507679 loss)
I0109 18:45:46.742244 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0598386 (* 1 = 0.0598386 loss)
I0109 18:45:46.742251 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0114114 (* 1 = 0.0114114 loss)
I0109 18:45:46.742259 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00411575 (* 1 = 0.00411575 loss)
I0109 18:45:46.742266 32941 sgd_solver.cpp:112] Iteration 5180, lr = 0.001
speed: 0.377s / iter
I0109 18:45:54.243624 32941 solver.cpp:239] Iteration 5200 (2.66626 iter/s, 7.50115s/20 iters), loss = 0.175325
I0109 18:45:54.243680 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0481232 (* 1 = 0.0481232 loss)
I0109 18:45:54.243690 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00808077 (* 1 = 0.00808077 loss)
I0109 18:45:54.243695 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0077959 (* 1 = 0.0077959 loss)
I0109 18:45:54.243700 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00421304 (* 1 = 0.00421304 loss)
I0109 18:45:54.243706 32941 sgd_solver.cpp:112] Iteration 5200, lr = 0.001
I0109 18:46:01.448637 32941 solver.cpp:239] Iteration 5220 (2.77596 iter/s, 7.20471s/20 iters), loss = 0.121799
I0109 18:46:01.448704 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.123197 (* 1 = 0.123197 loss)
I0109 18:46:01.448714 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0224728 (* 1 = 0.0224728 loss)
I0109 18:46:01.448720 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00164281 (* 1 = 0.00164281 loss)
I0109 18:46:01.448726 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000613035 (* 1 = 0.000613035 loss)
I0109 18:46:01.448734 32941 sgd_solver.cpp:112] Iteration 5220, lr = 0.001
I0109 18:46:08.795135 32941 solver.cpp:239] Iteration 5240 (2.7225 iter/s, 7.34618s/20 iters), loss = 0.266
I0109 18:46:08.795200 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.134493 (* 1 = 0.134493 loss)
I0109 18:46:08.795210 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0727517 (* 1 = 0.0727517 loss)
I0109 18:46:08.795217 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00290112 (* 1 = 0.00290112 loss)
I0109 18:46:08.795224 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00237425 (* 1 = 0.00237425 loss)
I0109 18:46:08.795233 32941 sgd_solver.cpp:112] Iteration 5240, lr = 0.001
I0109 18:46:16.200737 32941 solver.cpp:239] Iteration 5260 (2.70077 iter/s, 7.40529s/20 iters), loss = 0.108287
I0109 18:46:16.200794 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.109291 (* 1 = 0.109291 loss)
I0109 18:46:16.200804 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0135092 (* 1 = 0.0135092 loss)
I0109 18:46:16.200812 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00109168 (* 1 = 0.00109168 loss)
I0109 18:46:16.200819 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00120446 (* 1 = 0.00120446 loss)
I0109 18:46:16.200827 32941 sgd_solver.cpp:112] Iteration 5260, lr = 0.001
I0109 18:46:23.723239 32941 solver.cpp:239] Iteration 5280 (2.6588 iter/s, 7.52218s/20 iters), loss = 0.17392
I0109 18:46:23.723310 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.163261 (* 1 = 0.163261 loss)
I0109 18:46:23.723320 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0643646 (* 1 = 0.0643646 loss)
I0109 18:46:23.723327 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00436492 (* 1 = 0.00436492 loss)
I0109 18:46:23.723333 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0141867 (* 1 = 0.0141867 loss)
I0109 18:46:23.723341 32941 sgd_solver.cpp:112] Iteration 5280, lr = 0.001
I0109 18:46:31.012631 32941 solver.cpp:239] Iteration 5300 (2.74384 iter/s, 7.28906s/20 iters), loss = 0.317943
I0109 18:46:31.012710 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.165382 (* 1 = 0.165382 loss)
I0109 18:46:31.012720 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.100832 (* 1 = 0.100832 loss)
I0109 18:46:31.012727 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0166026 (* 1 = 0.0166026 loss)
I0109 18:46:31.012733 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0141704 (* 1 = 0.0141704 loss)
I0109 18:46:31.012742 32941 sgd_solver.cpp:112] Iteration 5300, lr = 0.001
I0109 18:46:38.354549 32941 solver.cpp:239] Iteration 5320 (2.72421 iter/s, 7.34158s/20 iters), loss = 0.226254
I0109 18:46:38.354614 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.00368092 (* 1 = 0.00368092 loss)
I0109 18:46:38.354622 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0648961 (* 1 = 0.0648961 loss)
I0109 18:46:38.354629 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.125609 (* 1 = 0.125609 loss)
I0109 18:46:38.354635 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.110269 (* 1 = 0.110269 loss)
I0109 18:46:38.354645 32941 sgd_solver.cpp:112] Iteration 5320, lr = 0.001
I0109 18:46:45.725818 32941 solver.cpp:239] Iteration 5340 (2.71335 iter/s, 7.37095s/20 iters), loss = 0.225712
I0109 18:46:45.725888 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.187093 (* 1 = 0.187093 loss)
I0109 18:46:45.725898 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.100663 (* 1 = 0.100663 loss)
I0109 18:46:45.725905 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00417456 (* 1 = 0.00417456 loss)
I0109 18:46:45.725912 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00217471 (* 1 = 0.00217471 loss)
I0109 18:46:45.725920 32941 sgd_solver.cpp:112] Iteration 5340, lr = 0.001
I0109 18:46:52.948079 32941 solver.cpp:239] Iteration 5360 (2.76934 iter/s, 7.22194s/20 iters), loss = 0.199005
I0109 18:46:52.948144 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0368512 (* 1 = 0.0368512 loss)
I0109 18:46:52.948153 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.130492 (* 1 = 0.130492 loss)
I0109 18:46:52.948160 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.130431 (* 1 = 0.130431 loss)
I0109 18:46:52.948166 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0351249 (* 1 = 0.0351249 loss)
I0109 18:46:52.948175 32941 sgd_solver.cpp:112] Iteration 5360, lr = 0.001
I0109 18:47:00.238003 32941 solver.cpp:239] Iteration 5380 (2.74363 iter/s, 7.28962s/20 iters), loss = 0.284543
I0109 18:47:00.238055 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0435367 (* 1 = 0.0435367 loss)
I0109 18:47:00.238065 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0304491 (* 1 = 0.0304491 loss)
I0109 18:47:00.238070 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00211143 (* 1 = 0.00211143 loss)
I0109 18:47:00.238087 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00251599 (* 1 = 0.00251599 loss)
I0109 18:47:00.238095 32941 sgd_solver.cpp:112] Iteration 5380, lr = 0.001
speed: 0.377s / iter
I0109 18:47:07.613492 32941 solver.cpp:239] Iteration 5400 (2.7118 iter/s, 7.37519s/20 iters), loss = 0.125196
I0109 18:47:07.613536 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0817233 (* 1 = 0.0817233 loss)
I0109 18:47:07.613545 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0279446 (* 1 = 0.0279446 loss)
I0109 18:47:07.613553 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00215066 (* 1 = 0.00215066 loss)
I0109 18:47:07.613559 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00195264 (* 1 = 0.00195264 loss)
I0109 18:47:07.613564 32941 sgd_solver.cpp:112] Iteration 5400, lr = 0.001
I0109 18:47:14.928586 32941 solver.cpp:239] Iteration 5420 (2.73418 iter/s, 7.31481s/20 iters), loss = 0.249963
I0109 18:47:14.928637 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.140676 (* 1 = 0.140676 loss)
I0109 18:47:14.928647 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.124958 (* 1 = 0.124958 loss)
I0109 18:47:14.928653 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000887533 (* 1 = 0.000887533 loss)
I0109 18:47:14.928659 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00317978 (* 1 = 0.00317978 loss)
I0109 18:47:14.928665 32941 sgd_solver.cpp:112] Iteration 5420, lr = 0.001
I0109 18:47:22.152585 32941 solver.cpp:239] Iteration 5440 (2.76866 iter/s, 7.2237s/20 iters), loss = 0.344133
I0109 18:47:22.152665 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.151833 (* 1 = 0.151833 loss)
I0109 18:47:22.152674 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.14054 (* 1 = 0.14054 loss)
I0109 18:47:22.152681 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0452624 (* 1 = 0.0452624 loss)
I0109 18:47:22.152688 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0519271 (* 1 = 0.0519271 loss)
I0109 18:47:22.152706 32941 sgd_solver.cpp:112] Iteration 5440, lr = 0.001
I0109 18:47:29.672166 32941 solver.cpp:239] Iteration 5460 (2.65984 iter/s, 7.51924s/20 iters), loss = 0.181183
I0109 18:47:29.672226 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.10401 (* 1 = 0.10401 loss)
I0109 18:47:29.672235 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0249749 (* 1 = 0.0249749 loss)
I0109 18:47:29.672242 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00773083 (* 1 = 0.00773083 loss)
I0109 18:47:29.672248 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0107093 (* 1 = 0.0107093 loss)
I0109 18:47:29.672256 32941 sgd_solver.cpp:112] Iteration 5460, lr = 0.001
I0109 18:47:37.083485 32941 solver.cpp:239] Iteration 5480 (2.69869 iter/s, 7.41101s/20 iters), loss = 0.256414
I0109 18:47:37.083566 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.217477 (* 1 = 0.217477 loss)
I0109 18:47:37.083576 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0758235 (* 1 = 0.0758235 loss)
I0109 18:47:37.083583 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0265273 (* 1 = 0.0265273 loss)
I0109 18:47:37.083590 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.021313 (* 1 = 0.021313 loss)
I0109 18:47:37.083606 32941 sgd_solver.cpp:112] Iteration 5480, lr = 0.001
I0109 18:47:44.397508 32941 solver.cpp:239] Iteration 5500 (2.7346 iter/s, 7.31369s/20 iters), loss = 0.248343
I0109 18:47:44.397570 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.204679 (* 1 = 0.204679 loss)
I0109 18:47:44.397581 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.10967 (* 1 = 0.10967 loss)
I0109 18:47:44.397588 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0293629 (* 1 = 0.0293629 loss)
I0109 18:47:44.397594 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0144085 (* 1 = 0.0144085 loss)
I0109 18:47:44.397603 32941 sgd_solver.cpp:112] Iteration 5500, lr = 0.001
I0109 18:47:51.869437 32941 solver.cpp:239] Iteration 5520 (2.6768 iter/s, 7.47162s/20 iters), loss = 0.220445
I0109 18:47:51.869494 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0834592 (* 1 = 0.0834592 loss)
I0109 18:47:51.869503 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.204908 (* 1 = 0.204908 loss)
I0109 18:47:51.869511 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00847331 (* 1 = 0.00847331 loss)
I0109 18:47:51.869518 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0052135 (* 1 = 0.0052135 loss)
I0109 18:47:51.869525 32941 sgd_solver.cpp:112] Iteration 5520, lr = 0.001
I0109 18:47:59.343022 32941 solver.cpp:239] Iteration 5540 (2.6762 iter/s, 7.47328s/20 iters), loss = 0.106751
I0109 18:47:59.343089 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0645847 (* 1 = 0.0645847 loss)
I0109 18:47:59.343099 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.023947 (* 1 = 0.023947 loss)
I0109 18:47:59.343106 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00964498 (* 1 = 0.00964498 loss)
I0109 18:47:59.343112 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000638797 (* 1 = 0.000638797 loss)
I0109 18:47:59.343120 32941 sgd_solver.cpp:112] Iteration 5540, lr = 0.001
I0109 18:48:06.972645 32941 solver.cpp:239] Iteration 5560 (2.62147 iter/s, 7.6293s/20 iters), loss = 0.282413
I0109 18:48:06.972704 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0542987 (* 1 = 0.0542987 loss)
I0109 18:48:06.972713 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.118048 (* 1 = 0.118048 loss)
I0109 18:48:06.972720 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00620597 (* 1 = 0.00620597 loss)
I0109 18:48:06.972728 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00349161 (* 1 = 0.00349161 loss)
I0109 18:48:06.972734 32941 sgd_solver.cpp:112] Iteration 5560, lr = 0.001
I0109 18:48:14.421070 32941 solver.cpp:239] Iteration 5580 (2.68525 iter/s, 7.4481s/20 iters), loss = 0.208578
I0109 18:48:14.421144 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0673717 (* 1 = 0.0673717 loss)
I0109 18:48:14.421154 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0653757 (* 1 = 0.0653757 loss)
I0109 18:48:14.421162 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0132865 (* 1 = 0.0132865 loss)
I0109 18:48:14.421169 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00385611 (* 1 = 0.00385611 loss)
I0109 18:48:14.421177 32941 sgd_solver.cpp:112] Iteration 5580, lr = 0.001
speed: 0.376s / iter
I0109 18:48:21.626507 32941 solver.cpp:239] Iteration 5600 (2.7758 iter/s, 7.20512s/20 iters), loss = 0.14897
I0109 18:48:21.626569 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0428086 (* 1 = 0.0428086 loss)
I0109 18:48:21.626579 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0278778 (* 1 = 0.0278778 loss)
I0109 18:48:21.626586 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0105022 (* 1 = 0.0105022 loss)
I0109 18:48:21.626592 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00334441 (* 1 = 0.00334441 loss)
I0109 18:48:21.626600 32941 sgd_solver.cpp:112] Iteration 5600, lr = 0.001
I0109 18:48:29.003796 32941 solver.cpp:239] Iteration 5620 (2.71114 iter/s, 7.37697s/20 iters), loss = 0.200979
I0109 18:48:29.003861 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0486215 (* 1 = 0.0486215 loss)
I0109 18:48:29.003871 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0434254 (* 1 = 0.0434254 loss)
I0109 18:48:29.003878 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0050623 (* 1 = 0.0050623 loss)
I0109 18:48:29.003887 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000887433 (* 1 = 0.000887433 loss)
I0109 18:48:29.003895 32941 sgd_solver.cpp:112] Iteration 5620, lr = 0.001
I0109 18:48:36.437768 32941 solver.cpp:239] Iteration 5640 (2.69046 iter/s, 7.43366s/20 iters), loss = 0.422382
I0109 18:48:36.437830 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0657828 (* 1 = 0.0657828 loss)
I0109 18:48:36.437839 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0425526 (* 1 = 0.0425526 loss)
I0109 18:48:36.437845 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0226269 (* 1 = 0.0226269 loss)
I0109 18:48:36.437852 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00326483 (* 1 = 0.00326483 loss)
I0109 18:48:36.437860 32941 sgd_solver.cpp:112] Iteration 5640, lr = 0.001
I0109 18:48:43.744927 32941 solver.cpp:239] Iteration 5660 (2.73716 iter/s, 7.30685s/20 iters), loss = 0.388393
I0109 18:48:43.744990 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0796129 (* 1 = 0.0796129 loss)
I0109 18:48:43.745000 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.224868 (* 1 = 0.224868 loss)
I0109 18:48:43.745007 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0276867 (* 1 = 0.0276867 loss)
I0109 18:48:43.745015 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0154306 (* 1 = 0.0154306 loss)
I0109 18:48:43.745023 32941 sgd_solver.cpp:112] Iteration 5660, lr = 0.001
I0109 18:48:51.132793 32941 solver.cpp:239] Iteration 5680 (2.70726 iter/s, 7.38755s/20 iters), loss = 0.150679
I0109 18:48:51.132855 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0976226 (* 1 = 0.0976226 loss)
I0109 18:48:51.132875 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0228513 (* 1 = 0.0228513 loss)
I0109 18:48:51.132885 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00208287 (* 1 = 0.00208287 loss)
I0109 18:48:51.132892 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0013739 (* 1 = 0.0013739 loss)
I0109 18:48:51.132899 32941 sgd_solver.cpp:112] Iteration 5680, lr = 0.001
I0109 18:48:58.614323 32941 solver.cpp:239] Iteration 5700 (2.67336 iter/s, 7.48122s/20 iters), loss = 0.212569
I0109 18:48:58.614382 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.122461 (* 1 = 0.122461 loss)
I0109 18:48:58.614392 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0941967 (* 1 = 0.0941967 loss)
I0109 18:48:58.614399 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0246113 (* 1 = 0.0246113 loss)
I0109 18:48:58.614408 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00725375 (* 1 = 0.00725375 loss)
I0109 18:48:58.614415 32941 sgd_solver.cpp:112] Iteration 5700, lr = 0.001
I0109 18:49:06.159910 32941 solver.cpp:239] Iteration 5720 (2.65066 iter/s, 7.54528s/20 iters), loss = 0.234199
I0109 18:49:06.159981 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0540595 (* 1 = 0.0540595 loss)
I0109 18:49:06.159991 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0321589 (* 1 = 0.0321589 loss)
I0109 18:49:06.159998 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0194631 (* 1 = 0.0194631 loss)
I0109 18:49:06.160006 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00167843 (* 1 = 0.00167843 loss)
I0109 18:49:06.160012 32941 sgd_solver.cpp:112] Iteration 5720, lr = 0.001
I0109 18:49:13.658560 32941 solver.cpp:239] Iteration 5740 (2.66726 iter/s, 7.49832s/20 iters), loss = 0.189881
I0109 18:49:13.658628 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.18064 (* 1 = 0.18064 loss)
I0109 18:49:13.658638 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0490443 (* 1 = 0.0490443 loss)
I0109 18:49:13.658646 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00385054 (* 1 = 0.00385054 loss)
I0109 18:49:13.658653 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00388488 (* 1 = 0.00388488 loss)
I0109 18:49:13.658660 32941 sgd_solver.cpp:112] Iteration 5740, lr = 0.001
I0109 18:49:21.078325 32941 solver.cpp:239] Iteration 5760 (2.69562 iter/s, 7.41944s/20 iters), loss = 0.294632
I0109 18:49:21.078389 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0919174 (* 1 = 0.0919174 loss)
I0109 18:49:21.078399 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.083326 (* 1 = 0.083326 loss)
I0109 18:49:21.078406 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0136959 (* 1 = 0.0136959 loss)
I0109 18:49:21.078413 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00335153 (* 1 = 0.00335153 loss)
I0109 18:49:21.078421 32941 sgd_solver.cpp:112] Iteration 5760, lr = 0.001
I0109 18:49:28.561239 32941 solver.cpp:239] Iteration 5780 (2.67287 iter/s, 7.48259s/20 iters), loss = 0.131005
I0109 18:49:28.561305 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.12345 (* 1 = 0.12345 loss)
I0109 18:49:28.561314 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.056641 (* 1 = 0.056641 loss)
I0109 18:49:28.561322 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00181779 (* 1 = 0.00181779 loss)
I0109 18:49:28.561328 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00226874 (* 1 = 0.00226874 loss)
I0109 18:49:28.561336 32941 sgd_solver.cpp:112] Iteration 5780, lr = 0.001
speed: 0.376s / iter
I0109 18:49:35.808527 32941 solver.cpp:239] Iteration 5800 (2.75977 iter/s, 7.24698s/20 iters), loss = 0.206889
I0109 18:49:35.808594 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.164602 (* 1 = 0.164602 loss)
I0109 18:49:35.808604 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.117161 (* 1 = 0.117161 loss)
I0109 18:49:35.808611 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0190638 (* 1 = 0.0190638 loss)
I0109 18:49:35.808617 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00676597 (* 1 = 0.00676597 loss)
I0109 18:49:35.808625 32941 sgd_solver.cpp:112] Iteration 5800, lr = 0.001
I0109 18:49:43.122066 32941 solver.cpp:239] Iteration 5820 (2.73477 iter/s, 7.31322s/20 iters), loss = 0.110092
I0109 18:49:43.122131 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0669922 (* 1 = 0.0669922 loss)
I0109 18:49:43.122141 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0259083 (* 1 = 0.0259083 loss)
I0109 18:49:43.122150 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0216357 (* 1 = 0.0216357 loss)
I0109 18:49:43.122156 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.003069 (* 1 = 0.003069 loss)
I0109 18:49:43.122164 32941 sgd_solver.cpp:112] Iteration 5820, lr = 0.001
I0109 18:49:50.594367 32941 solver.cpp:239] Iteration 5840 (2.67667 iter/s, 7.47198s/20 iters), loss = 0.520559
I0109 18:49:50.594424 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.14248 (* 1 = 0.14248 loss)
I0109 18:49:50.594432 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.271155 (* 1 = 0.271155 loss)
I0109 18:49:50.594439 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0435257 (* 1 = 0.0435257 loss)
I0109 18:49:50.594445 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0389805 (* 1 = 0.0389805 loss)
I0109 18:49:50.594452 32941 sgd_solver.cpp:112] Iteration 5840, lr = 0.001
I0109 18:49:57.851716 32941 solver.cpp:239] Iteration 5860 (2.75594 iter/s, 7.25704s/20 iters), loss = 0.109029
I0109 18:49:57.851779 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0682387 (* 1 = 0.0682387 loss)
I0109 18:49:57.851788 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0281071 (* 1 = 0.0281071 loss)
I0109 18:49:57.851796 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00337581 (* 1 = 0.00337581 loss)
I0109 18:49:57.851804 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00882868 (* 1 = 0.00882868 loss)
I0109 18:49:57.851811 32941 sgd_solver.cpp:112] Iteration 5860, lr = 0.001
I0109 18:50:05.202188 32941 solver.cpp:239] Iteration 5880 (2.72103 iter/s, 7.35016s/20 iters), loss = 0.161882
I0109 18:50:05.202244 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0438317 (* 1 = 0.0438317 loss)
I0109 18:50:05.202255 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0246159 (* 1 = 0.0246159 loss)
I0109 18:50:05.202261 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0296656 (* 1 = 0.0296656 loss)
I0109 18:50:05.202267 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0586194 (* 1 = 0.0586194 loss)
I0109 18:50:05.202275 32941 sgd_solver.cpp:112] Iteration 5880, lr = 0.001
I0109 18:50:12.696949 32941 solver.cpp:239] Iteration 5900 (2.66864 iter/s, 7.49445s/20 iters), loss = 0.0699593
I0109 18:50:12.697010 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0237136 (* 1 = 0.0237136 loss)
I0109 18:50:12.697018 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00786356 (* 1 = 0.00786356 loss)
I0109 18:50:12.697026 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00797835 (* 1 = 0.00797835 loss)
I0109 18:50:12.697031 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000186738 (* 1 = 0.000186738 loss)
I0109 18:50:12.697041 32941 sgd_solver.cpp:112] Iteration 5900, lr = 0.001
I0109 18:50:20.027611 32941 solver.cpp:239] Iteration 5920 (2.72838 iter/s, 7.33035s/20 iters), loss = 0.216625
I0109 18:50:20.027669 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0870214 (* 1 = 0.0870214 loss)
I0109 18:50:20.027678 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0375481 (* 1 = 0.0375481 loss)
I0109 18:50:20.027685 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0496162 (* 1 = 0.0496162 loss)
I0109 18:50:20.027691 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0258786 (* 1 = 0.0258786 loss)
I0109 18:50:20.027699 32941 sgd_solver.cpp:112] Iteration 5920, lr = 0.001
I0109 18:50:27.463600 32941 solver.cpp:239] Iteration 5940 (2.68973 iter/s, 7.43569s/20 iters), loss = 0.115357
I0109 18:50:27.463660 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0873042 (* 1 = 0.0873042 loss)
I0109 18:50:27.463668 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0935184 (* 1 = 0.0935184 loss)
I0109 18:50:27.463675 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00807528 (* 1 = 0.00807528 loss)
I0109 18:50:27.463680 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00607926 (* 1 = 0.00607926 loss)
I0109 18:50:27.463685 32941 sgd_solver.cpp:112] Iteration 5940, lr = 0.001
I0109 18:50:34.638160 32941 solver.cpp:239] Iteration 5960 (2.78775 iter/s, 7.17425s/20 iters), loss = 0.145586
I0109 18:50:34.638223 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.131401 (* 1 = 0.131401 loss)
I0109 18:50:34.638233 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0199405 (* 1 = 0.0199405 loss)
I0109 18:50:34.638240 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00168726 (* 1 = 0.00168726 loss)
I0109 18:50:34.638247 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00422479 (* 1 = 0.00422479 loss)
I0109 18:50:34.638254 32941 sgd_solver.cpp:112] Iteration 5960, lr = 0.001
I0109 18:50:41.991513 32941 solver.cpp:239] Iteration 5980 (2.71996 iter/s, 7.35304s/20 iters), loss = 0.130449
I0109 18:50:41.991561 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.100111 (* 1 = 0.100111 loss)
I0109 18:50:41.991570 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00865135 (* 1 = 0.00865135 loss)
I0109 18:50:41.991577 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000871358 (* 1 = 0.000871358 loss)
I0109 18:50:41.991590 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00118537 (* 1 = 0.00118537 loss)
I0109 18:50:41.991608 32941 sgd_solver.cpp:112] Iteration 5980, lr = 0.001
speed: 0.376s / iter
I0109 18:50:49.274551 32941 solver.cpp:239] Iteration 6000 (2.74622 iter/s, 7.28274s/20 iters), loss = 0.208697
I0109 18:50:49.274619 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0510808 (* 1 = 0.0510808 loss)
I0109 18:50:49.274628 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0913577 (* 1 = 0.0913577 loss)
I0109 18:50:49.274636 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0731605 (* 1 = 0.0731605 loss)
I0109 18:50:49.274641 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00223987 (* 1 = 0.00223987 loss)
I0109 18:50:49.274649 32941 sgd_solver.cpp:112] Iteration 6000, lr = 0.001
I0109 18:50:56.710920 32941 solver.cpp:239] Iteration 6020 (2.6896 iter/s, 7.43605s/20 iters), loss = 0.124857
I0109 18:50:56.710983 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0351279 (* 1 = 0.0351279 loss)
I0109 18:50:56.710994 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0292339 (* 1 = 0.0292339 loss)
I0109 18:50:56.710999 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00300658 (* 1 = 0.00300658 loss)
I0109 18:50:56.711006 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000505797 (* 1 = 0.000505797 loss)
I0109 18:50:56.711012 32941 sgd_solver.cpp:112] Iteration 6020, lr = 0.001
I0109 18:51:04.151376 32941 solver.cpp:239] Iteration 6040 (2.68812 iter/s, 7.44014s/20 iters), loss = 0.562517
I0109 18:51:04.151429 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0967346 (* 1 = 0.0967346 loss)
I0109 18:51:04.151438 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.769637 (* 1 = 0.769637 loss)
I0109 18:51:04.151445 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0169636 (* 1 = 0.0169636 loss)
I0109 18:51:04.151453 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00243883 (* 1 = 0.00243883 loss)
I0109 18:51:04.151460 32941 sgd_solver.cpp:112] Iteration 6040, lr = 0.001
I0109 18:51:11.549098 32941 solver.cpp:239] Iteration 6060 (2.70365 iter/s, 7.39741s/20 iters), loss = 0.263882
I0109 18:51:11.549165 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.170673 (* 1 = 0.170673 loss)
I0109 18:51:11.549180 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0994356 (* 1 = 0.0994356 loss)
I0109 18:51:11.549191 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0111694 (* 1 = 0.0111694 loss)
I0109 18:51:11.549201 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0115681 (* 1 = 0.0115681 loss)
I0109 18:51:11.549212 32941 sgd_solver.cpp:112] Iteration 6060, lr = 0.001
I0109 18:51:18.987803 32941 solver.cpp:239] Iteration 6080 (2.68875 iter/s, 7.4384s/20 iters), loss = 0.262156
I0109 18:51:18.987856 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0526686 (* 1 = 0.0526686 loss)
I0109 18:51:18.987866 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0503077 (* 1 = 0.0503077 loss)
I0109 18:51:18.987874 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00611444 (* 1 = 0.00611444 loss)
I0109 18:51:18.987882 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0020629 (* 1 = 0.0020629 loss)
I0109 18:51:18.987890 32941 sgd_solver.cpp:112] Iteration 6080, lr = 0.001
I0109 18:51:26.568621 32941 solver.cpp:239] Iteration 6100 (2.63835 iter/s, 7.5805s/20 iters), loss = 0.17579
I0109 18:51:26.568694 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.200506 (* 1 = 0.200506 loss)
I0109 18:51:26.568706 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.032069 (* 1 = 0.032069 loss)
I0109 18:51:26.568712 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.015793 (* 1 = 0.015793 loss)
I0109 18:51:26.568718 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00720613 (* 1 = 0.00720613 loss)
I0109 18:51:26.568727 32941 sgd_solver.cpp:112] Iteration 6100, lr = 0.001
I0109 18:51:34.078765 32941 solver.cpp:239] Iteration 6120 (2.66318 iter/s, 7.50982s/20 iters), loss = 0.150299
I0109 18:51:34.078819 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0407538 (* 1 = 0.0407538 loss)
I0109 18:51:34.078828 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0129494 (* 1 = 0.0129494 loss)
I0109 18:51:34.078835 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0245547 (* 1 = 0.0245547 loss)
I0109 18:51:34.078843 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00118774 (* 1 = 0.00118774 loss)
I0109 18:51:34.078851 32941 sgd_solver.cpp:112] Iteration 6120, lr = 0.001
I0109 18:51:41.381749 32941 solver.cpp:239] Iteration 6140 (2.73872 iter/s, 7.30268s/20 iters), loss = 0.298318
I0109 18:51:41.381801 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.131893 (* 1 = 0.131893 loss)
I0109 18:51:41.381810 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0465541 (* 1 = 0.0465541 loss)
I0109 18:51:41.381817 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00815264 (* 1 = 0.00815264 loss)
I0109 18:51:41.381824 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00809537 (* 1 = 0.00809537 loss)
I0109 18:51:41.381832 32941 sgd_solver.cpp:112] Iteration 6140, lr = 0.001
I0109 18:51:48.769305 32941 solver.cpp:239] Iteration 6160 (2.70737 iter/s, 7.38725s/20 iters), loss = 0.272883
I0109 18:51:48.769376 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0748334 (* 1 = 0.0748334 loss)
I0109 18:51:48.769384 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.173727 (* 1 = 0.173727 loss)
I0109 18:51:48.769392 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0115779 (* 1 = 0.0115779 loss)
I0109 18:51:48.769398 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00200516 (* 1 = 0.00200516 loss)
I0109 18:51:48.769405 32941 sgd_solver.cpp:112] Iteration 6160, lr = 0.001
I0109 18:51:56.011582 32941 solver.cpp:239] Iteration 6180 (2.76168 iter/s, 7.24196s/20 iters), loss = 0.1898
I0109 18:51:56.011642 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.203231 (* 1 = 0.203231 loss)
I0109 18:51:56.011652 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0433963 (* 1 = 0.0433963 loss)
I0109 18:51:56.011659 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0134985 (* 1 = 0.0134985 loss)
I0109 18:51:56.011665 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.021482 (* 1 = 0.021482 loss)
I0109 18:51:56.011673 32941 sgd_solver.cpp:112] Iteration 6180, lr = 0.001
speed: 0.376s / iter
I0109 18:52:03.387007 32941 solver.cpp:239] Iteration 6200 (2.71182 iter/s, 7.37511s/20 iters), loss = 0.154239
I0109 18:52:03.387061 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.14595 (* 1 = 0.14595 loss)
I0109 18:52:03.387070 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0538153 (* 1 = 0.0538153 loss)
I0109 18:52:03.387078 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0123169 (* 1 = 0.0123169 loss)
I0109 18:52:03.387084 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0073709 (* 1 = 0.0073709 loss)
I0109 18:52:03.387091 32941 sgd_solver.cpp:112] Iteration 6200, lr = 0.001
I0109 18:52:10.658272 32941 solver.cpp:239] Iteration 6220 (2.75067 iter/s, 7.27096s/20 iters), loss = 0.25014
I0109 18:52:10.658342 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0401569 (* 1 = 0.0401569 loss)
I0109 18:52:10.658352 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0842631 (* 1 = 0.0842631 loss)
I0109 18:52:10.658360 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00220694 (* 1 = 0.00220694 loss)
I0109 18:52:10.658366 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00136546 (* 1 = 0.00136546 loss)
I0109 18:52:10.658375 32941 sgd_solver.cpp:112] Iteration 6220, lr = 0.001
I0109 18:52:18.175904 32941 solver.cpp:239] Iteration 6240 (2.66053 iter/s, 7.51731s/20 iters), loss = 0.270607
I0109 18:52:18.175971 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.167035 (* 1 = 0.167035 loss)
I0109 18:52:18.175981 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0481664 (* 1 = 0.0481664 loss)
I0109 18:52:18.175988 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0112363 (* 1 = 0.0112363 loss)
I0109 18:52:18.175995 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00516811 (* 1 = 0.00516811 loss)
I0109 18:52:18.176003 32941 sgd_solver.cpp:112] Iteration 6240, lr = 0.001
I0109 18:52:25.513016 32941 solver.cpp:239] Iteration 6260 (2.72599 iter/s, 7.33679s/20 iters), loss = 0.112272
I0109 18:52:25.513080 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0491851 (* 1 = 0.0491851 loss)
I0109 18:52:25.513090 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0491981 (* 1 = 0.0491981 loss)
I0109 18:52:25.513098 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.039267 (* 1 = 0.039267 loss)
I0109 18:52:25.513104 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000642669 (* 1 = 0.000642669 loss)
I0109 18:52:25.513113 32941 sgd_solver.cpp:112] Iteration 6260, lr = 0.001
I0109 18:52:32.828519 32941 solver.cpp:239] Iteration 6280 (2.73404 iter/s, 7.31518s/20 iters), loss = 0.327894
I0109 18:52:32.828586 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.265924 (* 1 = 0.265924 loss)
I0109 18:52:32.828595 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.284911 (* 1 = 0.284911 loss)
I0109 18:52:32.828603 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0048642 (* 1 = 0.0048642 loss)
I0109 18:52:32.828609 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00895887 (* 1 = 0.00895887 loss)
I0109 18:52:32.828617 32941 sgd_solver.cpp:112] Iteration 6280, lr = 0.001
I0109 18:52:40.148123 32941 solver.cpp:239] Iteration 6300 (2.73251 iter/s, 7.31929s/20 iters), loss = 0.190233
I0109 18:52:40.148190 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.103276 (* 1 = 0.103276 loss)
I0109 18:52:40.148200 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0903775 (* 1 = 0.0903775 loss)
I0109 18:52:40.148207 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00872674 (* 1 = 0.00872674 loss)
I0109 18:52:40.148213 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0034776 (* 1 = 0.0034776 loss)
I0109 18:52:40.148221 32941 sgd_solver.cpp:112] Iteration 6300, lr = 0.001
I0109 18:52:47.407089 32941 solver.cpp:239] Iteration 6320 (2.75533 iter/s, 7.25866s/20 iters), loss = 0.175959
I0109 18:52:47.407147 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0867478 (* 1 = 0.0867478 loss)
I0109 18:52:47.407156 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0602894 (* 1 = 0.0602894 loss)
I0109 18:52:47.407162 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0275848 (* 1 = 0.0275848 loss)
I0109 18:52:47.407169 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0238498 (* 1 = 0.0238498 loss)
I0109 18:52:47.407176 32941 sgd_solver.cpp:112] Iteration 6320, lr = 0.001
I0109 18:52:54.750062 32941 solver.cpp:239] Iteration 6340 (2.72381 iter/s, 7.34266s/20 iters), loss = 0.229428
I0109 18:52:54.750131 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.178322 (* 1 = 0.178322 loss)
I0109 18:52:54.750140 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.13132 (* 1 = 0.13132 loss)
I0109 18:52:54.750146 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0172058 (* 1 = 0.0172058 loss)
I0109 18:52:54.750152 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.052995 (* 1 = 0.052995 loss)
I0109 18:52:54.750159 32941 sgd_solver.cpp:112] Iteration 6340, lr = 0.001
I0109 18:53:02.056592 32941 solver.cpp:239] Iteration 6360 (2.7374 iter/s, 7.30621s/20 iters), loss = 0.263288
I0109 18:53:02.056648 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0809617 (* 1 = 0.0809617 loss)
I0109 18:53:02.056658 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0270358 (* 1 = 0.0270358 loss)
I0109 18:53:02.056675 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00875343 (* 1 = 0.00875343 loss)
I0109 18:53:02.056681 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00933035 (* 1 = 0.00933035 loss)
I0109 18:53:02.056689 32941 sgd_solver.cpp:112] Iteration 6360, lr = 0.001
I0109 18:53:09.312471 32941 solver.cpp:239] Iteration 6380 (2.7565 iter/s, 7.25557s/20 iters), loss = 0.151478
I0109 18:53:09.312536 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.052609 (* 1 = 0.052609 loss)
I0109 18:53:09.312547 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0356526 (* 1 = 0.0356526 loss)
I0109 18:53:09.312554 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00120178 (* 1 = 0.00120178 loss)
I0109 18:53:09.312561 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00019639 (* 1 = 0.00019639 loss)
I0109 18:53:09.312568 32941 sgd_solver.cpp:112] Iteration 6380, lr = 0.001
speed: 0.375s / iter
I0109 18:53:16.676352 32941 solver.cpp:239] Iteration 6400 (2.71607 iter/s, 7.36357s/20 iters), loss = 0.1209
I0109 18:53:16.676403 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0744184 (* 1 = 0.0744184 loss)
I0109 18:53:16.676414 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0119447 (* 1 = 0.0119447 loss)
I0109 18:53:16.676420 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00391497 (* 1 = 0.00391497 loss)
I0109 18:53:16.676426 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000539042 (* 1 = 0.000539042 loss)
I0109 18:53:16.676434 32941 sgd_solver.cpp:112] Iteration 6400, lr = 0.001
I0109 18:53:24.071506 32941 solver.cpp:239] Iteration 6420 (2.70458 iter/s, 7.39485s/20 iters), loss = 0.198839
I0109 18:53:24.071569 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.096584 (* 1 = 0.096584 loss)
I0109 18:53:24.071579 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0501742 (* 1 = 0.0501742 loss)
I0109 18:53:24.071586 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00712866 (* 1 = 0.00712866 loss)
I0109 18:53:24.071593 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00397438 (* 1 = 0.00397438 loss)
I0109 18:53:24.071601 32941 sgd_solver.cpp:112] Iteration 6420, lr = 0.001
I0109 18:53:31.271313 32941 solver.cpp:239] Iteration 6440 (2.77797 iter/s, 7.1995s/20 iters), loss = 0.094954
I0109 18:53:31.271383 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0872154 (* 1 = 0.0872154 loss)
I0109 18:53:31.271392 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0346435 (* 1 = 0.0346435 loss)
I0109 18:53:31.271399 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00474538 (* 1 = 0.00474538 loss)
I0109 18:53:31.271406 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00270549 (* 1 = 0.00270549 loss)
I0109 18:53:31.271414 32941 sgd_solver.cpp:112] Iteration 6440, lr = 0.001
I0109 18:53:38.611052 32941 solver.cpp:239] Iteration 6460 (2.72501 iter/s, 7.33942s/20 iters), loss = 0.201122
I0109 18:53:38.611121 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.108967 (* 1 = 0.108967 loss)
I0109 18:53:38.611131 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.15241 (* 1 = 0.15241 loss)
I0109 18:53:38.611138 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0070432 (* 1 = 0.0070432 loss)
I0109 18:53:38.611145 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00392193 (* 1 = 0.00392193 loss)
I0109 18:53:38.611153 32941 sgd_solver.cpp:112] Iteration 6460, lr = 0.001
I0109 18:53:45.939596 32941 solver.cpp:239] Iteration 6480 (2.72918 iter/s, 7.32821s/20 iters), loss = 0.227081
I0109 18:53:45.939714 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0387581 (* 1 = 0.0387581 loss)
I0109 18:53:45.939733 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.063024 (* 1 = 0.063024 loss)
I0109 18:53:45.939745 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0155132 (* 1 = 0.0155132 loss)
I0109 18:53:45.939757 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00265724 (* 1 = 0.00265724 loss)
I0109 18:53:45.939770 32941 sgd_solver.cpp:112] Iteration 6480, lr = 0.001
I0109 18:53:53.336661 32941 solver.cpp:239] Iteration 6500 (2.70391 iter/s, 7.39671s/20 iters), loss = 0.311316
I0109 18:53:53.336728 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.170045 (* 1 = 0.170045 loss)
I0109 18:53:53.336737 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0949127 (* 1 = 0.0949127 loss)
I0109 18:53:53.336743 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0110485 (* 1 = 0.0110485 loss)
I0109 18:53:53.336750 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0258678 (* 1 = 0.0258678 loss)
I0109 18:53:53.336757 32941 sgd_solver.cpp:112] Iteration 6500, lr = 0.001
I0109 18:54:00.909492 32941 solver.cpp:239] Iteration 6520 (2.64114 iter/s, 7.5725s/20 iters), loss = 0.196049
I0109 18:54:00.909570 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.121647 (* 1 = 0.121647 loss)
I0109 18:54:00.909581 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0975982 (* 1 = 0.0975982 loss)
I0109 18:54:00.909590 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0319384 (* 1 = 0.0319384 loss)
I0109 18:54:00.909595 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00819406 (* 1 = 0.00819406 loss)
I0109 18:54:00.909603 32941 sgd_solver.cpp:112] Iteration 6520, lr = 0.001
I0109 18:54:08.259795 32941 solver.cpp:239] Iteration 6540 (2.7211 iter/s, 7.34997s/20 iters), loss = 0.2188
I0109 18:54:08.259863 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0404098 (* 1 = 0.0404098 loss)
I0109 18:54:08.259872 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.00522971 (* 1 = 0.00522971 loss)
I0109 18:54:08.259881 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000437176 (* 1 = 0.000437176 loss)
I0109 18:54:08.259886 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00169425 (* 1 = 0.00169425 loss)
I0109 18:54:08.259894 32941 sgd_solver.cpp:112] Iteration 6540, lr = 0.001
I0109 18:54:15.641790 32941 solver.cpp:239] Iteration 6560 (2.70941 iter/s, 7.38168s/20 iters), loss = 0.37274
I0109 18:54:15.641857 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.109416 (* 1 = 0.109416 loss)
I0109 18:54:15.641866 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.312681 (* 1 = 0.312681 loss)
I0109 18:54:15.641875 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00706016 (* 1 = 0.00706016 loss)
I0109 18:54:15.641881 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00161721 (* 1 = 0.00161721 loss)
I0109 18:54:15.641889 32941 sgd_solver.cpp:112] Iteration 6560, lr = 0.001
I0109 18:54:23.066413 32941 solver.cpp:239] Iteration 6580 (2.69386 iter/s, 7.4243s/20 iters), loss = 0.324575
I0109 18:54:23.066488 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.072136 (* 1 = 0.072136 loss)
I0109 18:54:23.066498 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.09269 (* 1 = 0.09269 loss)
I0109 18:54:23.066504 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00439826 (* 1 = 0.00439826 loss)
I0109 18:54:23.066511 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00212504 (* 1 = 0.00212504 loss)
I0109 18:54:23.066519 32941 sgd_solver.cpp:112] Iteration 6580, lr = 0.001
speed: 0.375s / iter
I0109 18:54:30.436527 32941 solver.cpp:239] Iteration 6600 (2.71377 iter/s, 7.36981s/20 iters), loss = 0.164769
I0109 18:54:30.436581 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.075086 (* 1 = 0.075086 loss)
I0109 18:54:30.436590 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0513794 (* 1 = 0.0513794 loss)
I0109 18:54:30.436596 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0236883 (* 1 = 0.0236883 loss)
I0109 18:54:30.436602 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0238399 (* 1 = 0.0238399 loss)
I0109 18:54:30.436609 32941 sgd_solver.cpp:112] Iteration 6600, lr = 0.001
I0109 18:54:37.765910 32941 solver.cpp:239] Iteration 6620 (2.72885 iter/s, 7.32909s/20 iters), loss = 0.126257
I0109 18:54:37.765954 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.102868 (* 1 = 0.102868 loss)
I0109 18:54:37.765962 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0197195 (* 1 = 0.0197195 loss)
I0109 18:54:37.765969 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0130919 (* 1 = 0.0130919 loss)
I0109 18:54:37.765974 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00166248 (* 1 = 0.00166248 loss)
I0109 18:54:37.765991 32941 sgd_solver.cpp:112] Iteration 6620, lr = 0.001
I0109 18:54:45.138121 32941 solver.cpp:239] Iteration 6640 (2.713 iter/s, 7.3719s/20 iters), loss = 0.16118
I0109 18:54:45.138186 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0340248 (* 1 = 0.0340248 loss)
I0109 18:54:45.138196 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0564831 (* 1 = 0.0564831 loss)
I0109 18:54:45.138203 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.000436083 (* 1 = 0.000436083 loss)
I0109 18:54:45.138211 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00046317 (* 1 = 0.00046317 loss)
I0109 18:54:45.138217 32941 sgd_solver.cpp:112] Iteration 6640, lr = 0.001
I0109 18:54:52.460021 32941 solver.cpp:239] Iteration 6660 (2.73165 iter/s, 7.32159s/20 iters), loss = 0.34662
I0109 18:54:52.460094 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.192697 (* 1 = 0.192697 loss)
I0109 18:54:52.460103 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.1618 (* 1 = 0.1618 loss)
I0109 18:54:52.460110 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0146909 (* 1 = 0.0146909 loss)
I0109 18:54:52.460116 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.027114 (* 1 = 0.027114 loss)
I0109 18:54:52.460124 32941 sgd_solver.cpp:112] Iteration 6660, lr = 0.001
I0109 18:54:59.784914 32941 solver.cpp:239] Iteration 6680 (2.73053 iter/s, 7.32458s/20 iters), loss = 0.182358
I0109 18:54:59.784963 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0866893 (* 1 = 0.0866893 loss)
I0109 18:54:59.784972 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.106814 (* 1 = 0.106814 loss)
I0109 18:54:59.784979 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00389829 (* 1 = 0.00389829 loss)
I0109 18:54:59.784986 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00216096 (* 1 = 0.00216096 loss)
I0109 18:54:59.784992 32941 sgd_solver.cpp:112] Iteration 6680, lr = 0.001
I0109 18:55:07.235466 32941 solver.cpp:239] Iteration 6700 (2.68448 iter/s, 7.45025s/20 iters), loss = 0.0896133
I0109 18:55:07.235540 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0447449 (* 1 = 0.0447449 loss)
I0109 18:55:07.235556 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0363127 (* 1 = 0.0363127 loss)
I0109 18:55:07.235568 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00612812 (* 1 = 0.00612812 loss)
I0109 18:55:07.235579 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00507685 (* 1 = 0.00507685 loss)
I0109 18:55:07.235590 32941 sgd_solver.cpp:112] Iteration 6700, lr = 0.001
I0109 18:55:14.621031 32941 solver.cpp:239] Iteration 6720 (2.7081 iter/s, 7.38524s/20 iters), loss = 0.18226
I0109 18:55:14.621094 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.131214 (* 1 = 0.131214 loss)
I0109 18:55:14.621104 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0527773 (* 1 = 0.0527773 loss)
I0109 18:55:14.621111 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0231014 (* 1 = 0.0231014 loss)
I0109 18:55:14.621117 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0213667 (* 1 = 0.0213667 loss)
I0109 18:55:14.621125 32941 sgd_solver.cpp:112] Iteration 6720, lr = 0.001
I0109 18:55:22.103770 32941 solver.cpp:239] Iteration 6740 (2.67293 iter/s, 7.48241s/20 iters), loss = 0.126719
I0109 18:55:22.103838 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0675058 (* 1 = 0.0675058 loss)
I0109 18:55:22.103848 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0962675 (* 1 = 0.0962675 loss)
I0109 18:55:22.103855 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0102856 (* 1 = 0.0102856 loss)
I0109 18:55:22.103862 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0017613 (* 1 = 0.0017613 loss)
I0109 18:55:22.103869 32941 sgd_solver.cpp:112] Iteration 6740, lr = 0.001
I0109 18:55:29.412058 32941 solver.cpp:239] Iteration 6760 (2.73674 iter/s, 7.30797s/20 iters), loss = 0.186039
I0109 18:55:29.412122 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.141612 (* 1 = 0.141612 loss)
I0109 18:55:29.412132 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0536914 (* 1 = 0.0536914 loss)
I0109 18:55:29.412138 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0124963 (* 1 = 0.0124963 loss)
I0109 18:55:29.412145 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0201257 (* 1 = 0.0201257 loss)
I0109 18:55:29.412153 32941 sgd_solver.cpp:112] Iteration 6760, lr = 0.001
I0109 18:55:36.791394 32941 solver.cpp:239] Iteration 6780 (2.71038 iter/s, 7.37903s/20 iters), loss = 0.278401
I0109 18:55:36.791456 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.103037 (* 1 = 0.103037 loss)
I0109 18:55:36.791465 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.052018 (* 1 = 0.052018 loss)
I0109 18:55:36.791472 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0043982 (* 1 = 0.0043982 loss)
I0109 18:55:36.791478 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0131526 (* 1 = 0.0131526 loss)
I0109 18:55:36.791486 32941 sgd_solver.cpp:112] Iteration 6780, lr = 0.001
speed: 0.375s / iter
I0109 18:55:44.112449 32941 solver.cpp:239] Iteration 6800 (2.73196 iter/s, 7.32074s/20 iters), loss = 0.208007
I0109 18:55:44.112512 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0556987 (* 1 = 0.0556987 loss)
I0109 18:55:44.112522 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0861291 (* 1 = 0.0861291 loss)
I0109 18:55:44.112529 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0288607 (* 1 = 0.0288607 loss)
I0109 18:55:44.112538 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0028002 (* 1 = 0.0028002 loss)
I0109 18:55:44.112546 32941 sgd_solver.cpp:112] Iteration 6800, lr = 0.001
I0109 18:55:51.486212 32941 solver.cpp:239] Iteration 6820 (2.71243 iter/s, 7.37345s/20 iters), loss = 0.136884
I0109 18:55:51.486271 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.125995 (* 1 = 0.125995 loss)
I0109 18:55:51.486280 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0399673 (* 1 = 0.0399673 loss)
I0109 18:55:51.486287 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0141051 (* 1 = 0.0141051 loss)
I0109 18:55:51.486294 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00454805 (* 1 = 0.00454805 loss)
I0109 18:55:51.486302 32941 sgd_solver.cpp:112] Iteration 6820, lr = 0.001
I0109 18:55:58.903978 32941 solver.cpp:239] Iteration 6840 (2.69635 iter/s, 7.41744s/20 iters), loss = 0.193759
I0109 18:55:58.904050 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0764303 (* 1 = 0.0764303 loss)
I0109 18:55:58.904060 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.040655 (* 1 = 0.040655 loss)
I0109 18:55:58.904067 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0173555 (* 1 = 0.0173555 loss)
I0109 18:55:58.904075 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00751595 (* 1 = 0.00751595 loss)
I0109 18:55:58.904083 32941 sgd_solver.cpp:112] Iteration 6840, lr = 0.001
I0109 18:56:06.629786 32941 solver.cpp:239] Iteration 6860 (2.58884 iter/s, 7.72547s/20 iters), loss = 0.446496
I0109 18:56:06.629851 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.103226 (* 1 = 0.103226 loss)
I0109 18:56:06.629860 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.379472 (* 1 = 0.379472 loss)
I0109 18:56:06.629868 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.131187 (* 1 = 0.131187 loss)
I0109 18:56:06.629874 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0545565 (* 1 = 0.0545565 loss)
I0109 18:56:06.629887 32941 sgd_solver.cpp:112] Iteration 6860, lr = 0.001
I0109 18:56:14.058969 32941 solver.cpp:239] Iteration 6880 (2.6922 iter/s, 7.42886s/20 iters), loss = 0.129011
I0109 18:56:14.059036 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0934762 (* 1 = 0.0934762 loss)
I0109 18:56:14.059046 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0398781 (* 1 = 0.0398781 loss)
I0109 18:56:14.059052 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00848281 (* 1 = 0.00848281 loss)
I0109 18:56:14.059059 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.0065224 (* 1 = 0.0065224 loss)
I0109 18:56:14.059067 32941 sgd_solver.cpp:112] Iteration 6880, lr = 0.001
I0109 18:56:21.404245 32941 solver.cpp:239] Iteration 6900 (2.72295 iter/s, 7.34496s/20 iters), loss = 0.162108
I0109 18:56:21.404306 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0447996 (* 1 = 0.0447996 loss)
I0109 18:56:21.404316 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0327506 (* 1 = 0.0327506 loss)
I0109 18:56:21.404323 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00417074 (* 1 = 0.00417074 loss)
I0109 18:56:21.404330 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.000295075 (* 1 = 0.000295075 loss)
I0109 18:56:21.404342 32941 sgd_solver.cpp:112] Iteration 6900, lr = 0.001
I0109 18:56:28.614601 32941 solver.cpp:239] Iteration 6920 (2.77391 iter/s, 7.21005s/20 iters), loss = 0.199491
I0109 18:56:28.614662 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0449054 (* 1 = 0.0449054 loss)
I0109 18:56:28.614672 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.141181 (* 1 = 0.141181 loss)
I0109 18:56:28.614678 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0159655 (* 1 = 0.0159655 loss)
I0109 18:56:28.614686 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00502318 (* 1 = 0.00502318 loss)
I0109 18:56:28.614693 32941 sgd_solver.cpp:112] Iteration 6920, lr = 0.001
I0109 18:56:35.946274 32941 solver.cpp:239] Iteration 6940 (2.728 iter/s, 7.33137s/20 iters), loss = 0.463809
I0109 18:56:35.946338 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.122552 (* 1 = 0.122552 loss)
I0109 18:56:35.946347 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0771316 (* 1 = 0.0771316 loss)
I0109 18:56:35.946357 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.0758062 (* 1 = 0.0758062 loss)
I0109 18:56:35.946363 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.120766 (* 1 = 0.120766 loss)
I0109 18:56:35.946372 32941 sgd_solver.cpp:112] Iteration 6940, lr = 0.001
I0109 18:56:43.338147 32941 solver.cpp:239] Iteration 6960 (2.70579 iter/s, 7.39156s/20 iters), loss = 0.194058
I0109 18:56:43.338213 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.12551 (* 1 = 0.12551 loss)
I0109 18:56:43.338223 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.0591255 (* 1 = 0.0591255 loss)
I0109 18:56:43.338230 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00722022 (* 1 = 0.00722022 loss)
I0109 18:56:43.338237 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00401958 (* 1 = 0.00401958 loss)
I0109 18:56:43.338245 32941 sgd_solver.cpp:112] Iteration 6960, lr = 0.001
I0109 18:56:50.688953 32941 solver.cpp:239] Iteration 6980 (2.72091 iter/s, 7.35049s/20 iters), loss = 0.0837724
I0109 18:56:50.689034 32941 solver.cpp:258]     Train net output #0: loss_bbox = 0.0467489 (* 1 = 0.0467489 loss)
I0109 18:56:50.689044 32941 solver.cpp:258]     Train net output #1: loss_cls = 0.060828 (* 1 = 0.060828 loss)
I0109 18:56:50.689052 32941 solver.cpp:258]     Train net output #2: rpn_cls_loss = 0.00120611 (* 1 = 0.00120611 loss)
I0109 18:56:50.689059 32941 solver.cpp:258]     Train net output #3: rpn_loss_bbox = 0.00147717 (* 1 = 0.00147717 loss)
I0109 18:56:50.689070 32941 sgd_solver.cpp:112] Iteration 6980, lr = 0.001
speed: 0.375s / iter
Wrote snapshot to: /home/ubuntu/user_space/maga_faster/our_method/output/faster_rcnn_end2end/voc_2007_trainval/vgg16_faster_rcnn_iter_7000.caffemodel
done solving

real	44m1.816s
user	37m13.846s
sys	7m33.512s
+ set +x
+ ./tools/test_net.py --gpu 0 --def models/pascal_voc/VGG16/faster_rcnn_end2end/test.prototxt --net /home/ubuntu/user_space/maga_faster/our_method/output/faster_rcnn_end2end/voc_2007_trainval/vgg16_faster_rcnn_iter_7000.caffemodel --imdb voc_2007_test --cfg experiments/cfgs/faster_rcnn_end2end.yml
Called with args:
Namespace(caffemodel='/home/ubuntu/user_space/maga_faster/our_method/output/faster_rcnn_end2end/voc_2007_trainval/vgg16_faster_rcnn_iter_7000.caffemodel', cfg_file='experiments/cfgs/faster_rcnn_end2end.yml', comp_mode=False, gpu_id=0, imdb_name='voc_2007_test', max_per_image=100, prototxt='models/pascal_voc/VGG16/faster_rcnn_end2end/test.prototxt', set_cfgs=None, vis=False, wait=True)
Using config:
{'DATA_DIR': '/home/ubuntu/user_space/maga_faster/our_method/data',
 'DEDUP_BOXES': 0.0625,
 'EPS': 1e-14,
 'EXP_DIR': 'faster_rcnn_end2end',
 'GPU_ID': 0,
 'MATLAB': 'matlab',
 'MODELS_DIR': '/home/ubuntu/user_space/maga_faster/our_method/models/pascal_voc',
 'PIXEL_MEANS': array([[[102.9801, 115.9465, 122.7717]]]),
 'RNG_SEED': 3,
 'ROOT_DIR': '/home/ubuntu/user_space/maga_faster/our_method',
 'TEST': {'BBOX_REG': True,
          'HAS_RPN': True,
          'MAX_SIZE': 1000,
          'NMS': 0.3,
          'PROPOSAL_METHOD': 'selective_search',
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'SCALES': [600],
          'SVM': False},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_SIZE': 128,
           'BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'BBOX_NORMALIZE_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZE_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_NORMALIZE_TARGETS': True,
           'BBOX_NORMALIZE_TARGETS_PRECOMPUTED': True,
           'BBOX_REG': True,
           'BBOX_THRESH': 0.5,
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': True,
           'IMS_PER_BATCH': 1,
           'MAX_SIZE': 1000,
           'PROPOSAL_METHOD': 'gt',
           'RPN_BATCHSIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000,
           'SCALES': [600],
           'SNAPSHOT_INFIX': '',
           'SNAPSHOT_ITERS': 10000,
           'USE_FLIPPED': True,
           'USE_PREFETCH': False},
 'USE_GPU_NMS': True}
WARNING: Logging before InitGoogleLogging() is written to STDERR
W0109 18:57:02.710209 33366 _caffe.cpp:140] DEPRECATION WARNING - deprecated use of Python interface
W0109 18:57:02.710254 33366 _caffe.cpp:141] Use this instead (with the named "weights" parameter):
W0109 18:57:02.710258 33366 _caffe.cpp:143] Net('models/pascal_voc/VGG16/faster_rcnn_end2end/test.prototxt', 1, weights='/home/ubuntu/user_space/maga_faster/our_method/output/faster_rcnn_end2end/voc_2007_trainval/vgg16_faster_rcnn_iter_7000.caffemodel')
I0109 18:57:02.730124 33366 upgrade_proto.cpp:69] Attempting to upgrade input file specified using deprecated input fields: models/pascal_voc/VGG16/faster_rcnn_end2end/test.prototxt
I0109 18:57:02.730173 33366 upgrade_proto.cpp:72] Successfully upgraded file specified using deprecated input fields.
W0109 18:57:02.730180 33366 upgrade_proto.cpp:74] Note that future Caffe releases will only support input layers and not input fields.
I0109 18:57:02.730638 33366 net.cpp:53] Initializing net from parameters: 
name: "VGG_ILSVRC_16_layers"
state {
  phase: TEST
  level: 0
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  top: "im_info"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 224
      dim: 224
    }
    shape {
      dim: 1
      dim: 3
    }
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "rpn_conv/3x3"
  type: "Convolution"
  bottom: "conv5_3"
  top: "rpn/output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu/3x3"
  type: "ReLU"
  bottom: "rpn/output"
  top: "rpn/output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 18
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn/output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 36
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: "rpn_cls_prob_reshape"
  type: "Reshape"
  bottom: "rpn_cls_prob"
  top: "rpn_cls_prob_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 18
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "proposal"
  type: "Python"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rois"
  python_param {
    module: "rpn.proposal_layer"
    layer: "ProposalLayer"
    param_str: "\'feat_stride\': 16"
  }
}
layer {
  name: "roi_pool5"
  type: "ROIPooling"
  bottom: "conv5_3"
  bottom: "rois"
  top: "pool5"
  roi_pooling_param {
    pooled_h: 7
    pooled_w: 7
    spatial_scale: 0.0625
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6"
  top: "fc6"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7"
  top: "fc7"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "cls_score"
  type: "InnerProduct"
  bottom: "fc7"
  top: "cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 9
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bbox_pred"
  type: "InnerProduct"
  bottom: "fc7"
  top: "bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 36
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "cls_prob"
  type: "Softmax"
  bottom: "cls_score"
  top: "cls_prob"
}
I0109 18:57:02.730890 33366 layer_factory.hpp:77] Creating layer input
I0109 18:57:02.730909 33366 net.cpp:86] Creating Layer input
I0109 18:57:02.730917 33366 net.cpp:382] input -> data
I0109 18:57:02.730931 33366 net.cpp:382] input -> im_info
I0109 18:57:02.763398 33366 net.cpp:124] Setting up input
I0109 18:57:02.763429 33366 net.cpp:131] Top shape: 1 3 224 224 (150528)
I0109 18:57:02.763435 33366 net.cpp:131] Top shape: 1 3 (3)
I0109 18:57:02.763438 33366 net.cpp:139] Memory required for data: 602124
I0109 18:57:02.763445 33366 layer_factory.hpp:77] Creating layer conv1_1
I0109 18:57:02.763466 33366 net.cpp:86] Creating Layer conv1_1
I0109 18:57:02.763470 33366 net.cpp:408] conv1_1 <- data
I0109 18:57:02.763478 33366 net.cpp:382] conv1_1 -> conv1_1
I0109 18:57:03.877813 33366 net.cpp:124] Setting up conv1_1
I0109 18:57:03.877849 33366 net.cpp:131] Top shape: 1 64 224 224 (3211264)
I0109 18:57:03.877854 33366 net.cpp:139] Memory required for data: 13447180
I0109 18:57:03.877871 33366 layer_factory.hpp:77] Creating layer relu1_1
I0109 18:57:03.877882 33366 net.cpp:86] Creating Layer relu1_1
I0109 18:57:03.877887 33366 net.cpp:408] relu1_1 <- conv1_1
I0109 18:57:03.877897 33366 net.cpp:369] relu1_1 -> conv1_1 (in-place)
I0109 18:57:03.878266 33366 net.cpp:124] Setting up relu1_1
I0109 18:57:03.878281 33366 net.cpp:131] Top shape: 1 64 224 224 (3211264)
I0109 18:57:03.878285 33366 net.cpp:139] Memory required for data: 26292236
I0109 18:57:03.878289 33366 layer_factory.hpp:77] Creating layer conv1_2
I0109 18:57:03.878299 33366 net.cpp:86] Creating Layer conv1_2
I0109 18:57:03.878304 33366 net.cpp:408] conv1_2 <- conv1_1
I0109 18:57:03.878312 33366 net.cpp:382] conv1_2 -> conv1_2
I0109 18:57:03.881848 33366 net.cpp:124] Setting up conv1_2
I0109 18:57:03.881870 33366 net.cpp:131] Top shape: 1 64 224 224 (3211264)
I0109 18:57:03.881875 33366 net.cpp:139] Memory required for data: 39137292
I0109 18:57:03.881883 33366 layer_factory.hpp:77] Creating layer relu1_2
I0109 18:57:03.881891 33366 net.cpp:86] Creating Layer relu1_2
I0109 18:57:03.881896 33366 net.cpp:408] relu1_2 <- conv1_2
I0109 18:57:03.881902 33366 net.cpp:369] relu1_2 -> conv1_2 (in-place)
I0109 18:57:03.882457 33366 net.cpp:124] Setting up relu1_2
I0109 18:57:03.882473 33366 net.cpp:131] Top shape: 1 64 224 224 (3211264)
I0109 18:57:03.882477 33366 net.cpp:139] Memory required for data: 51982348
I0109 18:57:03.882480 33366 layer_factory.hpp:77] Creating layer pool1
I0109 18:57:03.882488 33366 net.cpp:86] Creating Layer pool1
I0109 18:57:03.882493 33366 net.cpp:408] pool1 <- conv1_2
I0109 18:57:03.882504 33366 net.cpp:382] pool1 -> pool1
I0109 18:57:03.882550 33366 net.cpp:124] Setting up pool1
I0109 18:57:03.882560 33366 net.cpp:131] Top shape: 1 64 112 112 (802816)
I0109 18:57:03.882563 33366 net.cpp:139] Memory required for data: 55193612
I0109 18:57:03.882566 33366 layer_factory.hpp:77] Creating layer conv2_1
I0109 18:57:03.882575 33366 net.cpp:86] Creating Layer conv2_1
I0109 18:57:03.882578 33366 net.cpp:408] conv2_1 <- pool1
I0109 18:57:03.882587 33366 net.cpp:382] conv2_1 -> conv2_1
I0109 18:57:03.885932 33366 net.cpp:124] Setting up conv2_1
I0109 18:57:03.885952 33366 net.cpp:131] Top shape: 1 128 112 112 (1605632)
I0109 18:57:03.885957 33366 net.cpp:139] Memory required for data: 61616140
I0109 18:57:03.885969 33366 layer_factory.hpp:77] Creating layer relu2_1
I0109 18:57:03.885977 33366 net.cpp:86] Creating Layer relu2_1
I0109 18:57:03.885980 33366 net.cpp:408] relu2_1 <- conv2_1
I0109 18:57:03.885988 33366 net.cpp:369] relu2_1 -> conv2_1 (in-place)
I0109 18:57:03.886366 33366 net.cpp:124] Setting up relu2_1
I0109 18:57:03.886382 33366 net.cpp:131] Top shape: 1 128 112 112 (1605632)
I0109 18:57:03.886386 33366 net.cpp:139] Memory required for data: 68038668
I0109 18:57:03.886390 33366 layer_factory.hpp:77] Creating layer conv2_2
I0109 18:57:03.886402 33366 net.cpp:86] Creating Layer conv2_2
I0109 18:57:03.886406 33366 net.cpp:408] conv2_2 <- conv2_1
I0109 18:57:03.886413 33366 net.cpp:382] conv2_2 -> conv2_2
I0109 18:57:03.890046 33366 net.cpp:124] Setting up conv2_2
I0109 18:57:03.890071 33366 net.cpp:131] Top shape: 1 128 112 112 (1605632)
I0109 18:57:03.890076 33366 net.cpp:139] Memory required for data: 74461196
I0109 18:57:03.890084 33366 layer_factory.hpp:77] Creating layer relu2_2
I0109 18:57:03.890092 33366 net.cpp:86] Creating Layer relu2_2
I0109 18:57:03.890096 33366 net.cpp:408] relu2_2 <- conv2_2
I0109 18:57:03.890102 33366 net.cpp:369] relu2_2 -> conv2_2 (in-place)
I0109 18:57:03.890657 33366 net.cpp:124] Setting up relu2_2
I0109 18:57:03.890676 33366 net.cpp:131] Top shape: 1 128 112 112 (1605632)
I0109 18:57:03.890679 33366 net.cpp:139] Memory required for data: 80883724
I0109 18:57:03.890683 33366 layer_factory.hpp:77] Creating layer pool2
I0109 18:57:03.890691 33366 net.cpp:86] Creating Layer pool2
I0109 18:57:03.890695 33366 net.cpp:408] pool2 <- conv2_2
I0109 18:57:03.890703 33366 net.cpp:382] pool2 -> pool2
I0109 18:57:03.890746 33366 net.cpp:124] Setting up pool2
I0109 18:57:03.890753 33366 net.cpp:131] Top shape: 1 128 56 56 (401408)
I0109 18:57:03.890756 33366 net.cpp:139] Memory required for data: 82489356
I0109 18:57:03.890760 33366 layer_factory.hpp:77] Creating layer conv3_1
I0109 18:57:03.890775 33366 net.cpp:86] Creating Layer conv3_1
I0109 18:57:03.890779 33366 net.cpp:408] conv3_1 <- pool2
I0109 18:57:03.890786 33366 net.cpp:382] conv3_1 -> conv3_1
I0109 18:57:03.893993 33366 net.cpp:124] Setting up conv3_1
I0109 18:57:03.894011 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.894016 33366 net.cpp:139] Memory required for data: 85700620
I0109 18:57:03.894026 33366 layer_factory.hpp:77] Creating layer relu3_1
I0109 18:57:03.894034 33366 net.cpp:86] Creating Layer relu3_1
I0109 18:57:03.894038 33366 net.cpp:408] relu3_1 <- conv3_1
I0109 18:57:03.894045 33366 net.cpp:369] relu3_1 -> conv3_1 (in-place)
I0109 18:57:03.894412 33366 net.cpp:124] Setting up relu3_1
I0109 18:57:03.894425 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.894428 33366 net.cpp:139] Memory required for data: 88911884
I0109 18:57:03.894433 33366 layer_factory.hpp:77] Creating layer conv3_2
I0109 18:57:03.894443 33366 net.cpp:86] Creating Layer conv3_2
I0109 18:57:03.894446 33366 net.cpp:408] conv3_2 <- conv3_1
I0109 18:57:03.894454 33366 net.cpp:382] conv3_2 -> conv3_2
I0109 18:57:03.898032 33366 net.cpp:124] Setting up conv3_2
I0109 18:57:03.898049 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.898054 33366 net.cpp:139] Memory required for data: 92123148
I0109 18:57:03.898061 33366 layer_factory.hpp:77] Creating layer relu3_2
I0109 18:57:03.898068 33366 net.cpp:86] Creating Layer relu3_2
I0109 18:57:03.898072 33366 net.cpp:408] relu3_2 <- conv3_2
I0109 18:57:03.898079 33366 net.cpp:369] relu3_2 -> conv3_2 (in-place)
I0109 18:57:03.898643 33366 net.cpp:124] Setting up relu3_2
I0109 18:57:03.898659 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.898663 33366 net.cpp:139] Memory required for data: 95334412
I0109 18:57:03.898667 33366 layer_factory.hpp:77] Creating layer conv3_3
I0109 18:57:03.898679 33366 net.cpp:86] Creating Layer conv3_3
I0109 18:57:03.898682 33366 net.cpp:408] conv3_3 <- conv3_2
I0109 18:57:03.898690 33366 net.cpp:382] conv3_3 -> conv3_3
I0109 18:57:03.905359 33366 net.cpp:124] Setting up conv3_3
I0109 18:57:03.905387 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.905392 33366 net.cpp:139] Memory required for data: 98545676
I0109 18:57:03.905401 33366 layer_factory.hpp:77] Creating layer relu3_3
I0109 18:57:03.905417 33366 net.cpp:86] Creating Layer relu3_3
I0109 18:57:03.905422 33366 net.cpp:408] relu3_3 <- conv3_3
I0109 18:57:03.905429 33366 net.cpp:369] relu3_3 -> conv3_3 (in-place)
I0109 18:57:03.906008 33366 net.cpp:124] Setting up relu3_3
I0109 18:57:03.906026 33366 net.cpp:131] Top shape: 1 256 56 56 (802816)
I0109 18:57:03.906030 33366 net.cpp:139] Memory required for data: 101756940
I0109 18:57:03.906034 33366 layer_factory.hpp:77] Creating layer pool3
I0109 18:57:03.906042 33366 net.cpp:86] Creating Layer pool3
I0109 18:57:03.906046 33366 net.cpp:408] pool3 <- conv3_3
I0109 18:57:03.906052 33366 net.cpp:382] pool3 -> pool3
I0109 18:57:03.906100 33366 net.cpp:124] Setting up pool3
I0109 18:57:03.906106 33366 net.cpp:131] Top shape: 1 256 28 28 (200704)
I0109 18:57:03.906109 33366 net.cpp:139] Memory required for data: 102559756
I0109 18:57:03.906113 33366 layer_factory.hpp:77] Creating layer conv4_1
I0109 18:57:03.906127 33366 net.cpp:86] Creating Layer conv4_1
I0109 18:57:03.906132 33366 net.cpp:408] conv4_1 <- pool3
I0109 18:57:03.906141 33366 net.cpp:382] conv4_1 -> conv4_1
I0109 18:57:03.923780 33366 net.cpp:124] Setting up conv4_1
I0109 18:57:03.923822 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.923828 33366 net.cpp:139] Memory required for data: 104165388
I0109 18:57:03.923840 33366 layer_factory.hpp:77] Creating layer relu4_1
I0109 18:57:03.923856 33366 net.cpp:86] Creating Layer relu4_1
I0109 18:57:03.923862 33366 net.cpp:408] relu4_1 <- conv4_1
I0109 18:57:03.923871 33366 net.cpp:369] relu4_1 -> conv4_1 (in-place)
I0109 18:57:03.924360 33366 net.cpp:124] Setting up relu4_1
I0109 18:57:03.924378 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.924383 33366 net.cpp:139] Memory required for data: 105771020
I0109 18:57:03.924388 33366 layer_factory.hpp:77] Creating layer conv4_2
I0109 18:57:03.924402 33366 net.cpp:86] Creating Layer conv4_2
I0109 18:57:03.924408 33366 net.cpp:408] conv4_2 <- conv4_1
I0109 18:57:03.924419 33366 net.cpp:382] conv4_2 -> conv4_2
I0109 18:57:03.932845 33366 net.cpp:124] Setting up conv4_2
I0109 18:57:03.932884 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.932889 33366 net.cpp:139] Memory required for data: 107376652
I0109 18:57:03.932906 33366 layer_factory.hpp:77] Creating layer relu4_2
I0109 18:57:03.932919 33366 net.cpp:86] Creating Layer relu4_2
I0109 18:57:03.932924 33366 net.cpp:408] relu4_2 <- conv4_2
I0109 18:57:03.932931 33366 net.cpp:369] relu4_2 -> conv4_2 (in-place)
I0109 18:57:03.933514 33366 net.cpp:124] Setting up relu4_2
I0109 18:57:03.933531 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.933535 33366 net.cpp:139] Memory required for data: 108982284
I0109 18:57:03.933539 33366 layer_factory.hpp:77] Creating layer conv4_3
I0109 18:57:03.933552 33366 net.cpp:86] Creating Layer conv4_3
I0109 18:57:03.933555 33366 net.cpp:408] conv4_3 <- conv4_2
I0109 18:57:03.933562 33366 net.cpp:382] conv4_3 -> conv4_3
I0109 18:57:03.948688 33366 net.cpp:124] Setting up conv4_3
I0109 18:57:03.948721 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.948726 33366 net.cpp:139] Memory required for data: 110587916
I0109 18:57:03.948736 33366 layer_factory.hpp:77] Creating layer relu4_3
I0109 18:57:03.948746 33366 net.cpp:86] Creating Layer relu4_3
I0109 18:57:03.948751 33366 net.cpp:408] relu4_3 <- conv4_3
I0109 18:57:03.948763 33366 net.cpp:369] relu4_3 -> conv4_3 (in-place)
I0109 18:57:03.949160 33366 net.cpp:124] Setting up relu4_3
I0109 18:57:03.949175 33366 net.cpp:131] Top shape: 1 512 28 28 (401408)
I0109 18:57:03.949179 33366 net.cpp:139] Memory required for data: 112193548
I0109 18:57:03.949183 33366 layer_factory.hpp:77] Creating layer pool4
I0109 18:57:03.949190 33366 net.cpp:86] Creating Layer pool4
I0109 18:57:03.949194 33366 net.cpp:408] pool4 <- conv4_3
I0109 18:57:03.949203 33366 net.cpp:382] pool4 -> pool4
I0109 18:57:03.949245 33366 net.cpp:124] Setting up pool4
I0109 18:57:03.949252 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.949256 33366 net.cpp:139] Memory required for data: 112594956
I0109 18:57:03.949260 33366 layer_factory.hpp:77] Creating layer conv5_1
I0109 18:57:03.949271 33366 net.cpp:86] Creating Layer conv5_1
I0109 18:57:03.949275 33366 net.cpp:408] conv5_1 <- pool4
I0109 18:57:03.949282 33366 net.cpp:382] conv5_1 -> conv5_1
I0109 18:57:03.959434 33366 net.cpp:124] Setting up conv5_1
I0109 18:57:03.959473 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.959478 33366 net.cpp:139] Memory required for data: 112996364
I0109 18:57:03.959489 33366 layer_factory.hpp:77] Creating layer relu5_1
I0109 18:57:03.959501 33366 net.cpp:86] Creating Layer relu5_1
I0109 18:57:03.959506 33366 net.cpp:408] relu5_1 <- conv5_1
I0109 18:57:03.959513 33366 net.cpp:369] relu5_1 -> conv5_1 (in-place)
I0109 18:57:03.960091 33366 net.cpp:124] Setting up relu5_1
I0109 18:57:03.960108 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.960111 33366 net.cpp:139] Memory required for data: 113397772
I0109 18:57:03.960115 33366 layer_factory.hpp:77] Creating layer conv5_2
I0109 18:57:03.960127 33366 net.cpp:86] Creating Layer conv5_2
I0109 18:57:03.960131 33366 net.cpp:408] conv5_2 <- conv5_1
I0109 18:57:03.960140 33366 net.cpp:382] conv5_2 -> conv5_2
I0109 18:57:03.968320 33366 net.cpp:124] Setting up conv5_2
I0109 18:57:03.968358 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.968363 33366 net.cpp:139] Memory required for data: 113799180
I0109 18:57:03.968372 33366 layer_factory.hpp:77] Creating layer relu5_2
I0109 18:57:03.968382 33366 net.cpp:86] Creating Layer relu5_2
I0109 18:57:03.968387 33366 net.cpp:408] relu5_2 <- conv5_2
I0109 18:57:03.968397 33366 net.cpp:369] relu5_2 -> conv5_2 (in-place)
I0109 18:57:03.968773 33366 net.cpp:124] Setting up relu5_2
I0109 18:57:03.968789 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.968793 33366 net.cpp:139] Memory required for data: 114200588
I0109 18:57:03.968797 33366 layer_factory.hpp:77] Creating layer conv5_3
I0109 18:57:03.968808 33366 net.cpp:86] Creating Layer conv5_3
I0109 18:57:03.968812 33366 net.cpp:408] conv5_3 <- conv5_2
I0109 18:57:03.968819 33366 net.cpp:382] conv5_3 -> conv5_3
I0109 18:57:03.985044 33366 net.cpp:124] Setting up conv5_3
I0109 18:57:03.985090 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.985096 33366 net.cpp:139] Memory required for data: 114601996
I0109 18:57:03.985108 33366 layer_factory.hpp:77] Creating layer relu5_3
I0109 18:57:03.985121 33366 net.cpp:86] Creating Layer relu5_3
I0109 18:57:03.985126 33366 net.cpp:408] relu5_3 <- conv5_3
I0109 18:57:03.985137 33366 net.cpp:369] relu5_3 -> conv5_3 (in-place)
I0109 18:57:03.987573 33366 net.cpp:124] Setting up relu5_3
I0109 18:57:03.987593 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.987597 33366 net.cpp:139] Memory required for data: 115003404
I0109 18:57:03.987602 33366 layer_factory.hpp:77] Creating layer conv5_3_relu5_3_0_split
I0109 18:57:03.987613 33366 net.cpp:86] Creating Layer conv5_3_relu5_3_0_split
I0109 18:57:03.987618 33366 net.cpp:408] conv5_3_relu5_3_0_split <- conv5_3
I0109 18:57:03.987627 33366 net.cpp:382] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_0
I0109 18:57:03.987639 33366 net.cpp:382] conv5_3_relu5_3_0_split -> conv5_3_relu5_3_0_split_1
I0109 18:57:03.987687 33366 net.cpp:124] Setting up conv5_3_relu5_3_0_split
I0109 18:57:03.987701 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.987706 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:03.987710 33366 net.cpp:139] Memory required for data: 115806220
I0109 18:57:03.987715 33366 layer_factory.hpp:77] Creating layer rpn_conv/3x3
I0109 18:57:03.987740 33366 net.cpp:86] Creating Layer rpn_conv/3x3
I0109 18:57:03.987747 33366 net.cpp:408] rpn_conv/3x3 <- conv5_3_relu5_3_0_split_0
I0109 18:57:03.987756 33366 net.cpp:382] rpn_conv/3x3 -> rpn/output
I0109 18:57:04.024945 33366 net.cpp:124] Setting up rpn_conv/3x3
I0109 18:57:04.024976 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:04.024979 33366 net.cpp:139] Memory required for data: 116207628
I0109 18:57:04.024989 33366 layer_factory.hpp:77] Creating layer rpn_relu/3x3
I0109 18:57:04.025000 33366 net.cpp:86] Creating Layer rpn_relu/3x3
I0109 18:57:04.025005 33366 net.cpp:408] rpn_relu/3x3 <- rpn/output
I0109 18:57:04.025014 33366 net.cpp:369] rpn_relu/3x3 -> rpn/output (in-place)
I0109 18:57:04.025604 33366 net.cpp:124] Setting up rpn_relu/3x3
I0109 18:57:04.025630 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:04.025635 33366 net.cpp:139] Memory required for data: 116609036
I0109 18:57:04.025640 33366 layer_factory.hpp:77] Creating layer rpn/output_rpn_relu/3x3_0_split
I0109 18:57:04.025650 33366 net.cpp:86] Creating Layer rpn/output_rpn_relu/3x3_0_split
I0109 18:57:04.025653 33366 net.cpp:408] rpn/output_rpn_relu/3x3_0_split <- rpn/output
I0109 18:57:04.025660 33366 net.cpp:382] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_0
I0109 18:57:04.025667 33366 net.cpp:382] rpn/output_rpn_relu/3x3_0_split -> rpn/output_rpn_relu/3x3_0_split_1
I0109 18:57:04.025717 33366 net.cpp:124] Setting up rpn/output_rpn_relu/3x3_0_split
I0109 18:57:04.025727 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:04.025732 33366 net.cpp:131] Top shape: 1 512 14 14 (100352)
I0109 18:57:04.025734 33366 net.cpp:139] Memory required for data: 117411852
I0109 18:57:04.025738 33366 layer_factory.hpp:77] Creating layer rpn_cls_score
I0109 18:57:04.025751 33366 net.cpp:86] Creating Layer rpn_cls_score
I0109 18:57:04.025758 33366 net.cpp:408] rpn_cls_score <- rpn/output_rpn_relu/3x3_0_split_0
I0109 18:57:04.025768 33366 net.cpp:382] rpn_cls_score -> rpn_cls_score
I0109 18:57:04.027667 33366 net.cpp:124] Setting up rpn_cls_score
I0109 18:57:04.027683 33366 net.cpp:131] Top shape: 1 18 14 14 (3528)
I0109 18:57:04.027688 33366 net.cpp:139] Memory required for data: 117425964
I0109 18:57:04.027694 33366 layer_factory.hpp:77] Creating layer rpn_bbox_pred
I0109 18:57:04.027707 33366 net.cpp:86] Creating Layer rpn_bbox_pred
I0109 18:57:04.027711 33366 net.cpp:408] rpn_bbox_pred <- rpn/output_rpn_relu/3x3_0_split_1
I0109 18:57:04.027720 33366 net.cpp:382] rpn_bbox_pred -> rpn_bbox_pred
I0109 18:57:04.029682 33366 net.cpp:124] Setting up rpn_bbox_pred
I0109 18:57:04.029711 33366 net.cpp:131] Top shape: 1 36 14 14 (7056)
I0109 18:57:04.029716 33366 net.cpp:139] Memory required for data: 117454188
I0109 18:57:04.029722 33366 layer_factory.hpp:77] Creating layer rpn_cls_score_reshape
I0109 18:57:04.029733 33366 net.cpp:86] Creating Layer rpn_cls_score_reshape
I0109 18:57:04.029737 33366 net.cpp:408] rpn_cls_score_reshape <- rpn_cls_score
I0109 18:57:04.029743 33366 net.cpp:382] rpn_cls_score_reshape -> rpn_cls_score_reshape
I0109 18:57:04.029775 33366 net.cpp:124] Setting up rpn_cls_score_reshape
I0109 18:57:04.029784 33366 net.cpp:131] Top shape: 1 2 126 14 (3528)
I0109 18:57:04.029788 33366 net.cpp:139] Memory required for data: 117468300
I0109 18:57:04.029791 33366 layer_factory.hpp:77] Creating layer rpn_cls_prob
I0109 18:57:04.029798 33366 net.cpp:86] Creating Layer rpn_cls_prob
I0109 18:57:04.029801 33366 net.cpp:408] rpn_cls_prob <- rpn_cls_score_reshape
I0109 18:57:04.029809 33366 net.cpp:382] rpn_cls_prob -> rpn_cls_prob
I0109 18:57:04.030259 33366 net.cpp:124] Setting up rpn_cls_prob
I0109 18:57:04.030273 33366 net.cpp:131] Top shape: 1 2 126 14 (3528)
I0109 18:57:04.030277 33366 net.cpp:139] Memory required for data: 117482412
I0109 18:57:04.030282 33366 layer_factory.hpp:77] Creating layer rpn_cls_prob_reshape
I0109 18:57:04.030290 33366 net.cpp:86] Creating Layer rpn_cls_prob_reshape
I0109 18:57:04.030294 33366 net.cpp:408] rpn_cls_prob_reshape <- rpn_cls_prob
I0109 18:57:04.030302 33366 net.cpp:382] rpn_cls_prob_reshape -> rpn_cls_prob_reshape
I0109 18:57:04.030326 33366 net.cpp:124] Setting up rpn_cls_prob_reshape
I0109 18:57:04.030333 33366 net.cpp:131] Top shape: 1 18 14 14 (3528)
I0109 18:57:04.030336 33366 net.cpp:139] Memory required for data: 117496524
I0109 18:57:04.030339 33366 layer_factory.hpp:77] Creating layer proposal
I0109 18:57:04.031411 33366 net.cpp:86] Creating Layer proposal
I0109 18:57:04.031427 33366 net.cpp:408] proposal <- rpn_cls_prob_reshape
I0109 18:57:04.031433 33366 net.cpp:408] proposal <- rpn_bbox_pred
I0109 18:57:04.031438 33366 net.cpp:408] proposal <- im_info
I0109 18:57:04.031445 33366 net.cpp:382] proposal -> rois
I0109 18:57:04.032297 33366 net.cpp:124] Setting up proposal
I0109 18:57:04.032313 33366 net.cpp:131] Top shape: 1 5 (5)
I0109 18:57:04.032328 33366 net.cpp:139] Memory required for data: 117496544
I0109 18:57:04.032332 33366 layer_factory.hpp:77] Creating layer roi_pool5
I0109 18:57:04.032341 33366 net.cpp:86] Creating Layer roi_pool5
I0109 18:57:04.032346 33366 net.cpp:408] roi_pool5 <- conv5_3_relu5_3_0_split_1
I0109 18:57:04.032351 33366 net.cpp:408] roi_pool5 <- rois
I0109 18:57:04.032356 33366 net.cpp:382] roi_pool5 -> pool5
I0109 18:57:04.032364 33366 roi_pooling_layer.cpp:30] Spatial scale: 0.0625
I0109 18:57:04.032414 33366 net.cpp:124] Setting up roi_pool5
I0109 18:57:04.032423 33366 net.cpp:131] Top shape: 1 512 7 7 (25088)
I0109 18:57:04.032428 33366 net.cpp:139] Memory required for data: 117596896
I0109 18:57:04.032430 33366 layer_factory.hpp:77] Creating layer fc6
I0109 18:57:04.032438 33366 net.cpp:86] Creating Layer fc6
I0109 18:57:04.032443 33366 net.cpp:408] fc6 <- pool5
I0109 18:57:04.032450 33366 net.cpp:382] fc6 -> fc6
I0109 18:57:04.315176 33366 net.cpp:124] Setting up fc6
I0109 18:57:04.315249 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.315253 33366 net.cpp:139] Memory required for data: 117613280
I0109 18:57:04.315279 33366 layer_factory.hpp:77] Creating layer relu6
I0109 18:57:04.315295 33366 net.cpp:86] Creating Layer relu6
I0109 18:57:04.315299 33366 net.cpp:408] relu6 <- fc6
I0109 18:57:04.315307 33366 net.cpp:369] relu6 -> fc6 (in-place)
I0109 18:57:04.316130 33366 net.cpp:124] Setting up relu6
I0109 18:57:04.316145 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.316160 33366 net.cpp:139] Memory required for data: 117629664
I0109 18:57:04.316164 33366 layer_factory.hpp:77] Creating layer drop6
I0109 18:57:04.316174 33366 net.cpp:86] Creating Layer drop6
I0109 18:57:04.316179 33366 net.cpp:408] drop6 <- fc6
I0109 18:57:04.316186 33366 net.cpp:369] drop6 -> fc6 (in-place)
I0109 18:57:04.316213 33366 net.cpp:124] Setting up drop6
I0109 18:57:04.316218 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.316222 33366 net.cpp:139] Memory required for data: 117646048
I0109 18:57:04.316226 33366 layer_factory.hpp:77] Creating layer fc7
I0109 18:57:04.316237 33366 net.cpp:86] Creating Layer fc7
I0109 18:57:04.316241 33366 net.cpp:408] fc7 <- fc6
I0109 18:57:04.316246 33366 net.cpp:382] fc7 -> fc7
I0109 18:57:04.366168 33366 net.cpp:124] Setting up fc7
I0109 18:57:04.366209 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.366214 33366 net.cpp:139] Memory required for data: 117662432
I0109 18:57:04.366228 33366 layer_factory.hpp:77] Creating layer relu7
I0109 18:57:04.366241 33366 net.cpp:86] Creating Layer relu7
I0109 18:57:04.366246 33366 net.cpp:408] relu7 <- fc7
I0109 18:57:04.366252 33366 net.cpp:369] relu7 -> fc7 (in-place)
I0109 18:57:04.366729 33366 net.cpp:124] Setting up relu7
I0109 18:57:04.366744 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.366748 33366 net.cpp:139] Memory required for data: 117678816
I0109 18:57:04.366752 33366 layer_factory.hpp:77] Creating layer drop7
I0109 18:57:04.366760 33366 net.cpp:86] Creating Layer drop7
I0109 18:57:04.366763 33366 net.cpp:408] drop7 <- fc7
I0109 18:57:04.366772 33366 net.cpp:369] drop7 -> fc7 (in-place)
I0109 18:57:04.366798 33366 net.cpp:124] Setting up drop7
I0109 18:57:04.366803 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.366807 33366 net.cpp:139] Memory required for data: 117695200
I0109 18:57:04.366811 33366 layer_factory.hpp:77] Creating layer fc7_drop7_0_split
I0109 18:57:04.366822 33366 net.cpp:86] Creating Layer fc7_drop7_0_split
I0109 18:57:04.366825 33366 net.cpp:408] fc7_drop7_0_split <- fc7
I0109 18:57:04.366832 33366 net.cpp:382] fc7_drop7_0_split -> fc7_drop7_0_split_0
I0109 18:57:04.366840 33366 net.cpp:382] fc7_drop7_0_split -> fc7_drop7_0_split_1
I0109 18:57:04.366873 33366 net.cpp:124] Setting up fc7_drop7_0_split
I0109 18:57:04.366883 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.366886 33366 net.cpp:131] Top shape: 1 4096 (4096)
I0109 18:57:04.366889 33366 net.cpp:139] Memory required for data: 117727968
I0109 18:57:04.366894 33366 layer_factory.hpp:77] Creating layer cls_score
I0109 18:57:04.366905 33366 net.cpp:86] Creating Layer cls_score
I0109 18:57:04.366909 33366 net.cpp:408] cls_score <- fc7_drop7_0_split_0
I0109 18:57:04.366915 33366 net.cpp:382] cls_score -> cls_score
I0109 18:57:04.367434 33366 net.cpp:124] Setting up cls_score
I0109 18:57:04.367444 33366 net.cpp:131] Top shape: 1 9 (9)
I0109 18:57:04.367449 33366 net.cpp:139] Memory required for data: 117728004
I0109 18:57:04.367455 33366 layer_factory.hpp:77] Creating layer bbox_pred
I0109 18:57:04.367461 33366 net.cpp:86] Creating Layer bbox_pred
I0109 18:57:04.367465 33366 net.cpp:408] bbox_pred <- fc7_drop7_0_split_1
I0109 18:57:04.367473 33366 net.cpp:382] bbox_pred -> bbox_pred
I0109 18:57:04.369274 33366 net.cpp:124] Setting up bbox_pred
I0109 18:57:04.369287 33366 net.cpp:131] Top shape: 1 36 (36)
I0109 18:57:04.369290 33366 net.cpp:139] Memory required for data: 117728148
I0109 18:57:04.369297 33366 layer_factory.hpp:77] Creating layer cls_prob
I0109 18:57:04.369308 33366 net.cpp:86] Creating Layer cls_prob
I0109 18:57:04.369313 33366 net.cpp:408] cls_prob <- cls_score
I0109 18:57:04.369318 33366 net.cpp:382] cls_prob -> cls_prob
I0109 18:57:04.371811 33366 net.cpp:124] Setting up cls_prob
I0109 18:57:04.371827 33366 net.cpp:131] Top shape: 1 9 (9)
I0109 18:57:04.371831 33366 net.cpp:139] Memory required for data: 117728184
I0109 18:57:04.371835 33366 net.cpp:202] cls_prob does not need backward computation.
I0109 18:57:04.371840 33366 net.cpp:202] bbox_pred does not need backward computation.
I0109 18:57:04.371843 33366 net.cpp:202] cls_score does not need backward computation.
I0109 18:57:04.371847 33366 net.cpp:202] fc7_drop7_0_split does not need backward computation.
I0109 18:57:04.371851 33366 net.cpp:202] drop7 does not need backward computation.
I0109 18:57:04.371855 33366 net.cpp:202] relu7 does not need backward computation.
I0109 18:57:04.371860 33366 net.cpp:202] fc7 does not need backward computation.
I0109 18:57:04.371863 33366 net.cpp:202] drop6 does not need backward computation.
I0109 18:57:04.371866 33366 net.cpp:202] relu6 does not need backward computation.
I0109 18:57:04.371870 33366 net.cpp:202] fc6 does not need backward computation.
I0109 18:57:04.371873 33366 net.cpp:202] roi_pool5 does not need backward computation.
I0109 18:57:04.371878 33366 net.cpp:202] proposal does not need backward computation.
I0109 18:57:04.371882 33366 net.cpp:202] rpn_cls_prob_reshape does not need backward computation.
I0109 18:57:04.371887 33366 net.cpp:202] rpn_cls_prob does not need backward computation.
I0109 18:57:04.371891 33366 net.cpp:202] rpn_cls_score_reshape does not need backward computation.
I0109 18:57:04.371896 33366 net.cpp:202] rpn_bbox_pred does not need backward computation.
I0109 18:57:04.371899 33366 net.cpp:202] rpn_cls_score does not need backward computation.
I0109 18:57:04.371906 33366 net.cpp:202] rpn/output_rpn_relu/3x3_0_split does not need backward computation.
I0109 18:57:04.371910 33366 net.cpp:202] rpn_relu/3x3 does not need backward computation.
I0109 18:57:04.371914 33366 net.cpp:202] rpn_conv/3x3 does not need backward computation.
I0109 18:57:04.371918 33366 net.cpp:202] conv5_3_relu5_3_0_split does not need backward computation.
I0109 18:57:04.371922 33366 net.cpp:202] relu5_3 does not need backward computation.
I0109 18:57:04.371927 33366 net.cpp:202] conv5_3 does not need backward computation.
I0109 18:57:04.371930 33366 net.cpp:202] relu5_2 does not need backward computation.
I0109 18:57:04.371934 33366 net.cpp:202] conv5_2 does not need backward computation.
I0109 18:57:04.371938 33366 net.cpp:202] relu5_1 does not need backward computation.
I0109 18:57:04.371942 33366 net.cpp:202] conv5_1 does not need backward computation.
I0109 18:57:04.371945 33366 net.cpp:202] pool4 does not need backward computation.
I0109 18:57:04.371950 33366 net.cpp:202] relu4_3 does not need backward computation.
I0109 18:57:04.371954 33366 net.cpp:202] conv4_3 does not need backward computation.
I0109 18:57:04.371958 33366 net.cpp:202] relu4_2 does not need backward computation.
I0109 18:57:04.371961 33366 net.cpp:202] conv4_2 does not need backward computation.
I0109 18:57:04.371965 33366 net.cpp:202] relu4_1 does not need backward computation.
I0109 18:57:04.371968 33366 net.cpp:202] conv4_1 does not need backward computation.
I0109 18:57:04.371973 33366 net.cpp:202] pool3 does not need backward computation.
I0109 18:57:04.371976 33366 net.cpp:202] relu3_3 does not need backward computation.
I0109 18:57:04.371979 33366 net.cpp:202] conv3_3 does not need backward computation.
I0109 18:57:04.371984 33366 net.cpp:202] relu3_2 does not need backward computation.
I0109 18:57:04.371987 33366 net.cpp:202] conv3_2 does not need backward computation.
I0109 18:57:04.371991 33366 net.cpp:202] relu3_1 does not need backward computation.
I0109 18:57:04.371994 33366 net.cpp:202] conv3_1 does not need backward computation.
I0109 18:57:04.371999 33366 net.cpp:202] pool2 does not need backward computation.
I0109 18:57:04.372002 33366 net.cpp:202] relu2_2 does not need backward computation.
I0109 18:57:04.372006 33366 net.cpp:202] conv2_2 does not need backward computation.
I0109 18:57:04.372009 33366 net.cpp:202] relu2_1 does not need backward computation.
I0109 18:57:04.372014 33366 net.cpp:202] conv2_1 does not need backward computation.
I0109 18:57:04.372016 33366 net.cpp:202] pool1 does not need backward computation.
I0109 18:57:04.372020 33366 net.cpp:202] relu1_2 does not need backward computation.
I0109 18:57:04.372025 33366 net.cpp:202] conv1_2 does not need backward computation.
I0109 18:57:04.372030 33366 net.cpp:202] relu1_1 does not need backward computation.
I0109 18:57:04.372032 33366 net.cpp:202] conv1_1 does not need backward computation.
I0109 18:57:04.372036 33366 net.cpp:202] input does not need backward computation.
I0109 18:57:04.372040 33366 net.cpp:244] This network produces output bbox_pred
I0109 18:57:04.372045 33366 net.cpp:244] This network produces output cls_prob
I0109 18:57:04.372079 33366 net.cpp:257] Network initialization done.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:537] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 547335701
I0109 18:57:04.884604 33366 net.cpp:746] Ignoring source layer input-data
I0109 18:57:04.884624 33366 net.cpp:746] Ignoring source layer data_input-data_0_split
I0109 18:57:04.884634 33366 net.cpp:746] Ignoring source layer im_info_input-data_1_split
I0109 18:57:04.884636 33366 net.cpp:746] Ignoring source layer gt_boxes_input-data_2_split
I0109 18:57:04.896934 33366 net.cpp:746] Ignoring source layer rpn_cls_score_rpn_cls_score_0_split
I0109 18:57:04.896975 33366 net.cpp:746] Ignoring source layer rpn_bbox_pred_rpn_bbox_pred_0_split
I0109 18:57:04.896981 33366 net.cpp:746] Ignoring source layer rpn_cls_score_reshape_rpn_cls_score_reshape_0_split
I0109 18:57:04.896983 33366 net.cpp:746] Ignoring source layer rpn-data
I0109 18:57:04.896987 33366 net.cpp:746] Ignoring source layer rpn_loss_cls
I0109 18:57:04.896991 33366 net.cpp:746] Ignoring source layer rpn_loss_bbox
I0109 18:57:04.896996 33366 net.cpp:746] Ignoring source layer roi-data
I0109 18:57:04.984434 33366 net.cpp:746] Ignoring source layer loss_cls
I0109 18:57:04.984467 33366 net.cpp:746] Ignoring source layer loss_bbox
im_detect: 1/2097 0.237s 0.001s
im_detect: 2/2097 0.182s 0.001s
im_detect: 3/2097 0.163s 0.001s
im_detect: 4/2097 0.153s 0.001s
im_detect: 5/2097 0.147s 0.001s
im_detect: 6/2097 0.141s 0.001s
im_detect: 7/2097 0.138s 0.001s
im_detect: 8/2097 0.138s 0.001s
im_detect: 9/2097 0.138s 0.001s
im_detect: 10/2097 0.137s 0.001s
im_detect: 11/2097 0.135s 0.001s
im_detect: 12/2097 0.134s 0.001s
im_detect: 13/2097 0.133s 0.001s
im_detect: 14/2097 0.132s 0.001s
im_detect: 15/2097 0.131s 0.001s
im_detect: 16/2097 0.130s 0.001s
im_detect: 17/2097 0.130s 0.001s
im_detect: 18/2097 0.130s 0.001s
im_detect: 19/2097 0.130s 0.001s
im_detect: 20/2097 0.129s 0.001s
im_detect: 21/2097 0.129s 0.001s
im_detect: 22/2097 0.129s 0.001s
im_detect: 23/2097 0.128s 0.001s
im_detect: 24/2097 0.128s 0.001s
im_detect: 25/2097 0.127s 0.001s
im_detect: 26/2097 0.127s 0.001s
im_detect: 27/2097 0.127s 0.001s
im_detect: 28/2097 0.126s 0.001s
im_detect: 29/2097 0.126s 0.001s
im_detect: 30/2097 0.126s 0.001s
im_detect: 31/2097 0.126s 0.001s
im_detect: 32/2097 0.126s 0.001s
im_detect: 33/2097 0.126s 0.001s
im_detect: 34/2097 0.126s 0.001s
im_detect: 35/2097 0.126s 0.001s
im_detect: 36/2097 0.126s 0.001s
im_detect: 37/2097 0.126s 0.001s
im_detect: 38/2097 0.126s 0.001s
im_detect: 39/2097 0.127s 0.001s
im_detect: 40/2097 0.127s 0.001s
im_detect: 41/2097 0.127s 0.001s
im_detect: 42/2097 0.126s 0.001s
im_detect: 43/2097 0.126s 0.001s
im_detect: 44/2097 0.126s 0.001s
im_detect: 45/2097 0.126s 0.001s
im_detect: 46/2097 0.126s 0.001s
im_detect: 47/2097 0.126s 0.001s
im_detect: 48/2097 0.126s 0.001s
im_detect: 49/2097 0.125s 0.001s
im_detect: 50/2097 0.125s 0.001s
im_detect: 51/2097 0.125s 0.001s
im_detect: 52/2097 0.125s 0.001s
im_detect: 53/2097 0.125s 0.001s
im_detect: 54/2097 0.125s 0.001s
im_detect: 55/2097 0.125s 0.001s
im_detect: 56/2097 0.125s 0.001s
im_detect: 57/2097 0.125s 0.001s
im_detect: 58/2097 0.124s 0.001s
im_detect: 59/2097 0.125s 0.001s
im_detect: 60/2097 0.124s 0.001s
im_detect: 61/2097 0.124s 0.001s
im_detect: 62/2097 0.124s 0.001s
im_detect: 63/2097 0.124s 0.001s
im_detect: 64/2097 0.124s 0.001s
im_detect: 65/2097 0.124s 0.001s
im_detect: 66/2097 0.124s 0.001s
im_detect: 67/2097 0.124s 0.001s
im_detect: 68/2097 0.123s 0.001s
im_detect: 69/2097 0.123s 0.001s
im_detect: 70/2097 0.124s 0.001s
im_detect: 71/2097 0.123s 0.001s
im_detect: 72/2097 0.123s 0.001s
im_detect: 73/2097 0.123s 0.001s
im_detect: 74/2097 0.123s 0.001s
im_detect: 75/2097 0.123s 0.001s
im_detect: 76/2097 0.123s 0.001s
im_detect: 77/2097 0.123s 0.001s
im_detect: 78/2097 0.123s 0.001s
im_detect: 79/2097 0.123s 0.001s
im_detect: 80/2097 0.123s 0.001s
im_detect: 81/2097 0.123s 0.001s
im_detect: 82/2097 0.123s 0.001s
im_detect: 83/2097 0.123s 0.001s
im_detect: 84/2097 0.122s 0.001s
im_detect: 85/2097 0.122s 0.001s
im_detect: 86/2097 0.122s 0.001s
im_detect: 87/2097 0.122s 0.001s
im_detect: 88/2097 0.122s 0.001s
im_detect: 89/2097 0.122s 0.001s
im_detect: 90/2097 0.122s 0.001s
im_detect: 91/2097 0.122s 0.001s
im_detect: 92/2097 0.122s 0.001s
im_detect: 93/2097 0.122s 0.001s
im_detect: 94/2097 0.122s 0.001s
im_detect: 95/2097 0.122s 0.001s
im_detect: 96/2097 0.122s 0.001s
im_detect: 97/2097 0.122s 0.001s
im_detect: 98/2097 0.122s 0.001s
im_detect: 99/2097 0.122s 0.001s
im_detect: 100/2097 0.121s 0.001s
im_detect: 101/2097 0.121s 0.001s
im_detect: 102/2097 0.121s 0.001s
im_detect: 103/2097 0.121s 0.001s
im_detect: 104/2097 0.121s 0.001s
im_detect: 105/2097 0.121s 0.001s
im_detect: 106/2097 0.121s 0.001s
im_detect: 107/2097 0.121s 0.001s
im_detect: 108/2097 0.121s 0.001s
im_detect: 109/2097 0.121s 0.001s
im_detect: 110/2097 0.121s 0.001s
im_detect: 111/2097 0.121s 0.001s
im_detect: 112/2097 0.121s 0.001s
im_detect: 113/2097 0.121s 0.001s
im_detect: 114/2097 0.121s 0.001s
im_detect: 115/2097 0.121s 0.001s
im_detect: 116/2097 0.121s 0.001s
im_detect: 117/2097 0.121s 0.001s
im_detect: 118/2097 0.121s 0.001s
im_detect: 119/2097 0.121s 0.001s
im_detect: 120/2097 0.120s 0.001s
im_detect: 121/2097 0.121s 0.001s
im_detect: 122/2097 0.120s 0.001s
im_detect: 123/2097 0.120s 0.001s
im_detect: 124/2097 0.120s 0.001s
im_detect: 125/2097 0.120s 0.001s
im_detect: 126/2097 0.120s 0.001s
im_detect: 127/2097 0.120s 0.001s
im_detect: 128/2097 0.120s 0.001s
im_detect: 129/2097 0.120s 0.001s
im_detect: 130/2097 0.120s 0.001s
im_detect: 131/2097 0.120s 0.001s
im_detect: 132/2097 0.120s 0.001s
im_detect: 133/2097 0.120s 0.001s
im_detect: 134/2097 0.120s 0.001s
im_detect: 135/2097 0.120s 0.001s
im_detect: 136/2097 0.120s 0.001s
im_detect: 137/2097 0.120s 0.001s
im_detect: 138/2097 0.120s 0.001s
im_detect: 139/2097 0.120s 0.001s
im_detect: 140/2097 0.120s 0.001s
im_detect: 141/2097 0.120s 0.001s
im_detect: 142/2097 0.120s 0.001s
im_detect: 143/2097 0.120s 0.001s
im_detect: 144/2097 0.120s 0.001s
im_detect: 145/2097 0.120s 0.001s
im_detect: 146/2097 0.120s 0.001s
im_detect: 147/2097 0.120s 0.001s
im_detect: 148/2097 0.120s 0.001s
im_detect: 149/2097 0.120s 0.001s
im_detect: 150/2097 0.120s 0.001s
im_detect: 151/2097 0.120s 0.001s
im_detect: 152/2097 0.120s 0.001s
im_detect: 153/2097 0.120s 0.001s
im_detect: 154/2097 0.120s 0.001s
im_detect: 155/2097 0.120s 0.001s
im_detect: 156/2097 0.119s 0.001s
im_detect: 157/2097 0.119s 0.001s
im_detect: 158/2097 0.119s 0.001s
im_detect: 159/2097 0.119s 0.001s
im_detect: 160/2097 0.119s 0.001s
im_detect: 161/2097 0.119s 0.001s
im_detect: 162/2097 0.119s 0.001s
im_detect: 163/2097 0.119s 0.001s
im_detect: 164/2097 0.119s 0.001s
im_detect: 165/2097 0.119s 0.001s
im_detect: 166/2097 0.119s 0.001s
im_detect: 167/2097 0.119s 0.001s
im_detect: 168/2097 0.119s 0.001s
im_detect: 169/2097 0.119s 0.001s
im_detect: 170/2097 0.119s 0.001s
im_detect: 171/2097 0.119s 0.001s
im_detect: 172/2097 0.119s 0.001s
im_detect: 173/2097 0.119s 0.001s
im_detect: 174/2097 0.119s 0.001s
im_detect: 175/2097 0.119s 0.001s
im_detect: 176/2097 0.119s 0.001s
im_detect: 177/2097 0.119s 0.001s
im_detect: 178/2097 0.119s 0.001s
im_detect: 179/2097 0.119s 0.001s
im_detect: 180/2097 0.119s 0.001s
im_detect: 181/2097 0.119s 0.001s
im_detect: 182/2097 0.119s 0.001s
im_detect: 183/2097 0.119s 0.001s
im_detect: 184/2097 0.119s 0.001s
im_detect: 185/2097 0.119s 0.001s
im_detect: 186/2097 0.119s 0.001s
im_detect: 187/2097 0.119s 0.001s
im_detect: 188/2097 0.119s 0.001s
im_detect: 189/2097 0.119s 0.001s
im_detect: 190/2097 0.119s 0.001s
im_detect: 191/2097 0.119s 0.001s
im_detect: 192/2097 0.119s 0.001s
im_detect: 193/2097 0.119s 0.001s
im_detect: 194/2097 0.119s 0.001s
im_detect: 195/2097 0.119s 0.001s
im_detect: 196/2097 0.119s 0.001s
im_detect: 197/2097 0.119s 0.001s
im_detect: 198/2097 0.119s 0.001s
im_detect: 199/2097 0.119s 0.001s
im_detect: 200/2097 0.119s 0.001s
im_detect: 201/2097 0.119s 0.001s
im_detect: 202/2097 0.119s 0.001s
im_detect: 203/2097 0.119s 0.001s
im_detect: 204/2097 0.119s 0.001s
im_detect: 205/2097 0.119s 0.001s
im_detect: 206/2097 0.119s 0.001s
im_detect: 207/2097 0.119s 0.001s
im_detect: 208/2097 0.119s 0.001s
im_detect: 209/2097 0.119s 0.001s
im_detect: 210/2097 0.119s 0.001s
im_detect: 211/2097 0.118s 0.001s
im_detect: 212/2097 0.118s 0.001s
im_detect: 213/2097 0.118s 0.001s
im_detect: 214/2097 0.118s 0.001s
im_detect: 215/2097 0.118s 0.001s
im_detect: 216/2097 0.118s 0.001s
im_detect: 217/2097 0.118s 0.001s
im_detect: 218/2097 0.118s 0.001s
im_detect: 219/2097 0.118s 0.001s
im_detect: 220/2097 0.118s 0.001s
im_detect: 221/2097 0.118s 0.001s
im_detect: 222/2097 0.118s 0.001s
im_detect: 223/2097 0.118s 0.001s
im_detect: 224/2097 0.118s 0.001s
im_detect: 225/2097 0.118s 0.001s
im_detect: 226/2097 0.118s 0.001s
im_detect: 227/2097 0.118s 0.001s
im_detect: 228/2097 0.118s 0.001s
im_detect: 229/2097 0.118s 0.001s
im_detect: 230/2097 0.118s 0.001s
im_detect: 231/2097 0.118s 0.001s
im_detect: 232/2097 0.118s 0.001s
im_detect: 233/2097 0.118s 0.001s
im_detect: 234/2097 0.118s 0.001s
im_detect: 235/2097 0.118s 0.001s
im_detect: 236/2097 0.118s 0.001s
im_detect: 237/2097 0.118s 0.001s
im_detect: 238/2097 0.118s 0.001s
im_detect: 239/2097 0.118s 0.001s
im_detect: 240/2097 0.118s 0.001s
im_detect: 241/2097 0.118s 0.001s
im_detect: 242/2097 0.118s 0.001s
im_detect: 243/2097 0.118s 0.001s
im_detect: 244/2097 0.118s 0.001s
im_detect: 245/2097 0.118s 0.001s
im_detect: 246/2097 0.118s 0.001s
im_detect: 247/2097 0.118s 0.001s
im_detect: 248/2097 0.118s 0.001s
im_detect: 249/2097 0.118s 0.001s
im_detect: 250/2097 0.118s 0.001s
im_detect: 251/2097 0.118s 0.001s
im_detect: 252/2097 0.118s 0.001s
im_detect: 253/2097 0.118s 0.001s
im_detect: 254/2097 0.118s 0.001s
im_detect: 255/2097 0.118s 0.001s
im_detect: 256/2097 0.118s 0.001s
im_detect: 257/2097 0.118s 0.001s
im_detect: 258/2097 0.118s 0.001s
im_detect: 259/2097 0.118s 0.001s
im_detect: 260/2097 0.118s 0.001s
im_detect: 261/2097 0.118s 0.001s
im_detect: 262/2097 0.118s 0.001s
im_detect: 263/2097 0.118s 0.001s
im_detect: 264/2097 0.118s 0.001s
im_detect: 265/2097 0.118s 0.001s
im_detect: 266/2097 0.118s 0.001s
im_detect: 267/2097 0.118s 0.001s
im_detect: 268/2097 0.118s 0.001s
im_detect: 269/2097 0.118s 0.001s
im_detect: 270/2097 0.118s 0.001s
im_detect: 271/2097 0.118s 0.001s
im_detect: 272/2097 0.118s 0.001s
im_detect: 273/2097 0.117s 0.001s
im_detect: 274/2097 0.117s 0.001s
im_detect: 275/2097 0.117s 0.001s
im_detect: 276/2097 0.117s 0.001s
im_detect: 277/2097 0.117s 0.001s
im_detect: 278/2097 0.117s 0.001s
im_detect: 279/2097 0.117s 0.001s
im_detect: 280/2097 0.117s 0.001s
im_detect: 281/2097 0.117s 0.001s
im_detect: 282/2097 0.116s 0.001s
im_detect: 283/2097 0.116s 0.001s
im_detect: 284/2097 0.116s 0.001s
im_detect: 285/2097 0.116s 0.001s
im_detect: 286/2097 0.116s 0.001s
im_detect: 287/2097 0.116s 0.001s
im_detect: 288/2097 0.116s 0.001s
im_detect: 289/2097 0.116s 0.001s
im_detect: 290/2097 0.115s 0.001s
im_detect: 291/2097 0.115s 0.001s
im_detect: 292/2097 0.115s 0.001s
im_detect: 293/2097 0.115s 0.001s
im_detect: 294/2097 0.115s 0.001s
im_detect: 295/2097 0.115s 0.001s
im_detect: 296/2097 0.115s 0.001s
im_detect: 297/2097 0.115s 0.001s
im_detect: 298/2097 0.115s 0.001s
im_detect: 299/2097 0.115s 0.001s
im_detect: 300/2097 0.114s 0.001s
im_detect: 301/2097 0.114s 0.001s
im_detect: 302/2097 0.114s 0.001s
im_detect: 303/2097 0.114s 0.001s
im_detect: 304/2097 0.114s 0.001s
im_detect: 305/2097 0.114s 0.001s
im_detect: 306/2097 0.114s 0.001s
im_detect: 307/2097 0.114s 0.001s
im_detect: 308/2097 0.114s 0.001s
im_detect: 309/2097 0.114s 0.001s
im_detect: 310/2097 0.113s 0.001s
im_detect: 311/2097 0.113s 0.001s
im_detect: 312/2097 0.113s 0.001s
im_detect: 313/2097 0.113s 0.001s
im_detect: 314/2097 0.113s 0.001s
im_detect: 315/2097 0.113s 0.001s
im_detect: 316/2097 0.113s 0.001s
im_detect: 317/2097 0.113s 0.001s
im_detect: 318/2097 0.113s 0.001s
im_detect: 319/2097 0.113s 0.001s
im_detect: 320/2097 0.112s 0.001s
im_detect: 321/2097 0.112s 0.001s
im_detect: 322/2097 0.112s 0.001s
im_detect: 323/2097 0.112s 0.001s
im_detect: 324/2097 0.112s 0.001s
im_detect: 325/2097 0.112s 0.001s
im_detect: 326/2097 0.112s 0.001s
im_detect: 327/2097 0.112s 0.001s
im_detect: 328/2097 0.112s 0.001s
im_detect: 329/2097 0.112s 0.001s
im_detect: 330/2097 0.112s 0.001s
im_detect: 331/2097 0.111s 0.001s
im_detect: 332/2097 0.111s 0.001s
im_detect: 333/2097 0.111s 0.001s
im_detect: 334/2097 0.111s 0.001s
im_detect: 335/2097 0.111s 0.001s
im_detect: 336/2097 0.111s 0.001s
im_detect: 337/2097 0.111s 0.001s
im_detect: 338/2097 0.111s 0.001s
im_detect: 339/2097 0.111s 0.001s
im_detect: 340/2097 0.111s 0.001s
im_detect: 341/2097 0.111s 0.001s
im_detect: 342/2097 0.111s 0.001s
im_detect: 343/2097 0.110s 0.001s
im_detect: 344/2097 0.110s 0.001s
im_detect: 345/2097 0.110s 0.001s
im_detect: 346/2097 0.110s 0.001s
im_detect: 347/2097 0.110s 0.001s
im_detect: 348/2097 0.110s 0.001s
im_detect: 349/2097 0.110s 0.001s
im_detect: 350/2097 0.110s 0.001s
im_detect: 351/2097 0.110s 0.001s
im_detect: 352/2097 0.110s 0.001s
im_detect: 353/2097 0.110s 0.001s
im_detect: 354/2097 0.110s 0.001s
im_detect: 355/2097 0.110s 0.001s
im_detect: 356/2097 0.109s 0.001s
im_detect: 357/2097 0.109s 0.001s
im_detect: 358/2097 0.109s 0.001s
im_detect: 359/2097 0.109s 0.001s
im_detect: 360/2097 0.109s 0.001s
im_detect: 361/2097 0.109s 0.001s
im_detect: 362/2097 0.109s 0.001s
im_detect: 363/2097 0.109s 0.001s
im_detect: 364/2097 0.109s 0.001s
im_detect: 365/2097 0.109s 0.001s
im_detect: 366/2097 0.109s 0.001s
im_detect: 367/2097 0.109s 0.001s
im_detect: 368/2097 0.109s 0.001s
im_detect: 369/2097 0.109s 0.001s
im_detect: 370/2097 0.109s 0.001s
im_detect: 371/2097 0.108s 0.001s
im_detect: 372/2097 0.108s 0.001s
im_detect: 373/2097 0.108s 0.001s
im_detect: 374/2097 0.108s 0.001s
im_detect: 375/2097 0.108s 0.001s
im_detect: 376/2097 0.108s 0.001s
im_detect: 377/2097 0.108s 0.001s
im_detect: 378/2097 0.108s 0.001s
im_detect: 379/2097 0.108s 0.001s
im_detect: 380/2097 0.108s 0.001s
im_detect: 381/2097 0.108s 0.001s
im_detect: 382/2097 0.108s 0.001s
im_detect: 383/2097 0.108s 0.001s
im_detect: 384/2097 0.107s 0.001s
im_detect: 385/2097 0.107s 0.001s
im_detect: 386/2097 0.107s 0.001s
im_detect: 387/2097 0.107s 0.001s
im_detect: 388/2097 0.107s 0.001s
im_detect: 389/2097 0.107s 0.001s
im_detect: 390/2097 0.107s 0.001s
im_detect: 391/2097 0.107s 0.001s
im_detect: 392/2097 0.107s 0.001s
im_detect: 393/2097 0.107s 0.001s
im_detect: 394/2097 0.107s 0.001s
im_detect: 395/2097 0.107s 0.001s
im_detect: 396/2097 0.107s 0.001s
im_detect: 397/2097 0.107s 0.001s
im_detect: 398/2097 0.107s 0.001s
im_detect: 399/2097 0.107s 0.001s
im_detect: 400/2097 0.107s 0.001s
im_detect: 401/2097 0.107s 0.001s
im_detect: 402/2097 0.107s 0.001s
im_detect: 403/2097 0.106s 0.001s
im_detect: 404/2097 0.106s 0.001s
im_detect: 405/2097 0.106s 0.001s
im_detect: 406/2097 0.106s 0.001s
im_detect: 407/2097 0.106s 0.001s
im_detect: 408/2097 0.106s 0.001s
im_detect: 409/2097 0.106s 0.001s
im_detect: 410/2097 0.106s 0.001s
im_detect: 411/2097 0.106s 0.001s
im_detect: 412/2097 0.106s 0.001s
im_detect: 413/2097 0.106s 0.001s
im_detect: 414/2097 0.106s 0.001s
im_detect: 415/2097 0.106s 0.001s
im_detect: 416/2097 0.106s 0.001s
im_detect: 417/2097 0.106s 0.001s
im_detect: 418/2097 0.106s 0.001s
im_detect: 419/2097 0.106s 0.001s
im_detect: 420/2097 0.106s 0.001s
im_detect: 421/2097 0.105s 0.001s
im_detect: 422/2097 0.106s 0.001s
im_detect: 423/2097 0.105s 0.001s
im_detect: 424/2097 0.105s 0.001s
im_detect: 425/2097 0.105s 0.001s
im_detect: 426/2097 0.105s 0.001s
im_detect: 427/2097 0.105s 0.001s
im_detect: 428/2097 0.105s 0.001s
im_detect: 429/2097 0.105s 0.001s
im_detect: 430/2097 0.105s 0.001s
im_detect: 431/2097 0.105s 0.001s
im_detect: 432/2097 0.105s 0.001s
im_detect: 433/2097 0.105s 0.001s
im_detect: 434/2097 0.105s 0.001s
im_detect: 435/2097 0.105s 0.001s
im_detect: 436/2097 0.105s 0.001s
im_detect: 437/2097 0.105s 0.001s
im_detect: 438/2097 0.105s 0.001s
im_detect: 439/2097 0.105s 0.001s
im_detect: 440/2097 0.105s 0.001s
im_detect: 441/2097 0.105s 0.001s
im_detect: 442/2097 0.105s 0.001s
im_detect: 443/2097 0.105s 0.001s
im_detect: 444/2097 0.105s 0.001s
im_detect: 445/2097 0.105s 0.001s
im_detect: 446/2097 0.105s 0.001s
im_detect: 447/2097 0.105s 0.001s
im_detect: 448/2097 0.105s 0.001s
im_detect: 449/2097 0.104s 0.001s
im_detect: 450/2097 0.104s 0.001s
im_detect: 451/2097 0.104s 0.001s
im_detect: 452/2097 0.104s 0.001s
im_detect: 453/2097 0.104s 0.001s
im_detect: 454/2097 0.104s 0.001s
im_detect: 455/2097 0.104s 0.001s
im_detect: 456/2097 0.104s 0.001s
im_detect: 457/2097 0.104s 0.001s
im_detect: 458/2097 0.104s 0.001s
im_detect: 459/2097 0.104s 0.001s
im_detect: 460/2097 0.104s 0.001s
im_detect: 461/2097 0.104s 0.001s
im_detect: 462/2097 0.104s 0.001s
im_detect: 463/2097 0.104s 0.001s
im_detect: 464/2097 0.104s 0.001s
im_detect: 465/2097 0.104s 0.001s
im_detect: 466/2097 0.104s 0.001s
im_detect: 467/2097 0.104s 0.001s
im_detect: 468/2097 0.104s 0.001s
im_detect: 469/2097 0.104s 0.001s
im_detect: 470/2097 0.103s 0.001s
im_detect: 471/2097 0.103s 0.001s
im_detect: 472/2097 0.103s 0.001s
im_detect: 473/2097 0.103s 0.001s
im_detect: 474/2097 0.103s 0.001s
im_detect: 475/2097 0.103s 0.001s
im_detect: 476/2097 0.103s 0.001s
im_detect: 477/2097 0.103s 0.001s
im_detect: 478/2097 0.103s 0.001s
im_detect: 479/2097 0.103s 0.001s
im_detect: 480/2097 0.103s 0.001s
im_detect: 481/2097 0.103s 0.001s
im_detect: 482/2097 0.103s 0.001s
im_detect: 483/2097 0.103s 0.001s
im_detect: 484/2097 0.103s 0.001s
im_detect: 485/2097 0.103s 0.001s
im_detect: 486/2097 0.103s 0.001s
im_detect: 487/2097 0.103s 0.001s
im_detect: 488/2097 0.103s 0.001s
im_detect: 489/2097 0.103s 0.001s
im_detect: 490/2097 0.103s 0.001s
im_detect: 491/2097 0.103s 0.001s
im_detect: 492/2097 0.103s 0.001s
im_detect: 493/2097 0.102s 0.001s
im_detect: 494/2097 0.102s 0.001s
im_detect: 495/2097 0.102s 0.001s
im_detect: 496/2097 0.102s 0.001s
im_detect: 497/2097 0.102s 0.001s
im_detect: 498/2097 0.102s 0.001s
im_detect: 499/2097 0.102s 0.001s
im_detect: 500/2097 0.102s 0.001s
im_detect: 501/2097 0.102s 0.001s
im_detect: 502/2097 0.102s 0.001s
im_detect: 503/2097 0.102s 0.001s
im_detect: 504/2097 0.102s 0.001s
im_detect: 505/2097 0.102s 0.001s
im_detect: 506/2097 0.102s 0.001s
im_detect: 507/2097 0.102s 0.001s
im_detect: 508/2097 0.102s 0.001s
im_detect: 509/2097 0.102s 0.001s
im_detect: 510/2097 0.102s 0.001s
im_detect: 511/2097 0.102s 0.001s
im_detect: 512/2097 0.102s 0.001s
im_detect: 513/2097 0.102s 0.001s
im_detect: 514/2097 0.102s 0.001s
im_detect: 515/2097 0.102s 0.001s
im_detect: 516/2097 0.102s 0.001s
im_detect: 517/2097 0.102s 0.001s
im_detect: 518/2097 0.101s 0.001s
im_detect: 519/2097 0.101s 0.001s
im_detect: 520/2097 0.101s 0.001s
im_detect: 521/2097 0.101s 0.001s
im_detect: 522/2097 0.101s 0.001s
im_detect: 523/2097 0.101s 0.001s
im_detect: 524/2097 0.101s 0.001s
im_detect: 525/2097 0.101s 0.001s
im_detect: 526/2097 0.101s 0.001s
im_detect: 527/2097 0.101s 0.001s
im_detect: 528/2097 0.101s 0.001s
im_detect: 529/2097 0.101s 0.001s
im_detect: 530/2097 0.101s 0.001s
im_detect: 531/2097 0.101s 0.001s
im_detect: 532/2097 0.101s 0.001s
im_detect: 533/2097 0.101s 0.001s
im_detect: 534/2097 0.101s 0.001s
im_detect: 535/2097 0.101s 0.001s
im_detect: 536/2097 0.101s 0.001s
im_detect: 537/2097 0.101s 0.001s
im_detect: 538/2097 0.101s 0.001s
im_detect: 539/2097 0.101s 0.001s
im_detect: 540/2097 0.101s 0.001s
im_detect: 541/2097 0.101s 0.001s
im_detect: 542/2097 0.101s 0.001s
im_detect: 543/2097 0.101s 0.001s
im_detect: 544/2097 0.101s 0.001s
im_detect: 545/2097 0.101s 0.001s
im_detect: 546/2097 0.101s 0.001s
im_detect: 547/2097 0.101s 0.001s
im_detect: 548/2097 0.101s 0.001s
im_detect: 549/2097 0.101s 0.001s
im_detect: 550/2097 0.100s 0.001s
im_detect: 551/2097 0.100s 0.001s
im_detect: 552/2097 0.100s 0.001s
im_detect: 553/2097 0.100s 0.001s
im_detect: 554/2097 0.100s 0.001s
im_detect: 555/2097 0.100s 0.001s
im_detect: 556/2097 0.100s 0.001s
im_detect: 557/2097 0.100s 0.001s
im_detect: 558/2097 0.100s 0.001s
im_detect: 559/2097 0.100s 0.001s
im_detect: 560/2097 0.100s 0.001s
im_detect: 561/2097 0.100s 0.001s
im_detect: 562/2097 0.100s 0.001s
im_detect: 563/2097 0.100s 0.001s
im_detect: 564/2097 0.100s 0.001s
im_detect: 565/2097 0.100s 0.001s
im_detect: 566/2097 0.100s 0.001s
im_detect: 567/2097 0.100s 0.001s
im_detect: 568/2097 0.100s 0.001s
im_detect: 569/2097 0.100s 0.001s
im_detect: 570/2097 0.100s 0.001s
im_detect: 571/2097 0.100s 0.001s
im_detect: 572/2097 0.100s 0.001s
im_detect: 573/2097 0.100s 0.001s
im_detect: 574/2097 0.100s 0.001s
im_detect: 575/2097 0.100s 0.001s
im_detect: 576/2097 0.100s 0.001s
im_detect: 577/2097 0.100s 0.001s
im_detect: 578/2097 0.100s 0.001s
im_detect: 579/2097 0.100s 0.001s
im_detect: 580/2097 0.100s 0.001s
im_detect: 581/2097 0.100s 0.001s
im_detect: 582/2097 0.100s 0.001s
im_detect: 583/2097 0.100s 0.001s
im_detect: 584/2097 0.100s 0.001s
im_detect: 585/2097 0.100s 0.001s
im_detect: 586/2097 0.100s 0.001s
im_detect: 587/2097 0.100s 0.001s
im_detect: 588/2097 0.099s 0.001s
im_detect: 589/2097 0.099s 0.001s
im_detect: 590/2097 0.099s 0.001s
im_detect: 591/2097 0.099s 0.001s
im_detect: 592/2097 0.099s 0.001s
im_detect: 593/2097 0.099s 0.001s
im_detect: 594/2097 0.099s 0.001s
im_detect: 595/2097 0.099s 0.001s
im_detect: 596/2097 0.099s 0.001s
im_detect: 597/2097 0.099s 0.001s
im_detect: 598/2097 0.099s 0.001s
im_detect: 599/2097 0.099s 0.001s
im_detect: 600/2097 0.099s 0.001s
im_detect: 601/2097 0.099s 0.001s
im_detect: 602/2097 0.099s 0.001s
im_detect: 603/2097 0.099s 0.001s
im_detect: 604/2097 0.099s 0.001s
im_detect: 605/2097 0.099s 0.001s
im_detect: 606/2097 0.099s 0.001s
im_detect: 607/2097 0.099s 0.001s
im_detect: 608/2097 0.099s 0.001s
im_detect: 609/2097 0.099s 0.001s
im_detect: 610/2097 0.099s 0.001s
im_detect: 611/2097 0.099s 0.001s
im_detect: 612/2097 0.099s 0.001s
im_detect: 613/2097 0.099s 0.001s
im_detect: 614/2097 0.099s 0.001s
im_detect: 615/2097 0.099s 0.001s
im_detect: 616/2097 0.099s 0.001s
im_detect: 617/2097 0.099s 0.001s
im_detect: 618/2097 0.099s 0.001s
im_detect: 619/2097 0.099s 0.001s
im_detect: 620/2097 0.099s 0.001s
im_detect: 621/2097 0.099s 0.001s
im_detect: 622/2097 0.099s 0.001s
im_detect: 623/2097 0.099s 0.001s
im_detect: 624/2097 0.099s 0.001s
im_detect: 625/2097 0.099s 0.001s
im_detect: 626/2097 0.099s 0.001s
im_detect: 627/2097 0.099s 0.001s
im_detect: 628/2097 0.099s 0.001s
im_detect: 629/2097 0.099s 0.001s
im_detect: 630/2097 0.099s 0.001s
im_detect: 631/2097 0.099s 0.001s
im_detect: 632/2097 0.099s 0.001s
im_detect: 633/2097 0.098s 0.001s
im_detect: 634/2097 0.098s 0.001s
im_detect: 635/2097 0.098s 0.001s
im_detect: 636/2097 0.098s 0.001s
im_detect: 637/2097 0.098s 0.001s
im_detect: 638/2097 0.098s 0.001s
im_detect: 639/2097 0.098s 0.001s
im_detect: 640/2097 0.098s 0.001s
im_detect: 641/2097 0.098s 0.001s
im_detect: 642/2097 0.098s 0.001s
im_detect: 643/2097 0.098s 0.001s
im_detect: 644/2097 0.098s 0.001s
im_detect: 645/2097 0.098s 0.001s
im_detect: 646/2097 0.098s 0.001s
im_detect: 647/2097 0.098s 0.001s
im_detect: 648/2097 0.098s 0.001s
im_detect: 649/2097 0.098s 0.001s
im_detect: 650/2097 0.098s 0.001s
im_detect: 651/2097 0.098s 0.001s
im_detect: 652/2097 0.098s 0.001s
im_detect: 653/2097 0.098s 0.001s
im_detect: 654/2097 0.098s 0.001s
im_detect: 655/2097 0.098s 0.001s
im_detect: 656/2097 0.098s 0.001s
im_detect: 657/2097 0.098s 0.001s
im_detect: 658/2097 0.098s 0.001s
im_detect: 659/2097 0.098s 0.001s
im_detect: 660/2097 0.098s 0.001s
im_detect: 661/2097 0.098s 0.001s
im_detect: 662/2097 0.098s 0.001s
im_detect: 663/2097 0.098s 0.001s
im_detect: 664/2097 0.098s 0.001s
im_detect: 665/2097 0.098s 0.001s
im_detect: 666/2097 0.098s 0.001s
im_detect: 667/2097 0.098s 0.001s
im_detect: 668/2097 0.098s 0.001s
im_detect: 669/2097 0.098s 0.001s
im_detect: 670/2097 0.097s 0.001s
im_detect: 671/2097 0.097s 0.001s
im_detect: 672/2097 0.097s 0.001s
im_detect: 673/2097 0.097s 0.001s
im_detect: 674/2097 0.097s 0.001s
im_detect: 675/2097 0.097s 0.001s
im_detect: 676/2097 0.097s 0.001s
im_detect: 677/2097 0.097s 0.001s
im_detect: 678/2097 0.097s 0.001s
im_detect: 679/2097 0.097s 0.001s
im_detect: 680/2097 0.097s 0.001s
im_detect: 681/2097 0.097s 0.001s
im_detect: 682/2097 0.097s 0.001s
im_detect: 683/2097 0.097s 0.001s
im_detect: 684/2097 0.097s 0.001s
im_detect: 685/2097 0.097s 0.001s
im_detect: 686/2097 0.097s 0.001s
im_detect: 687/2097 0.097s 0.001s
im_detect: 688/2097 0.097s 0.001s
im_detect: 689/2097 0.097s 0.001s
im_detect: 690/2097 0.097s 0.001s
im_detect: 691/2097 0.097s 0.001s
im_detect: 692/2097 0.097s 0.001s
im_detect: 693/2097 0.097s 0.001s
im_detect: 694/2097 0.097s 0.001s
im_detect: 695/2097 0.097s 0.001s
im_detect: 696/2097 0.097s 0.001s
im_detect: 697/2097 0.097s 0.001s
im_detect: 698/2097 0.097s 0.001s
im_detect: 699/2097 0.097s 0.001s
im_detect: 700/2097 0.097s 0.001s
im_detect: 701/2097 0.097s 0.001s
im_detect: 702/2097 0.097s 0.001s
im_detect: 703/2097 0.097s 0.001s
im_detect: 704/2097 0.097s 0.001s
im_detect: 705/2097 0.097s 0.001s
im_detect: 706/2097 0.097s 0.001s
im_detect: 707/2097 0.097s 0.001s
im_detect: 708/2097 0.097s 0.001s
im_detect: 709/2097 0.097s 0.001s
im_detect: 710/2097 0.097s 0.001s
im_detect: 711/2097 0.097s 0.001s
im_detect: 712/2097 0.097s 0.001s
im_detect: 713/2097 0.097s 0.001s
im_detect: 714/2097 0.097s 0.001s
im_detect: 715/2097 0.097s 0.001s
im_detect: 716/2097 0.097s 0.001s
im_detect: 717/2097 0.097s 0.001s
im_detect: 718/2097 0.097s 0.001s
im_detect: 719/2097 0.097s 0.001s
im_detect: 720/2097 0.097s 0.001s
im_detect: 721/2097 0.097s 0.001s
im_detect: 722/2097 0.096s 0.001s
im_detect: 723/2097 0.096s 0.001s
im_detect: 724/2097 0.096s 0.001s
im_detect: 725/2097 0.096s 0.001s
im_detect: 726/2097 0.096s 0.001s
im_detect: 727/2097 0.096s 0.001s
im_detect: 728/2097 0.096s 0.001s
im_detect: 729/2097 0.096s 0.001s
im_detect: 730/2097 0.096s 0.001s
im_detect: 731/2097 0.096s 0.001s
im_detect: 732/2097 0.096s 0.001s
im_detect: 733/2097 0.096s 0.001s
im_detect: 734/2097 0.096s 0.001s
im_detect: 735/2097 0.096s 0.001s
im_detect: 736/2097 0.096s 0.001s
im_detect: 737/2097 0.096s 0.001s
im_detect: 738/2097 0.096s 0.001s
im_detect: 739/2097 0.096s 0.001s
im_detect: 740/2097 0.096s 0.001s
im_detect: 741/2097 0.096s 0.001s
im_detect: 742/2097 0.096s 0.001s
im_detect: 743/2097 0.096s 0.001s
im_detect: 744/2097 0.096s 0.001s
im_detect: 745/2097 0.096s 0.001s
im_detect: 746/2097 0.096s 0.001s
im_detect: 747/2097 0.096s 0.001s
im_detect: 748/2097 0.096s 0.001s
im_detect: 749/2097 0.096s 0.001s
im_detect: 750/2097 0.096s 0.001s
im_detect: 751/2097 0.096s 0.001s
im_detect: 752/2097 0.096s 0.001s
im_detect: 753/2097 0.096s 0.001s
im_detect: 754/2097 0.096s 0.001s
im_detect: 755/2097 0.096s 0.001s
im_detect: 756/2097 0.096s 0.001s
im_detect: 757/2097 0.096s 0.001s
im_detect: 758/2097 0.096s 0.001s
im_detect: 759/2097 0.096s 0.001s
im_detect: 760/2097 0.096s 0.001s
im_detect: 761/2097 0.096s 0.001s
im_detect: 762/2097 0.096s 0.001s
im_detect: 763/2097 0.096s 0.001s
im_detect: 764/2097 0.096s 0.001s
im_detect: 765/2097 0.096s 0.001s
im_detect: 766/2097 0.096s 0.001s
im_detect: 767/2097 0.096s 0.001s
im_detect: 768/2097 0.096s 0.001s
im_detect: 769/2097 0.096s 0.001s
im_detect: 770/2097 0.096s 0.001s
im_detect: 771/2097 0.096s 0.001s
im_detect: 772/2097 0.096s 0.001s
im_detect: 773/2097 0.096s 0.001s
im_detect: 774/2097 0.096s 0.001s
im_detect: 775/2097 0.096s 0.001s
im_detect: 776/2097 0.096s 0.001s
im_detect: 777/2097 0.096s 0.001s
im_detect: 778/2097 0.096s 0.001s
im_detect: 779/2097 0.096s 0.001s
im_detect: 780/2097 0.096s 0.001s
im_detect: 781/2097 0.096s 0.001s
im_detect: 782/2097 0.096s 0.001s
im_detect: 783/2097 0.096s 0.001s
im_detect: 784/2097 0.096s 0.001s
im_detect: 785/2097 0.096s 0.001s
im_detect: 786/2097 0.096s 0.001s
im_detect: 787/2097 0.096s 0.001s
im_detect: 788/2097 0.096s 0.001s
im_detect: 789/2097 0.096s 0.001s
im_detect: 790/2097 0.096s 0.001s
im_detect: 791/2097 0.096s 0.001s
im_detect: 792/2097 0.096s 0.001s
im_detect: 793/2097 0.096s 0.001s
im_detect: 794/2097 0.096s 0.001s
im_detect: 795/2097 0.096s 0.001s
im_detect: 796/2097 0.095s 0.001s
im_detect: 797/2097 0.095s 0.001s
im_detect: 798/2097 0.095s 0.001s
im_detect: 799/2097 0.095s 0.001s
im_detect: 800/2097 0.095s 0.001s
im_detect: 801/2097 0.095s 0.001s
im_detect: 802/2097 0.095s 0.001s
im_detect: 803/2097 0.095s 0.001s
im_detect: 804/2097 0.095s 0.001s
im_detect: 805/2097 0.095s 0.001s
im_detect: 806/2097 0.095s 0.001s
im_detect: 807/2097 0.095s 0.001s
im_detect: 808/2097 0.095s 0.001s
im_detect: 809/2097 0.095s 0.001s
im_detect: 810/2097 0.095s 0.001s
im_detect: 811/2097 0.095s 0.001s
im_detect: 812/2097 0.095s 0.001s
im_detect: 813/2097 0.095s 0.001s
im_detect: 814/2097 0.095s 0.001s
im_detect: 815/2097 0.095s 0.001s
im_detect: 816/2097 0.095s 0.001s
im_detect: 817/2097 0.095s 0.001s
im_detect: 818/2097 0.095s 0.001s
im_detect: 819/2097 0.095s 0.001s
im_detect: 820/2097 0.095s 0.001s
im_detect: 821/2097 0.095s 0.001s
im_detect: 822/2097 0.095s 0.001s
im_detect: 823/2097 0.095s 0.001s
im_detect: 824/2097 0.095s 0.001s
im_detect: 825/2097 0.095s 0.001s
im_detect: 826/2097 0.095s 0.001s
im_detect: 827/2097 0.095s 0.001s
im_detect: 828/2097 0.095s 0.001s
im_detect: 829/2097 0.095s 0.001s
im_detect: 830/2097 0.095s 0.001s
im_detect: 831/2097 0.095s 0.001s
im_detect: 832/2097 0.095s 0.001s
im_detect: 833/2097 0.095s 0.001s
im_detect: 834/2097 0.095s 0.001s
im_detect: 835/2097 0.095s 0.001s
im_detect: 836/2097 0.095s 0.001s
im_detect: 837/2097 0.095s 0.001s
im_detect: 838/2097 0.095s 0.001s
im_detect: 839/2097 0.095s 0.001s
im_detect: 840/2097 0.095s 0.001s
im_detect: 841/2097 0.095s 0.001s
im_detect: 842/2097 0.095s 0.001s
im_detect: 843/2097 0.095s 0.001s
im_detect: 844/2097 0.095s 0.001s
im_detect: 845/2097 0.095s 0.001s
im_detect: 846/2097 0.095s 0.001s
im_detect: 847/2097 0.095s 0.001s
im_detect: 848/2097 0.095s 0.001s
im_detect: 849/2097 0.095s 0.001s
im_detect: 850/2097 0.095s 0.001s
im_detect: 851/2097 0.095s 0.001s
im_detect: 852/2097 0.095s 0.001s
im_detect: 853/2097 0.095s 0.001s
im_detect: 854/2097 0.095s 0.001s
im_detect: 855/2097 0.095s 0.001s
im_detect: 856/2097 0.095s 0.001s
im_detect: 857/2097 0.095s 0.001s
im_detect: 858/2097 0.095s 0.001s
im_detect: 859/2097 0.095s 0.001s
im_detect: 860/2097 0.095s 0.001s
im_detect: 861/2097 0.095s 0.001s
im_detect: 862/2097 0.095s 0.001s
im_detect: 863/2097 0.095s 0.001s
im_detect: 864/2097 0.095s 0.001s
im_detect: 865/2097 0.095s 0.001s
im_detect: 866/2097 0.095s 0.001s
im_detect: 867/2097 0.095s 0.001s
im_detect: 868/2097 0.095s 0.001s
im_detect: 869/2097 0.095s 0.001s
im_detect: 870/2097 0.095s 0.001s
im_detect: 871/2097 0.095s 0.001s
im_detect: 872/2097 0.095s 0.001s
im_detect: 873/2097 0.095s 0.001s
im_detect: 874/2097 0.095s 0.001s
im_detect: 875/2097 0.095s 0.001s
im_detect: 876/2097 0.095s 0.001s
im_detect: 877/2097 0.095s 0.001s
im_detect: 878/2097 0.095s 0.001s
im_detect: 879/2097 0.095s 0.001s
im_detect: 880/2097 0.095s 0.001s
im_detect: 881/2097 0.095s 0.001s
im_detect: 882/2097 0.095s 0.001s
im_detect: 883/2097 0.095s 0.001s
im_detect: 884/2097 0.095s 0.001s
im_detect: 885/2097 0.095s 0.001s
im_detect: 886/2097 0.095s 0.001s
im_detect: 887/2097 0.095s 0.001s
im_detect: 888/2097 0.095s 0.001s
im_detect: 889/2097 0.095s 0.001s
im_detect: 890/2097 0.095s 0.001s
im_detect: 891/2097 0.095s 0.001s
im_detect: 892/2097 0.095s 0.001s
im_detect: 893/2097 0.095s 0.001s
im_detect: 894/2097 0.095s 0.001s
im_detect: 895/2097 0.095s 0.001s
im_detect: 896/2097 0.095s 0.001s
im_detect: 897/2097 0.095s 0.001s
im_detect: 898/2097 0.095s 0.001s
im_detect: 899/2097 0.095s 0.001s
im_detect: 900/2097 0.095s 0.001s
im_detect: 901/2097 0.095s 0.001s
im_detect: 902/2097 0.095s 0.001s
im_detect: 903/2097 0.095s 0.001s
im_detect: 904/2097 0.095s 0.001s
im_detect: 905/2097 0.095s 0.001s
im_detect: 906/2097 0.095s 0.001s
im_detect: 907/2097 0.095s 0.001s
im_detect: 908/2097 0.095s 0.001s
im_detect: 909/2097 0.095s 0.001s
im_detect: 910/2097 0.095s 0.001s
im_detect: 911/2097 0.095s 0.001s
im_detect: 912/2097 0.095s 0.001s
im_detect: 913/2097 0.095s 0.001s
im_detect: 914/2097 0.095s 0.001s
im_detect: 915/2097 0.095s 0.001s
im_detect: 916/2097 0.095s 0.001s
im_detect: 917/2097 0.095s 0.001s
im_detect: 918/2097 0.095s 0.001s
im_detect: 919/2097 0.094s 0.001s
im_detect: 920/2097 0.094s 0.001s
im_detect: 921/2097 0.094s 0.001s
im_detect: 922/2097 0.094s 0.001s
im_detect: 923/2097 0.094s 0.001s
im_detect: 924/2097 0.094s 0.001s
im_detect: 925/2097 0.094s 0.001s
im_detect: 926/2097 0.094s 0.001s
im_detect: 927/2097 0.094s 0.001s
im_detect: 928/2097 0.094s 0.001s
im_detect: 929/2097 0.094s 0.001s
im_detect: 930/2097 0.094s 0.001s
im_detect: 931/2097 0.094s 0.001s
im_detect: 932/2097 0.094s 0.001s
im_detect: 933/2097 0.094s 0.001s
im_detect: 934/2097 0.094s 0.001s
im_detect: 935/2097 0.094s 0.001s
im_detect: 936/2097 0.094s 0.001s
im_detect: 937/2097 0.094s 0.001s
im_detect: 938/2097 0.094s 0.001s
im_detect: 939/2097 0.094s 0.001s
im_detect: 940/2097 0.094s 0.001s
im_detect: 941/2097 0.094s 0.001s
im_detect: 942/2097 0.094s 0.001s
im_detect: 943/2097 0.094s 0.001s
im_detect: 944/2097 0.094s 0.001s
im_detect: 945/2097 0.094s 0.001s
im_detect: 946/2097 0.094s 0.001s
im_detect: 947/2097 0.094s 0.001s
im_detect: 948/2097 0.094s 0.001s
im_detect: 949/2097 0.094s 0.001s
im_detect: 950/2097 0.094s 0.001s
im_detect: 951/2097 0.094s 0.001s
im_detect: 952/2097 0.094s 0.001s
im_detect: 953/2097 0.094s 0.001s
im_detect: 954/2097 0.094s 0.001s
im_detect: 955/2097 0.094s 0.001s
im_detect: 956/2097 0.094s 0.001s
im_detect: 957/2097 0.094s 0.001s
im_detect: 958/2097 0.094s 0.001s
im_detect: 959/2097 0.094s 0.001s
im_detect: 960/2097 0.094s 0.001s
im_detect: 961/2097 0.094s 0.001s
im_detect: 962/2097 0.094s 0.001s
im_detect: 963/2097 0.094s 0.001s
im_detect: 964/2097 0.095s 0.001s
im_detect: 965/2097 0.095s 0.001s
im_detect: 966/2097 0.095s 0.001s
im_detect: 967/2097 0.095s 0.001s
im_detect: 968/2097 0.095s 0.001s
im_detect: 969/2097 0.095s 0.001s
im_detect: 970/2097 0.095s 0.001s
im_detect: 971/2097 0.095s 0.001s
im_detect: 972/2097 0.095s 0.001s
im_detect: 973/2097 0.095s 0.001s
im_detect: 974/2097 0.095s 0.001s
im_detect: 975/2097 0.095s 0.001s
im_detect: 976/2097 0.095s 0.001s
im_detect: 977/2097 0.095s 0.001s
im_detect: 978/2097 0.095s 0.001s
im_detect: 979/2097 0.095s 0.001s
im_detect: 980/2097 0.095s 0.001s
im_detect: 981/2097 0.095s 0.001s
im_detect: 982/2097 0.095s 0.001s
im_detect: 983/2097 0.095s 0.001s
im_detect: 984/2097 0.095s 0.001s
im_detect: 985/2097 0.095s 0.001s
im_detect: 986/2097 0.095s 0.001s
im_detect: 987/2097 0.095s 0.001s
im_detect: 988/2097 0.095s 0.001s
im_detect: 989/2097 0.095s 0.001s
im_detect: 990/2097 0.095s 0.001s
im_detect: 991/2097 0.095s 0.001s
im_detect: 992/2097 0.095s 0.001s
im_detect: 993/2097 0.095s 0.001s
im_detect: 994/2097 0.095s 0.001s
im_detect: 995/2097 0.095s 0.001s
im_detect: 996/2097 0.095s 0.001s
im_detect: 997/2097 0.095s 0.001s
im_detect: 998/2097 0.095s 0.001s
im_detect: 999/2097 0.095s 0.001s
im_detect: 1000/2097 0.095s 0.001s
im_detect: 1001/2097 0.095s 0.001s
im_detect: 1002/2097 0.095s 0.001s
im_detect: 1003/2097 0.095s 0.001s
im_detect: 1004/2097 0.095s 0.001s
im_detect: 1005/2097 0.095s 0.001s
im_detect: 1006/2097 0.095s 0.001s
im_detect: 1007/2097 0.095s 0.001s
im_detect: 1008/2097 0.095s 0.001s
im_detect: 1009/2097 0.095s 0.001s
im_detect: 1010/2097 0.095s 0.001s
im_detect: 1011/2097 0.095s 0.001s
im_detect: 1012/2097 0.095s 0.001s
im_detect: 1013/2097 0.095s 0.001s
im_detect: 1014/2097 0.095s 0.001s
im_detect: 1015/2097 0.095s 0.001s
im_detect: 1016/2097 0.095s 0.001s
im_detect: 1017/2097 0.095s 0.001s
im_detect: 1018/2097 0.095s 0.001s
im_detect: 1019/2097 0.095s 0.001s
im_detect: 1020/2097 0.095s 0.001s
im_detect: 1021/2097 0.095s 0.001s
im_detect: 1022/2097 0.095s 0.001s
im_detect: 1023/2097 0.095s 0.001s
im_detect: 1024/2097 0.095s 0.001s
im_detect: 1025/2097 0.095s 0.001s
im_detect: 1026/2097 0.095s 0.001s
im_detect: 1027/2097 0.095s 0.001s
im_detect: 1028/2097 0.095s 0.001s
im_detect: 1029/2097 0.095s 0.001s
im_detect: 1030/2097 0.095s 0.001s
im_detect: 1031/2097 0.095s 0.001s
im_detect: 1032/2097 0.095s 0.001s
im_detect: 1033/2097 0.095s 0.001s
im_detect: 1034/2097 0.095s 0.001s
im_detect: 1035/2097 0.095s 0.001s
im_detect: 1036/2097 0.095s 0.001s
im_detect: 1037/2097 0.095s 0.001s
im_detect: 1038/2097 0.095s 0.001s
im_detect: 1039/2097 0.095s 0.001s
im_detect: 1040/2097 0.095s 0.001s
im_detect: 1041/2097 0.095s 0.001s
im_detect: 1042/2097 0.095s 0.001s
im_detect: 1043/2097 0.095s 0.001s
im_detect: 1044/2097 0.095s 0.001s
im_detect: 1045/2097 0.095s 0.001s
im_detect: 1046/2097 0.095s 0.001s
im_detect: 1047/2097 0.095s 0.001s
im_detect: 1048/2097 0.095s 0.001s
im_detect: 1049/2097 0.095s 0.001s
im_detect: 1050/2097 0.095s 0.001s
im_detect: 1051/2097 0.095s 0.001s
im_detect: 1052/2097 0.095s 0.001s
im_detect: 1053/2097 0.095s 0.001s
im_detect: 1054/2097 0.095s 0.001s
im_detect: 1055/2097 0.095s 0.001s
im_detect: 1056/2097 0.095s 0.001s
im_detect: 1057/2097 0.095s 0.001s
im_detect: 1058/2097 0.095s 0.001s
im_detect: 1059/2097 0.095s 0.001s
im_detect: 1060/2097 0.095s 0.001s
im_detect: 1061/2097 0.095s 0.001s
im_detect: 1062/2097 0.095s 0.001s
im_detect: 1063/2097 0.095s 0.001s
im_detect: 1064/2097 0.095s 0.001s
im_detect: 1065/2097 0.095s 0.001s
im_detect: 1066/2097 0.095s 0.001s
im_detect: 1067/2097 0.095s 0.001s
im_detect: 1068/2097 0.095s 0.001s
im_detect: 1069/2097 0.095s 0.001s
im_detect: 1070/2097 0.095s 0.001s
im_detect: 1071/2097 0.095s 0.001s
im_detect: 1072/2097 0.095s 0.001s
im_detect: 1073/2097 0.095s 0.001s
im_detect: 1074/2097 0.095s 0.001s
im_detect: 1075/2097 0.095s 0.001s
im_detect: 1076/2097 0.095s 0.001s
im_detect: 1077/2097 0.096s 0.001s
im_detect: 1078/2097 0.096s 0.001s
im_detect: 1079/2097 0.096s 0.001s
im_detect: 1080/2097 0.096s 0.001s
im_detect: 1081/2097 0.096s 0.001s
im_detect: 1082/2097 0.096s 0.001s
im_detect: 1083/2097 0.096s 0.001s
im_detect: 1084/2097 0.096s 0.001s
im_detect: 1085/2097 0.096s 0.001s
im_detect: 1086/2097 0.096s 0.001s
im_detect: 1087/2097 0.096s 0.001s
im_detect: 1088/2097 0.096s 0.001s
im_detect: 1089/2097 0.096s 0.001s
im_detect: 1090/2097 0.096s 0.001s
im_detect: 1091/2097 0.096s 0.001s
im_detect: 1092/2097 0.096s 0.001s
im_detect: 1093/2097 0.096s 0.001s
im_detect: 1094/2097 0.096s 0.001s
im_detect: 1095/2097 0.096s 0.001s
im_detect: 1096/2097 0.096s 0.001s
im_detect: 1097/2097 0.096s 0.001s
im_detect: 1098/2097 0.096s 0.001s
im_detect: 1099/2097 0.096s 0.001s
im_detect: 1100/2097 0.096s 0.001s
im_detect: 1101/2097 0.096s 0.001s
im_detect: 1102/2097 0.096s 0.001s
im_detect: 1103/2097 0.096s 0.001s
im_detect: 1104/2097 0.096s 0.001s
im_detect: 1105/2097 0.096s 0.001s
im_detect: 1106/2097 0.096s 0.001s
im_detect: 1107/2097 0.096s 0.001s
im_detect: 1108/2097 0.096s 0.001s
im_detect: 1109/2097 0.096s 0.001s
im_detect: 1110/2097 0.096s 0.001s
im_detect: 1111/2097 0.096s 0.001s
im_detect: 1112/2097 0.096s 0.001s
im_detect: 1113/2097 0.096s 0.001s
im_detect: 1114/2097 0.096s 0.001s
im_detect: 1115/2097 0.096s 0.001s
im_detect: 1116/2097 0.096s 0.001s
im_detect: 1117/2097 0.096s 0.001s
im_detect: 1118/2097 0.096s 0.001s
im_detect: 1119/2097 0.096s 0.001s
im_detect: 1120/2097 0.096s 0.001s
im_detect: 1121/2097 0.096s 0.001s
im_detect: 1122/2097 0.096s 0.001s
im_detect: 1123/2097 0.096s 0.001s
im_detect: 1124/2097 0.096s 0.001s
im_detect: 1125/2097 0.097s 0.001s
im_detect: 1126/2097 0.097s 0.001s
im_detect: 1127/2097 0.097s 0.001s
im_detect: 1128/2097 0.097s 0.001s
im_detect: 1129/2097 0.097s 0.001s
im_detect: 1130/2097 0.097s 0.001s
im_detect: 1131/2097 0.097s 0.001s
im_detect: 1132/2097 0.097s 0.001s
im_detect: 1133/2097 0.097s 0.001s
im_detect: 1134/2097 0.097s 0.001s
im_detect: 1135/2097 0.097s 0.001s
im_detect: 1136/2097 0.097s 0.001s
im_detect: 1137/2097 0.097s 0.001s
im_detect: 1138/2097 0.097s 0.001s
im_detect: 1139/2097 0.097s 0.001s
im_detect: 1140/2097 0.097s 0.001s
im_detect: 1141/2097 0.097s 0.001s
im_detect: 1142/2097 0.097s 0.001s
im_detect: 1143/2097 0.097s 0.001s
im_detect: 1144/2097 0.097s 0.001s
im_detect: 1145/2097 0.097s 0.001s
im_detect: 1146/2097 0.097s 0.001s
im_detect: 1147/2097 0.097s 0.001s
im_detect: 1148/2097 0.097s 0.001s
im_detect: 1149/2097 0.097s 0.001s
im_detect: 1150/2097 0.097s 0.001s
im_detect: 1151/2097 0.097s 0.001s
im_detect: 1152/2097 0.097s 0.001s
im_detect: 1153/2097 0.097s 0.001s
im_detect: 1154/2097 0.097s 0.001s
im_detect: 1155/2097 0.097s 0.001s
im_detect: 1156/2097 0.097s 0.001s
im_detect: 1157/2097 0.097s 0.001s
im_detect: 1158/2097 0.097s 0.001s
im_detect: 1159/2097 0.097s 0.001s
im_detect: 1160/2097 0.097s 0.001s
im_detect: 1161/2097 0.097s 0.001s
im_detect: 1162/2097 0.097s 0.001s
im_detect: 1163/2097 0.097s 0.001s
im_detect: 1164/2097 0.097s 0.001s
im_detect: 1165/2097 0.097s 0.001s
im_detect: 1166/2097 0.097s 0.001s
im_detect: 1167/2097 0.097s 0.001s
im_detect: 1168/2097 0.097s 0.001s
im_detect: 1169/2097 0.097s 0.001s
im_detect: 1170/2097 0.097s 0.001s
im_detect: 1171/2097 0.097s 0.001s
im_detect: 1172/2097 0.097s 0.001s
im_detect: 1173/2097 0.097s 0.001s
im_detect: 1174/2097 0.097s 0.001s
im_detect: 1175/2097 0.097s 0.001s
im_detect: 1176/2097 0.097s 0.001s
im_detect: 1177/2097 0.097s 0.001s
im_detect: 1178/2097 0.097s 0.001s
im_detect: 1179/2097 0.097s 0.001s
im_detect: 1180/2097 0.097s 0.001s
im_detect: 1181/2097 0.097s 0.001s
im_detect: 1182/2097 0.097s 0.001s
im_detect: 1183/2097 0.097s 0.001s
im_detect: 1184/2097 0.098s 0.001s
im_detect: 1185/2097 0.098s 0.001s
im_detect: 1186/2097 0.098s 0.001s
im_detect: 1187/2097 0.098s 0.001s
im_detect: 1188/2097 0.098s 0.001s
im_detect: 1189/2097 0.098s 0.001s
im_detect: 1190/2097 0.098s 0.001s
im_detect: 1191/2097 0.098s 0.001s
im_detect: 1192/2097 0.098s 0.001s
im_detect: 1193/2097 0.098s 0.001s
im_detect: 1194/2097 0.098s 0.001s
im_detect: 1195/2097 0.098s 0.001s
im_detect: 1196/2097 0.098s 0.001s
im_detect: 1197/2097 0.098s 0.001s
im_detect: 1198/2097 0.098s 0.001s
im_detect: 1199/2097 0.098s 0.001s
im_detect: 1200/2097 0.098s 0.001s
im_detect: 1201/2097 0.098s 0.001s
im_detect: 1202/2097 0.098s 0.001s
im_detect: 1203/2097 0.098s 0.001s
im_detect: 1204/2097 0.098s 0.001s
im_detect: 1205/2097 0.098s 0.001s
im_detect: 1206/2097 0.098s 0.001s
im_detect: 1207/2097 0.098s 0.001s
im_detect: 1208/2097 0.098s 0.001s
im_detect: 1209/2097 0.098s 0.001s
im_detect: 1210/2097 0.098s 0.001s
im_detect: 1211/2097 0.098s 0.001s
im_detect: 1212/2097 0.098s 0.001s
im_detect: 1213/2097 0.098s 0.001s
im_detect: 1214/2097 0.098s 0.001s
im_detect: 1215/2097 0.098s 0.001s
im_detect: 1216/2097 0.098s 0.001s
im_detect: 1217/2097 0.098s 0.001s
im_detect: 1218/2097 0.098s 0.001s
im_detect: 1219/2097 0.098s 0.001s
im_detect: 1220/2097 0.098s 0.001s
im_detect: 1221/2097 0.098s 0.001s
im_detect: 1222/2097 0.098s 0.001s
im_detect: 1223/2097 0.098s 0.001s
im_detect: 1224/2097 0.098s 0.001s
im_detect: 1225/2097 0.098s 0.001s
im_detect: 1226/2097 0.098s 0.001s
im_detect: 1227/2097 0.098s 0.001s
im_detect: 1228/2097 0.098s 0.001s
im_detect: 1229/2097 0.098s 0.001s
im_detect: 1230/2097 0.098s 0.001s
im_detect: 1231/2097 0.098s 0.001s
im_detect: 1232/2097 0.098s 0.001s
im_detect: 1233/2097 0.098s 0.001s
im_detect: 1234/2097 0.098s 0.001s
im_detect: 1235/2097 0.098s 0.001s
im_detect: 1236/2097 0.098s 0.001s
im_detect: 1237/2097 0.098s 0.001s
im_detect: 1238/2097 0.098s 0.001s
im_detect: 1239/2097 0.098s 0.001s
im_detect: 1240/2097 0.098s 0.001s
im_detect: 1241/2097 0.098s 0.001s
im_detect: 1242/2097 0.098s 0.001s
im_detect: 1243/2097 0.098s 0.001s
im_detect: 1244/2097 0.098s 0.001s
im_detect: 1245/2097 0.098s 0.001s
im_detect: 1246/2097 0.098s 0.001s
im_detect: 1247/2097 0.098s 0.001s
im_detect: 1248/2097 0.098s 0.001s
im_detect: 1249/2097 0.098s 0.001s
im_detect: 1250/2097 0.098s 0.001s
im_detect: 1251/2097 0.098s 0.001s
im_detect: 1252/2097 0.098s 0.001s
im_detect: 1253/2097 0.098s 0.001s
im_detect: 1254/2097 0.098s 0.001s
im_detect: 1255/2097 0.098s 0.001s
im_detect: 1256/2097 0.099s 0.001s
im_detect: 1257/2097 0.099s 0.001s
im_detect: 1258/2097 0.099s 0.001s
im_detect: 1259/2097 0.099s 0.001s
im_detect: 1260/2097 0.099s 0.001s
im_detect: 1261/2097 0.099s 0.001s
im_detect: 1262/2097 0.099s 0.001s
im_detect: 1263/2097 0.099s 0.001s
im_detect: 1264/2097 0.099s 0.001s
im_detect: 1265/2097 0.099s 0.001s
im_detect: 1266/2097 0.099s 0.001s
im_detect: 1267/2097 0.099s 0.001s
im_detect: 1268/2097 0.099s 0.001s
im_detect: 1269/2097 0.099s 0.001s
im_detect: 1270/2097 0.099s 0.001s
im_detect: 1271/2097 0.099s 0.001s
im_detect: 1272/2097 0.099s 0.001s
im_detect: 1273/2097 0.099s 0.001s
im_detect: 1274/2097 0.099s 0.001s
im_detect: 1275/2097 0.099s 0.001s
im_detect: 1276/2097 0.099s 0.001s
im_detect: 1277/2097 0.099s 0.001s
im_detect: 1278/2097 0.099s 0.001s
im_detect: 1279/2097 0.099s 0.001s
im_detect: 1280/2097 0.099s 0.001s
im_detect: 1281/2097 0.099s 0.001s
im_detect: 1282/2097 0.099s 0.001s
im_detect: 1283/2097 0.099s 0.001s
im_detect: 1284/2097 0.099s 0.001s
im_detect: 1285/2097 0.099s 0.001s
im_detect: 1286/2097 0.099s 0.001s
im_detect: 1287/2097 0.099s 0.001s
im_detect: 1288/2097 0.099s 0.001s
im_detect: 1289/2097 0.099s 0.001s
im_detect: 1290/2097 0.099s 0.001s
im_detect: 1291/2097 0.099s 0.001s
im_detect: 1292/2097 0.099s 0.001s
im_detect: 1293/2097 0.099s 0.001s
im_detect: 1294/2097 0.099s 0.001s
im_detect: 1295/2097 0.099s 0.001s
im_detect: 1296/2097 0.099s 0.001s
im_detect: 1297/2097 0.099s 0.001s
im_detect: 1298/2097 0.099s 0.001s
im_detect: 1299/2097 0.099s 0.001s
im_detect: 1300/2097 0.099s 0.001s
im_detect: 1301/2097 0.099s 0.001s
im_detect: 1302/2097 0.099s 0.001s
im_detect: 1303/2097 0.099s 0.001s
im_detect: 1304/2097 0.099s 0.001s
im_detect: 1305/2097 0.099s 0.001s
im_detect: 1306/2097 0.099s 0.001s
im_detect: 1307/2097 0.099s 0.001s
im_detect: 1308/2097 0.099s 0.001s
im_detect: 1309/2097 0.099s 0.001s
im_detect: 1310/2097 0.099s 0.001s
im_detect: 1311/2097 0.099s 0.001s
im_detect: 1312/2097 0.099s 0.001s
im_detect: 1313/2097 0.099s 0.001s
im_detect: 1314/2097 0.099s 0.001s
im_detect: 1315/2097 0.099s 0.001s
im_detect: 1316/2097 0.099s 0.001s
im_detect: 1317/2097 0.099s 0.001s
im_detect: 1318/2097 0.099s 0.001s
im_detect: 1319/2097 0.099s 0.001s
im_detect: 1320/2097 0.099s 0.001s
im_detect: 1321/2097 0.099s 0.001s
im_detect: 1322/2097 0.099s 0.001s
im_detect: 1323/2097 0.099s 0.001s
im_detect: 1324/2097 0.099s 0.001s
im_detect: 1325/2097 0.099s 0.001s
im_detect: 1326/2097 0.099s 0.001s
im_detect: 1327/2097 0.099s 0.001s
im_detect: 1328/2097 0.099s 0.001s
im_detect: 1329/2097 0.099s 0.001s
im_detect: 1330/2097 0.099s 0.001s
im_detect: 1331/2097 0.099s 0.001s
im_detect: 1332/2097 0.099s 0.001s
im_detect: 1333/2097 0.099s 0.001s
im_detect: 1334/2097 0.098s 0.001s
im_detect: 1335/2097 0.098s 0.001s
im_detect: 1336/2097 0.098s 0.001s
im_detect: 1337/2097 0.098s 0.001s
im_detect: 1338/2097 0.098s 0.001s
im_detect: 1339/2097 0.098s 0.001s
im_detect: 1340/2097 0.098s 0.001s
im_detect: 1341/2097 0.098s 0.001s
im_detect: 1342/2097 0.098s 0.001s
im_detect: 1343/2097 0.098s 0.001s
im_detect: 1344/2097 0.098s 0.001s
im_detect: 1345/2097 0.098s 0.001s
im_detect: 1346/2097 0.098s 0.001s
im_detect: 1347/2097 0.098s 0.001s
im_detect: 1348/2097 0.098s 0.001s
im_detect: 1349/2097 0.098s 0.001s
im_detect: 1350/2097 0.098s 0.001s
im_detect: 1351/2097 0.098s 0.001s
im_detect: 1352/2097 0.098s 0.001s
im_detect: 1353/2097 0.098s 0.001s
im_detect: 1354/2097 0.098s 0.001s
im_detect: 1355/2097 0.098s 0.001s
im_detect: 1356/2097 0.098s 0.001s
im_detect: 1357/2097 0.098s 0.001s
im_detect: 1358/2097 0.098s 0.001s
im_detect: 1359/2097 0.098s 0.001s
im_detect: 1360/2097 0.098s 0.001s
im_detect: 1361/2097 0.098s 0.001s
im_detect: 1362/2097 0.098s 0.001s
im_detect: 1363/2097 0.098s 0.001s
im_detect: 1364/2097 0.098s 0.001s
im_detect: 1365/2097 0.098s 0.001s
im_detect: 1366/2097 0.098s 0.001s
im_detect: 1367/2097 0.098s 0.001s
im_detect: 1368/2097 0.098s 0.001s
im_detect: 1369/2097 0.098s 0.001s
im_detect: 1370/2097 0.098s 0.001s
im_detect: 1371/2097 0.098s 0.001s
im_detect: 1372/2097 0.098s 0.001s
im_detect: 1373/2097 0.098s 0.001s
im_detect: 1374/2097 0.098s 0.001s
im_detect: 1375/2097 0.098s 0.001s
im_detect: 1376/2097 0.098s 0.001s
im_detect: 1377/2097 0.098s 0.001s
im_detect: 1378/2097 0.098s 0.001s
im_detect: 1379/2097 0.098s 0.001s
im_detect: 1380/2097 0.098s 0.001s
im_detect: 1381/2097 0.098s 0.001s
im_detect: 1382/2097 0.098s 0.001s
im_detect: 1383/2097 0.098s 0.001s
im_detect: 1384/2097 0.098s 0.001s
im_detect: 1385/2097 0.098s 0.001s
im_detect: 1386/2097 0.098s 0.001s
im_detect: 1387/2097 0.098s 0.001s
im_detect: 1388/2097 0.098s 0.001s
im_detect: 1389/2097 0.098s 0.001s
im_detect: 1390/2097 0.098s 0.001s
im_detect: 1391/2097 0.098s 0.001s
im_detect: 1392/2097 0.098s 0.001s
im_detect: 1393/2097 0.098s 0.001s
im_detect: 1394/2097 0.098s 0.001s
im_detect: 1395/2097 0.098s 0.001s
im_detect: 1396/2097 0.098s 0.001s
im_detect: 1397/2097 0.098s 0.001s
im_detect: 1398/2097 0.098s 0.001s
im_detect: 1399/2097 0.098s 0.001s
im_detect: 1400/2097 0.098s 0.001s
im_detect: 1401/2097 0.098s 0.001s
im_detect: 1402/2097 0.098s 0.001s
im_detect: 1403/2097 0.098s 0.001s
im_detect: 1404/2097 0.098s 0.001s
im_detect: 1405/2097 0.098s 0.001s
im_detect: 1406/2097 0.098s 0.001s
im_detect: 1407/2097 0.098s 0.001s
im_detect: 1408/2097 0.098s 0.001s
im_detect: 1409/2097 0.098s 0.001s
im_detect: 1410/2097 0.098s 0.001s
im_detect: 1411/2097 0.098s 0.001s
im_detect: 1412/2097 0.098s 0.001s
im_detect: 1413/2097 0.098s 0.001s
im_detect: 1414/2097 0.098s 0.001s
im_detect: 1415/2097 0.098s 0.001s
im_detect: 1416/2097 0.098s 0.001s
im_detect: 1417/2097 0.098s 0.001s
im_detect: 1418/2097 0.098s 0.001s
im_detect: 1419/2097 0.098s 0.001s
im_detect: 1420/2097 0.098s 0.001s
im_detect: 1421/2097 0.098s 0.001s
im_detect: 1422/2097 0.098s 0.001s
im_detect: 1423/2097 0.098s 0.001s
im_detect: 1424/2097 0.098s 0.001s
im_detect: 1425/2097 0.098s 0.001s
im_detect: 1426/2097 0.098s 0.001s
im_detect: 1427/2097 0.098s 0.001s
im_detect: 1428/2097 0.098s 0.001s
im_detect: 1429/2097 0.098s 0.001s
im_detect: 1430/2097 0.098s 0.001s
im_detect: 1431/2097 0.098s 0.001s
im_detect: 1432/2097 0.098s 0.001s
im_detect: 1433/2097 0.098s 0.001s
im_detect: 1434/2097 0.098s 0.001s
im_detect: 1435/2097 0.098s 0.001s
im_detect: 1436/2097 0.098s 0.001s
im_detect: 1437/2097 0.098s 0.001s
im_detect: 1438/2097 0.097s 0.001s
im_detect: 1439/2097 0.097s 0.001s
im_detect: 1440/2097 0.097s 0.001s
im_detect: 1441/2097 0.097s 0.001s
im_detect: 1442/2097 0.097s 0.001s
im_detect: 1443/2097 0.097s 0.001s
im_detect: 1444/2097 0.097s 0.001s
im_detect: 1445/2097 0.097s 0.001s
im_detect: 1446/2097 0.097s 0.001s
im_detect: 1447/2097 0.097s 0.001s
im_detect: 1448/2097 0.097s 0.001s
im_detect: 1449/2097 0.097s 0.001s
im_detect: 1450/2097 0.097s 0.001s
im_detect: 1451/2097 0.097s 0.001s
im_detect: 1452/2097 0.097s 0.001s
im_detect: 1453/2097 0.097s 0.001s
im_detect: 1454/2097 0.097s 0.001s
im_detect: 1455/2097 0.097s 0.001s
im_detect: 1456/2097 0.097s 0.001s
im_detect: 1457/2097 0.097s 0.001s
im_detect: 1458/2097 0.097s 0.001s
im_detect: 1459/2097 0.097s 0.001s
im_detect: 1460/2097 0.097s 0.001s
im_detect: 1461/2097 0.097s 0.001s
im_detect: 1462/2097 0.097s 0.001s
im_detect: 1463/2097 0.097s 0.001s
im_detect: 1464/2097 0.097s 0.001s
im_detect: 1465/2097 0.097s 0.001s
im_detect: 1466/2097 0.097s 0.001s
im_detect: 1467/2097 0.097s 0.001s
im_detect: 1468/2097 0.097s 0.001s
im_detect: 1469/2097 0.097s 0.001s
im_detect: 1470/2097 0.097s 0.001s
im_detect: 1471/2097 0.097s 0.001s
im_detect: 1472/2097 0.097s 0.001s
im_detect: 1473/2097 0.097s 0.001s
im_detect: 1474/2097 0.097s 0.001s
im_detect: 1475/2097 0.097s 0.001s
im_detect: 1476/2097 0.097s 0.001s
im_detect: 1477/2097 0.097s 0.001s
im_detect: 1478/2097 0.097s 0.001s
im_detect: 1479/2097 0.097s 0.001s
im_detect: 1480/2097 0.097s 0.001s
im_detect: 1481/2097 0.097s 0.001s
im_detect: 1482/2097 0.097s 0.001s
im_detect: 1483/2097 0.097s 0.001s
im_detect: 1484/2097 0.097s 0.001s
im_detect: 1485/2097 0.097s 0.001s
im_detect: 1486/2097 0.097s 0.001s
im_detect: 1487/2097 0.097s 0.001s
im_detect: 1488/2097 0.097s 0.001s
im_detect: 1489/2097 0.097s 0.001s
im_detect: 1490/2097 0.097s 0.001s
im_detect: 1491/2097 0.097s 0.001s
im_detect: 1492/2097 0.097s 0.001s
im_detect: 1493/2097 0.097s 0.001s
im_detect: 1494/2097 0.097s 0.001s
im_detect: 1495/2097 0.097s 0.001s
im_detect: 1496/2097 0.097s 0.001s
im_detect: 1497/2097 0.097s 0.001s
im_detect: 1498/2097 0.097s 0.001s
im_detect: 1499/2097 0.097s 0.001s
im_detect: 1500/2097 0.097s 0.001s
im_detect: 1501/2097 0.097s 0.001s
im_detect: 1502/2097 0.097s 0.001s
im_detect: 1503/2097 0.097s 0.001s
im_detect: 1504/2097 0.097s 0.001s
im_detect: 1505/2097 0.097s 0.001s
im_detect: 1506/2097 0.097s 0.001s
im_detect: 1507/2097 0.097s 0.001s
im_detect: 1508/2097 0.097s 0.001s
im_detect: 1509/2097 0.097s 0.001s
im_detect: 1510/2097 0.097s 0.001s
im_detect: 1511/2097 0.097s 0.001s
im_detect: 1512/2097 0.097s 0.001s
im_detect: 1513/2097 0.097s 0.001s
im_detect: 1514/2097 0.097s 0.001s
im_detect: 1515/2097 0.097s 0.001s
im_detect: 1516/2097 0.097s 0.001s
im_detect: 1517/2097 0.097s 0.001s
im_detect: 1518/2097 0.097s 0.001s
im_detect: 1519/2097 0.097s 0.001s
im_detect: 1520/2097 0.097s 0.001s
im_detect: 1521/2097 0.097s 0.001s
im_detect: 1522/2097 0.097s 0.001s
im_detect: 1523/2097 0.097s 0.001s
im_detect: 1524/2097 0.097s 0.001s
im_detect: 1525/2097 0.097s 0.001s
im_detect: 1526/2097 0.097s 0.001s
im_detect: 1527/2097 0.097s 0.001s
im_detect: 1528/2097 0.097s 0.001s
im_detect: 1529/2097 0.097s 0.001s
im_detect: 1530/2097 0.097s 0.001s
im_detect: 1531/2097 0.097s 0.001s
im_detect: 1532/2097 0.097s 0.001s
im_detect: 1533/2097 0.097s 0.001s
im_detect: 1534/2097 0.097s 0.001s
im_detect: 1535/2097 0.097s 0.001s
im_detect: 1536/2097 0.097s 0.001s
im_detect: 1537/2097 0.097s 0.001s
im_detect: 1538/2097 0.097s 0.001s
im_detect: 1539/2097 0.097s 0.001s
im_detect: 1540/2097 0.097s 0.001s
im_detect: 1541/2097 0.097s 0.001s
im_detect: 1542/2097 0.097s 0.001s
im_detect: 1543/2097 0.097s 0.001s
im_detect: 1544/2097 0.097s 0.001s
im_detect: 1545/2097 0.097s 0.001s
im_detect: 1546/2097 0.096s 0.001s
im_detect: 1547/2097 0.096s 0.001s
im_detect: 1548/2097 0.096s 0.001s
im_detect: 1549/2097 0.096s 0.001s
im_detect: 1550/2097 0.096s 0.001s
im_detect: 1551/2097 0.096s 0.001s
im_detect: 1552/2097 0.096s 0.001s
im_detect: 1553/2097 0.096s 0.001s
im_detect: 1554/2097 0.096s 0.001s
im_detect: 1555/2097 0.096s 0.001s
im_detect: 1556/2097 0.096s 0.001s
im_detect: 1557/2097 0.096s 0.001s
im_detect: 1558/2097 0.096s 0.001s
im_detect: 1559/2097 0.096s 0.001s
im_detect: 1560/2097 0.096s 0.001s
im_detect: 1561/2097 0.096s 0.001s
im_detect: 1562/2097 0.096s 0.001s
im_detect: 1563/2097 0.096s 0.001s
im_detect: 1564/2097 0.096s 0.001s
im_detect: 1565/2097 0.096s 0.001s
im_detect: 1566/2097 0.096s 0.001s
im_detect: 1567/2097 0.096s 0.001s
im_detect: 1568/2097 0.096s 0.001s
im_detect: 1569/2097 0.096s 0.001s
im_detect: 1570/2097 0.096s 0.001s
im_detect: 1571/2097 0.096s 0.001s
im_detect: 1572/2097 0.096s 0.001s
im_detect: 1573/2097 0.096s 0.001s
im_detect: 1574/2097 0.096s 0.001s
im_detect: 1575/2097 0.096s 0.001s
im_detect: 1576/2097 0.096s 0.001s
im_detect: 1577/2097 0.096s 0.001s
im_detect: 1578/2097 0.096s 0.001s
im_detect: 1579/2097 0.096s 0.001s
im_detect: 1580/2097 0.096s 0.001s
im_detect: 1581/2097 0.096s 0.001s
im_detect: 1582/2097 0.096s 0.001s
im_detect: 1583/2097 0.096s 0.001s
im_detect: 1584/2097 0.096s 0.001s
im_detect: 1585/2097 0.096s 0.001s
im_detect: 1586/2097 0.096s 0.001s
im_detect: 1587/2097 0.096s 0.001s
im_detect: 1588/2097 0.096s 0.001s
im_detect: 1589/2097 0.096s 0.001s
im_detect: 1590/2097 0.096s 0.001s
im_detect: 1591/2097 0.096s 0.001s
im_detect: 1592/2097 0.096s 0.001s
im_detect: 1593/2097 0.096s 0.001s
im_detect: 1594/2097 0.096s 0.001s
im_detect: 1595/2097 0.096s 0.001s
im_detect: 1596/2097 0.096s 0.001s
im_detect: 1597/2097 0.096s 0.001s
im_detect: 1598/2097 0.096s 0.001s
im_detect: 1599/2097 0.096s 0.001s
im_detect: 1600/2097 0.096s 0.001s
im_detect: 1601/2097 0.096s 0.001s
im_detect: 1602/2097 0.096s 0.001s
im_detect: 1603/2097 0.096s 0.001s
im_detect: 1604/2097 0.096s 0.001s
im_detect: 1605/2097 0.096s 0.001s
im_detect: 1606/2097 0.096s 0.001s
im_detect: 1607/2097 0.096s 0.001s
im_detect: 1608/2097 0.096s 0.001s
im_detect: 1609/2097 0.096s 0.001s
im_detect: 1610/2097 0.096s 0.001s
im_detect: 1611/2097 0.096s 0.001s
im_detect: 1612/2097 0.096s 0.001s
im_detect: 1613/2097 0.096s 0.001s
im_detect: 1614/2097 0.096s 0.001s
im_detect: 1615/2097 0.096s 0.001s
im_detect: 1616/2097 0.096s 0.001s
im_detect: 1617/2097 0.096s 0.001s
im_detect: 1618/2097 0.096s 0.001s
im_detect: 1619/2097 0.096s 0.001s
im_detect: 1620/2097 0.096s 0.001s
im_detect: 1621/2097 0.096s 0.001s
im_detect: 1622/2097 0.096s 0.001s
im_detect: 1623/2097 0.096s 0.001s
im_detect: 1624/2097 0.096s 0.001s
im_detect: 1625/2097 0.096s 0.001s
im_detect: 1626/2097 0.096s 0.001s
im_detect: 1627/2097 0.096s 0.001s
im_detect: 1628/2097 0.096s 0.001s
im_detect: 1629/2097 0.096s 0.001s
im_detect: 1630/2097 0.096s 0.001s
im_detect: 1631/2097 0.096s 0.001s
im_detect: 1632/2097 0.096s 0.001s
im_detect: 1633/2097 0.096s 0.001s
im_detect: 1634/2097 0.096s 0.001s
im_detect: 1635/2097 0.096s 0.001s
im_detect: 1636/2097 0.096s 0.001s
im_detect: 1637/2097 0.096s 0.001s
im_detect: 1638/2097 0.096s 0.001s
im_detect: 1639/2097 0.096s 0.001s
im_detect: 1640/2097 0.096s 0.001s
im_detect: 1641/2097 0.096s 0.001s
im_detect: 1642/2097 0.096s 0.001s
im_detect: 1643/2097 0.096s 0.001s
im_detect: 1644/2097 0.096s 0.001s
im_detect: 1645/2097 0.096s 0.001s
im_detect: 1646/2097 0.096s 0.001s
im_detect: 1647/2097 0.096s 0.001s
im_detect: 1648/2097 0.096s 0.001s
im_detect: 1649/2097 0.096s 0.001s
im_detect: 1650/2097 0.096s 0.001s
im_detect: 1651/2097 0.096s 0.001s
im_detect: 1652/2097 0.096s 0.001s
im_detect: 1653/2097 0.096s 0.001s
im_detect: 1654/2097 0.096s 0.001s
im_detect: 1655/2097 0.096s 0.001s
im_detect: 1656/2097 0.096s 0.001s
im_detect: 1657/2097 0.096s 0.001s
im_detect: 1658/2097 0.096s 0.001s
im_detect: 1659/2097 0.096s 0.001s
im_detect: 1660/2097 0.096s 0.001s
im_detect: 1661/2097 0.096s 0.001s
im_detect: 1662/2097 0.096s 0.001s
im_detect: 1663/2097 0.096s 0.001s
im_detect: 1664/2097 0.096s 0.001s
im_detect: 1665/2097 0.096s 0.001s
im_detect: 1666/2097 0.096s 0.001s
im_detect: 1667/2097 0.096s 0.001s
im_detect: 1668/2097 0.096s 0.001s
im_detect: 1669/2097 0.096s 0.001s
im_detect: 1670/2097 0.096s 0.001s
im_detect: 1671/2097 0.096s 0.001s
im_detect: 1672/2097 0.096s 0.001s
im_detect: 1673/2097 0.096s 0.001s
im_detect: 1674/2097 0.096s 0.001s
im_detect: 1675/2097 0.096s 0.001s
im_detect: 1676/2097 0.096s 0.001s
im_detect: 1677/2097 0.096s 0.001s
im_detect: 1678/2097 0.096s 0.001s
im_detect: 1679/2097 0.096s 0.001s
im_detect: 1680/2097 0.096s 0.001s
im_detect: 1681/2097 0.095s 0.001s
im_detect: 1682/2097 0.095s 0.001s
im_detect: 1683/2097 0.095s 0.001s
im_detect: 1684/2097 0.095s 0.001s
im_detect: 1685/2097 0.095s 0.001s
im_detect: 1686/2097 0.095s 0.001s
im_detect: 1687/2097 0.095s 0.001s
im_detect: 1688/2097 0.095s 0.001s
im_detect: 1689/2097 0.095s 0.001s
im_detect: 1690/2097 0.095s 0.001s
im_detect: 1691/2097 0.095s 0.001s
im_detect: 1692/2097 0.095s 0.001s
im_detect: 1693/2097 0.095s 0.001s
im_detect: 1694/2097 0.095s 0.001s
im_detect: 1695/2097 0.095s 0.001s
im_detect: 1696/2097 0.095s 0.001s
im_detect: 1697/2097 0.095s 0.001s
im_detect: 1698/2097 0.095s 0.001s
im_detect: 1699/2097 0.095s 0.001s
im_detect: 1700/2097 0.095s 0.001s
im_detect: 1701/2097 0.095s 0.001s
im_detect: 1702/2097 0.095s 0.001s
im_detect: 1703/2097 0.095s 0.001s
im_detect: 1704/2097 0.095s 0.001s
im_detect: 1705/2097 0.095s 0.001s
im_detect: 1706/2097 0.095s 0.001s
im_detect: 1707/2097 0.095s 0.001s
im_detect: 1708/2097 0.095s 0.001s
im_detect: 1709/2097 0.095s 0.001s
im_detect: 1710/2097 0.095s 0.001s
im_detect: 1711/2097 0.095s 0.001s
im_detect: 1712/2097 0.095s 0.001s
im_detect: 1713/2097 0.095s 0.001s
im_detect: 1714/2097 0.095s 0.001s
im_detect: 1715/2097 0.095s 0.001s
im_detect: 1716/2097 0.095s 0.001s
im_detect: 1717/2097 0.095s 0.001s
im_detect: 1718/2097 0.095s 0.001s
im_detect: 1719/2097 0.095s 0.001s
im_detect: 1720/2097 0.095s 0.001s
im_detect: 1721/2097 0.095s 0.001s
im_detect: 1722/2097 0.095s 0.001s
im_detect: 1723/2097 0.095s 0.001s
im_detect: 1724/2097 0.095s 0.001s
im_detect: 1725/2097 0.095s 0.001s
im_detect: 1726/2097 0.095s 0.001s
im_detect: 1727/2097 0.095s 0.001s
im_detect: 1728/2097 0.095s 0.001s
im_detect: 1729/2097 0.095s 0.001s
im_detect: 1730/2097 0.095s 0.001s
im_detect: 1731/2097 0.095s 0.001s
im_detect: 1732/2097 0.095s 0.001s
im_detect: 1733/2097 0.095s 0.001s
im_detect: 1734/2097 0.095s 0.001s
im_detect: 1735/2097 0.095s 0.001s
im_detect: 1736/2097 0.095s 0.001s
im_detect: 1737/2097 0.095s 0.001s
im_detect: 1738/2097 0.095s 0.001s
im_detect: 1739/2097 0.095s 0.001s
im_detect: 1740/2097 0.095s 0.001s
im_detect: 1741/2097 0.095s 0.001s
im_detect: 1742/2097 0.095s 0.001s
im_detect: 1743/2097 0.095s 0.001s
im_detect: 1744/2097 0.095s 0.001s
im_detect: 1745/2097 0.095s 0.001s
im_detect: 1746/2097 0.095s 0.001s
im_detect: 1747/2097 0.095s 0.001s
im_detect: 1748/2097 0.095s 0.001s
im_detect: 1749/2097 0.095s 0.001s
im_detect: 1750/2097 0.095s 0.001s
im_detect: 1751/2097 0.095s 0.001s
im_detect: 1752/2097 0.095s 0.001s
im_detect: 1753/2097 0.095s 0.001s
im_detect: 1754/2097 0.095s 0.001s
im_detect: 1755/2097 0.095s 0.001s
im_detect: 1756/2097 0.095s 0.001s
im_detect: 1757/2097 0.095s 0.001s
im_detect: 1758/2097 0.095s 0.001s
im_detect: 1759/2097 0.095s 0.001s
im_detect: 1760/2097 0.095s 0.001s
im_detect: 1761/2097 0.095s 0.001s
im_detect: 1762/2097 0.095s 0.001s
im_detect: 1763/2097 0.095s 0.001s
im_detect: 1764/2097 0.095s 0.001s
im_detect: 1765/2097 0.095s 0.001s
im_detect: 1766/2097 0.095s 0.001s
im_detect: 1767/2097 0.095s 0.001s
im_detect: 1768/2097 0.095s 0.001s
im_detect: 1769/2097 0.095s 0.001s
im_detect: 1770/2097 0.095s 0.001s
im_detect: 1771/2097 0.095s 0.001s
im_detect: 1772/2097 0.095s 0.001s
im_detect: 1773/2097 0.095s 0.001s
im_detect: 1774/2097 0.095s 0.001s
im_detect: 1775/2097 0.095s 0.001s
im_detect: 1776/2097 0.095s 0.001s
im_detect: 1777/2097 0.095s 0.001s
im_detect: 1778/2097 0.095s 0.001s
im_detect: 1779/2097 0.095s 0.001s
im_detect: 1780/2097 0.095s 0.001s
im_detect: 1781/2097 0.095s 0.001s
im_detect: 1782/2097 0.095s 0.001s
im_detect: 1783/2097 0.095s 0.001s
im_detect: 1784/2097 0.095s 0.001s
im_detect: 1785/2097 0.095s 0.001s
im_detect: 1786/2097 0.095s 0.001s
im_detect: 1787/2097 0.095s 0.001s
im_detect: 1788/2097 0.095s 0.001s
im_detect: 1789/2097 0.095s 0.001s
im_detect: 1790/2097 0.095s 0.001s
im_detect: 1791/2097 0.095s 0.001s
im_detect: 1792/2097 0.095s 0.001s
im_detect: 1793/2097 0.095s 0.001s
im_detect: 1794/2097 0.095s 0.001s
im_detect: 1795/2097 0.095s 0.001s
im_detect: 1796/2097 0.095s 0.001s
im_detect: 1797/2097 0.095s 0.001s
im_detect: 1798/2097 0.095s 0.001s
im_detect: 1799/2097 0.095s 0.001s
im_detect: 1800/2097 0.095s 0.001s
im_detect: 1801/2097 0.095s 0.001s
im_detect: 1802/2097 0.095s 0.001s
im_detect: 1803/2097 0.095s 0.001s
im_detect: 1804/2097 0.095s 0.001s
im_detect: 1805/2097 0.095s 0.001s
im_detect: 1806/2097 0.095s 0.001s
im_detect: 1807/2097 0.095s 0.001s
im_detect: 1808/2097 0.095s 0.001s
im_detect: 1809/2097 0.095s 0.001s
im_detect: 1810/2097 0.095s 0.001s
im_detect: 1811/2097 0.095s 0.001s
im_detect: 1812/2097 0.095s 0.001s
im_detect: 1813/2097 0.095s 0.001s
im_detect: 1814/2097 0.095s 0.001s
im_detect: 1815/2097 0.095s 0.001s
im_detect: 1816/2097 0.095s 0.001s
im_detect: 1817/2097 0.095s 0.001s
im_detect: 1818/2097 0.095s 0.001s
im_detect: 1819/2097 0.095s 0.001s
im_detect: 1820/2097 0.095s 0.001s
im_detect: 1821/2097 0.095s 0.001s
im_detect: 1822/2097 0.095s 0.001s
im_detect: 1823/2097 0.095s 0.001s
im_detect: 1824/2097 0.095s 0.001s
im_detect: 1825/2097 0.095s 0.001s
im_detect: 1826/2097 0.095s 0.001s
im_detect: 1827/2097 0.094s 0.001s
im_detect: 1828/2097 0.094s 0.001s
im_detect: 1829/2097 0.094s 0.001s
im_detect: 1830/2097 0.094s 0.001s
im_detect: 1831/2097 0.094s 0.001s
im_detect: 1832/2097 0.094s 0.001s
im_detect: 1833/2097 0.094s 0.001s
im_detect: 1834/2097 0.094s 0.001s
im_detect: 1835/2097 0.094s 0.001s
im_detect: 1836/2097 0.094s 0.001s
im_detect: 1837/2097 0.094s 0.001s
im_detect: 1838/2097 0.094s 0.001s
im_detect: 1839/2097 0.094s 0.001s
im_detect: 1840/2097 0.094s 0.001s
im_detect: 1841/2097 0.094s 0.001s
im_detect: 1842/2097 0.094s 0.001s
im_detect: 1843/2097 0.094s 0.001s
im_detect: 1844/2097 0.094s 0.001s
im_detect: 1845/2097 0.094s 0.001s
im_detect: 1846/2097 0.094s 0.001s
im_detect: 1847/2097 0.094s 0.001s
im_detect: 1848/2097 0.094s 0.001s
im_detect: 1849/2097 0.094s 0.001s
im_detect: 1850/2097 0.094s 0.001s
im_detect: 1851/2097 0.094s 0.001s
im_detect: 1852/2097 0.094s 0.001s
im_detect: 1853/2097 0.094s 0.001s
im_detect: 1854/2097 0.094s 0.001s
im_detect: 1855/2097 0.094s 0.001s
im_detect: 1856/2097 0.094s 0.001s
im_detect: 1857/2097 0.094s 0.001s
im_detect: 1858/2097 0.094s 0.001s
im_detect: 1859/2097 0.094s 0.001s
im_detect: 1860/2097 0.094s 0.001s
im_detect: 1861/2097 0.094s 0.001s
im_detect: 1862/2097 0.094s 0.001s
im_detect: 1863/2097 0.094s 0.001s
im_detect: 1864/2097 0.094s 0.001s
im_detect: 1865/2097 0.094s 0.001s
im_detect: 1866/2097 0.094s 0.001s
im_detect: 1867/2097 0.094s 0.001s
im_detect: 1868/2097 0.094s 0.001s
im_detect: 1869/2097 0.094s 0.001s
im_detect: 1870/2097 0.094s 0.001s
im_detect: 1871/2097 0.094s 0.001s
im_detect: 1872/2097 0.094s 0.001s
im_detect: 1873/2097 0.094s 0.001s
im_detect: 1874/2097 0.094s 0.001s
im_detect: 1875/2097 0.094s 0.001s
im_detect: 1876/2097 0.094s 0.001s
im_detect: 1877/2097 0.094s 0.001s
im_detect: 1878/2097 0.094s 0.001s
im_detect: 1879/2097 0.094s 0.001s
im_detect: 1880/2097 0.094s 0.001s
im_detect: 1881/2097 0.094s 0.001s
im_detect: 1882/2097 0.094s 0.001s
im_detect: 1883/2097 0.094s 0.001s
im_detect: 1884/2097 0.094s 0.001s
im_detect: 1885/2097 0.094s 0.001s
im_detect: 1886/2097 0.094s 0.001s
im_detect: 1887/2097 0.094s 0.001s
im_detect: 1888/2097 0.094s 0.001s
im_detect: 1889/2097 0.094s 0.001s
im_detect: 1890/2097 0.094s 0.001s
im_detect: 1891/2097 0.094s 0.001s
im_detect: 1892/2097 0.094s 0.001s
im_detect: 1893/2097 0.094s 0.001s
im_detect: 1894/2097 0.094s 0.001s
im_detect: 1895/2097 0.094s 0.001s
im_detect: 1896/2097 0.094s 0.001s
im_detect: 1897/2097 0.094s 0.001s
im_detect: 1898/2097 0.094s 0.001s
im_detect: 1899/2097 0.094s 0.001s
im_detect: 1900/2097 0.094s 0.001s
im_detect: 1901/2097 0.094s 0.001s
im_detect: 1902/2097 0.094s 0.001s
im_detect: 1903/2097 0.094s 0.001s
im_detect: 1904/2097 0.094s 0.001s
im_detect: 1905/2097 0.094s 0.001s
im_detect: 1906/2097 0.094s 0.001s
im_detect: 1907/2097 0.094s 0.001s
im_detect: 1908/2097 0.094s 0.001s
im_detect: 1909/2097 0.094s 0.001s
im_detect: 1910/2097 0.094s 0.001s
im_detect: 1911/2097 0.094s 0.001s
im_detect: 1912/2097 0.094s 0.001s
im_detect: 1913/2097 0.094s 0.001s
im_detect: 1914/2097 0.094s 0.001s
im_detect: 1915/2097 0.094s 0.001s
im_detect: 1916/2097 0.094s 0.001s
im_detect: 1917/2097 0.094s 0.001s
im_detect: 1918/2097 0.094s 0.001s
im_detect: 1919/2097 0.094s 0.001s
im_detect: 1920/2097 0.094s 0.001s
im_detect: 1921/2097 0.094s 0.001s
im_detect: 1922/2097 0.094s 0.001s
im_detect: 1923/2097 0.094s 0.001s
im_detect: 1924/2097 0.094s 0.001s
im_detect: 1925/2097 0.094s 0.001s
im_detect: 1926/2097 0.094s 0.001s
im_detect: 1927/2097 0.094s 0.001s
im_detect: 1928/2097 0.094s 0.001s
im_detect: 1929/2097 0.094s 0.001s
im_detect: 1930/2097 0.094s 0.001s
im_detect: 1931/2097 0.094s 0.001s
im_detect: 1932/2097 0.094s 0.001s
im_detect: 1933/2097 0.094s 0.001s
im_detect: 1934/2097 0.094s 0.001s
im_detect: 1935/2097 0.094s 0.001s
im_detect: 1936/2097 0.094s 0.001s
im_detect: 1937/2097 0.094s 0.001s
im_detect: 1938/2097 0.094s 0.001s
im_detect: 1939/2097 0.094s 0.001s
im_detect: 1940/2097 0.094s 0.001s
im_detect: 1941/2097 0.094s 0.001s
im_detect: 1942/2097 0.094s 0.001s
im_detect: 1943/2097 0.094s 0.001s
im_detect: 1944/2097 0.094s 0.001s
im_detect: 1945/2097 0.094s 0.001s
im_detect: 1946/2097 0.094s 0.001s
im_detect: 1947/2097 0.094s 0.001s
im_detect: 1948/2097 0.094s 0.001s
im_detect: 1949/2097 0.094s 0.001s
im_detect: 1950/2097 0.094s 0.001s
im_detect: 1951/2097 0.094s 0.001s
im_detect: 1952/2097 0.094s 0.001s
im_detect: 1953/2097 0.094s 0.001s
im_detect: 1954/2097 0.094s 0.001s
im_detect: 1955/2097 0.094s 0.001s
im_detect: 1956/2097 0.094s 0.001s
im_detect: 1957/2097 0.094s 0.001s
im_detect: 1958/2097 0.094s 0.001s
im_detect: 1959/2097 0.094s 0.001s
im_detect: 1960/2097 0.094s 0.001s
im_detect: 1961/2097 0.094s 0.001s
im_detect: 1962/2097 0.094s 0.001s
im_detect: 1963/2097 0.094s 0.001s
im_detect: 1964/2097 0.094s 0.001s
im_detect: 1965/2097 0.094s 0.001s
im_detect: 1966/2097 0.094s 0.001s
im_detect: 1967/2097 0.094s 0.001s
im_detect: 1968/2097 0.094s 0.001s
im_detect: 1969/2097 0.094s 0.001s
im_detect: 1970/2097 0.094s 0.001s
im_detect: 1971/2097 0.094s 0.001s
im_detect: 1972/2097 0.094s 0.001s
im_detect: 1973/2097 0.094s 0.001s
im_detect: 1974/2097 0.094s 0.001s
im_detect: 1975/2097 0.094s 0.001s
im_detect: 1976/2097 0.094s 0.001s
im_detect: 1977/2097 0.094s 0.001s
im_detect: 1978/2097 0.094s 0.001s
im_detect: 1979/2097 0.094s 0.001s
im_detect: 1980/2097 0.094s 0.001s
im_detect: 1981/2097 0.094s 0.001s
im_detect: 1982/2097 0.094s 0.001s
im_detect: 1983/2097 0.094s 0.001s
im_detect: 1984/2097 0.094s 0.001s
im_detect: 1985/2097 0.094s 0.001s
im_detect: 1986/2097 0.094s 0.001s
im_detect: 1987/2097 0.094s 0.001s
im_detect: 1988/2097 0.094s 0.001s
im_detect: 1989/2097 0.094s 0.001s
im_detect: 1990/2097 0.094s 0.001s
im_detect: 1991/2097 0.094s 0.001s
im_detect: 1992/2097 0.094s 0.001s
im_detect: 1993/2097 0.094s 0.001s
im_detect: 1994/2097 0.094s 0.001s
im_detect: 1995/2097 0.094s 0.001s
im_detect: 1996/2097 0.094s 0.001s
im_detect: 1997/2097 0.094s 0.001s
im_detect: 1998/2097 0.094s 0.001s
im_detect: 1999/2097 0.094s 0.001s
im_detect: 2000/2097 0.094s 0.001s
im_detect: 2001/2097 0.094s 0.001s
im_detect: 2002/2097 0.094s 0.001s
im_detect: 2003/2097 0.094s 0.001s
im_detect: 2004/2097 0.094s 0.001s
im_detect: 2005/2097 0.094s 0.001s
im_detect: 2006/2097 0.094s 0.001s
im_detect: 2007/2097 0.094s 0.001s
im_detect: 2008/2097 0.094s 0.001s
im_detect: 2009/2097 0.094s 0.001s
im_detect: 2010/2097 0.094s 0.001s
im_detect: 2011/2097 0.094s 0.001s
im_detect: 2012/2097 0.094s 0.001s
im_detect: 2013/2097 0.094s 0.001s
im_detect: 2014/2097 0.094s 0.001s
im_detect: 2015/2097 0.094s 0.001s
im_detect: 2016/2097 0.094s 0.001s
im_detect: 2017/2097 0.094s 0.001s
im_detect: 2018/2097 0.094s 0.001s
im_detect: 2019/2097 0.094s 0.001s
im_detect: 2020/2097 0.094s 0.001s
im_detect: 2021/2097 0.094s 0.001s
im_detect: 2022/2097 0.094s 0.001s
im_detect: 2023/2097 0.094s 0.001s
im_detect: 2024/2097 0.094s 0.001s
im_detect: 2025/2097 0.094s 0.001s
im_detect: 2026/2097 0.094s 0.001s
im_detect: 2027/2097 0.094s 0.001s
im_detect: 2028/2097 0.094s 0.001s
im_detect: 2029/2097 0.094s 0.001s
im_detect: 2030/2097 0.094s 0.001s
im_detect: 2031/2097 0.094s 0.001s
im_detect: 2032/2097 0.094s 0.001s
im_detect: 2033/2097 0.094s 0.001s
im_detect: 2034/2097 0.094s 0.001s
im_detect: 2035/2097 0.094s 0.001s
im_detect: 2036/2097 0.094s 0.001s
im_detect: 2037/2097 0.094s 0.001s
im_detect: 2038/2097 0.094s 0.001s
im_detect: 2039/2097 0.094s 0.001s
im_detect: 2040/2097 0.094s 0.001s
im_detect: 2041/2097 0.094s 0.001s
im_detect: 2042/2097 0.094s 0.001s
im_detect: 2043/2097 0.094s 0.001s
im_detect: 2044/2097 0.094s 0.001s
im_detect: 2045/2097 0.094s 0.001s
im_detect: 2046/2097 0.094s 0.001s
im_detect: 2047/2097 0.094s 0.001s
im_detect: 2048/2097 0.094s 0.001s
im_detect: 2049/2097 0.094s 0.001s
im_detect: 2050/2097 0.094s 0.001s
im_detect: 2051/2097 0.094s 0.001s
im_detect: 2052/2097 0.094s 0.001s
im_detect: 2053/2097 0.094s 0.001s
im_detect: 2054/2097 0.094s 0.001s
im_detect: 2055/2097 0.094s 0.001s
im_detect: 2056/2097 0.094s 0.001s
im_detect: 2057/2097 0.094s 0.001s
im_detect: 2058/2097 0.094s 0.001s
im_detect: 2059/2097 0.094s 0.001s
im_detect: 2060/2097 0.094s 0.001s
im_detect: 2061/2097 0.094s 0.001s
im_detect: 2062/2097 0.094s 0.001s
im_detect: 2063/2097 0.094s 0.001s
im_detect: 2064/2097 0.094s 0.001s
im_detect: 2065/2097 0.094s 0.001s
im_detect: 2066/2097 0.094s 0.001s
im_detect: 2067/2097 0.094s 0.001s
im_detect: 2068/2097 0.094s 0.001s
im_detect: 2069/2097 0.094s 0.001s
im_detect: 2070/2097 0.094s 0.001s
im_detect: 2071/2097 0.094s 0.001s
im_detect: 2072/2097 0.094s 0.001s
im_detect: 2073/2097 0.094s 0.001s
im_detect: 2074/2097 0.094s 0.001s
im_detect: 2075/2097 0.094s 0.001s
im_detect: 2076/2097 0.094s 0.001s
im_detect: 2077/2097 0.094s 0.001s
im_detect: 2078/2097 0.094s 0.001s
im_detect: 2079/2097 0.094s 0.001s
im_detect: 2080/2097 0.094s 0.001s
im_detect: 2081/2097 0.094s 0.001s
im_detect: 2082/2097 0.094s 0.001s
im_detect: 2083/2097 0.094s 0.001s
im_detect: 2084/2097 0.094s 0.001s
im_detect: 2085/2097 0.094s 0.001s
im_detect: 2086/2097 0.094s 0.001s
im_detect: 2087/2097 0.094s 0.001s
im_detect: 2088/2097 0.094s 0.001s
im_detect: 2089/2097 0.094s 0.001s
im_detect: 2090/2097 0.094s 0.001s
im_detect: 2091/2097 0.094s 0.001s
im_detect: 2092/2097 0.094s 0.001s
im_detect: 2093/2097 0.094s 0.001s
im_detect: 2094/2097 0.094s 0.001s
im_detect: 2095/2097 0.094s 0.001s
im_detect: 2096/2097 0.094s 0.001s
im_detect: 2097/2097 0.094s 0.001s
Evaluating detections
Writing day_2_yes VOC results file
Writing day_2_no VOC results file
Writing day_3_yes VOC results file
Writing day_3_no VOC results file
Writing night_2_yes VOC results file
Writing night_2_no VOC results file
Writing night_3_yes VOC results file
Writing night_3_no VOC results file
VOC07 metric? Yes
Reading annotation for 1/2097
Reading annotation for 101/2097
Reading annotation for 201/2097
Reading annotation for 301/2097
Reading annotation for 401/2097
Reading annotation for 501/2097
Reading annotation for 601/2097
Reading annotation for 701/2097
Reading annotation for 801/2097
Reading annotation for 901/2097
Reading annotation for 1001/2097
Reading annotation for 1101/2097
Reading annotation for 1201/2097
Reading annotation for 1301/2097
Reading annotation for 1401/2097
Reading annotation for 1501/2097
Reading annotation for 1601/2097
Reading annotation for 1701/2097
Reading annotation for 1801/2097
Reading annotation for 1901/2097
Reading annotation for 2001/2097
Saving cached annotations to /home/ubuntu/user_space/maga_faster/our_method/data/VOCdevkit2007/annotations_cache/annots.pkl
AP for day_2_yes = 0.8367
AP for day_2_no = 0.7494
AP for day_3_yes = 0.8325
AP for day_3_no = 0.8344
AP for night_2_yes = 0.7850
AP for night_2_no = 0.6265
AP for night_3_yes = 0.8527
AP for night_3_no = 0.8753
Mean AP = 0.7991
~~~~~~~~
Results:
0.837
0.749
0.833
0.834
0.785
0.627
0.853
0.875
0.799
~~~~~~~~

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	4m2.780s
user	3m43.372s
sys	0m39.370s
